nohup: ignoring input
Epoch:   0%|          | 0/4 [00:00<?, ?it/s]human_feature : tensor([[0.1469, 0.0000, 0.0000,  ..., 0.0003, 0.0000, 0.0013],
        [0.1469, 0.0000, 0.0000,  ..., 0.0003, 0.0000, 0.0013],
        [0.1469, 0.0000, 0.0000,  ..., 0.0003, 0.0000, 0.0013],
        ...,
        [0.2069, 0.0635, 0.2590,  ..., 0.0005, 0.0016, 0.0012],
        [0.2069, 0.0635, 0.2590,  ..., 0.0005, 0.0016, 0.0012],
        [0.2069, 0.0635, 0.2590,  ..., 0.0005, 0.0016, 0.0012]],
       dtype=torch.float16)
data_dir /data/hdj/tracking_buggy_files/joblib_memmap_swt/data/
dev_file train_3hard_1_valid_data.txt
prefix /data/hdj/tracking_buggy_files/swt/swt
human_feature : tensor([[5.0049e-01, 0.0000e+00, 3.5303e-01,  ..., 1.3709e-04, 9.6858e-05,
         1.2903e-03],
        [5.0049e-01, 0.0000e+00, 3.5303e-01,  ..., 1.3709e-04, 9.6858e-05,
         1.2903e-03],
        [5.0049e-01, 0.0000e+00, 3.5303e-01,  ..., 1.3709e-04, 9.6858e-05,
         1.2903e-03],
        ...,
        [7.5623e-02, 0.0000e+00, 4.8126e-02,  ..., 1.2624e-04, 8.6725e-05,
         1.1845e-03],
        [7.5623e-02, 0.0000e+00, 4.8126e-02,  ..., 1.2624e-04, 8.6725e-05,
         1.1845e-03],
        [7.5623e-02, 0.0000e+00, 4.8126e-02,  ..., 1.2624e-04, 8.6725e-05,
         1.1845e-03]], dtype=torch.float16)
使用TextCNNClassifier模型
Focal_loss alpha = [0.25, 0.75], 将对每一类权重进行精细化赋值
training!!!
[ 1 : 0 / 5645.21875 ] loss :3.7527  , accuracy:  0.6875 true nums: 11  ration : 0.171875 acc : 0.6875  f1 : 0.16666666666666669
[ 1 : 100 / 5645.21875 ] loss :2.0113  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 200 / 5645.21875 ] loss :2.5553  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 300 / 5645.21875 ] loss :2.6074  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 400 / 5645.21875 ] loss :2.4908  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 500 / 5645.21875 ] loss :2.3536  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 600 / 5645.21875 ] loss :2.4624  , accuracy:  0.703125 true nums: 20  ration : 0.3125 acc : 0.703125  f1 : 0.09523809523809523
[ 1 : 700 / 5645.21875 ] loss :2.3811  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 800 / 5645.21875 ] loss :2.2626  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 900 / 5645.21875 ] loss :2.5699  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 1000 / 5645.21875 ] loss :1.9928  , accuracy:  0.84375 true nums: 10  ration : 0.15625 acc : 0.84375  f1 : 0.0
[ 1 : 1100 / 5645.21875 ] loss :2.3335  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1200 / 5645.21875 ] loss :2.5407  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 1300 / 5645.21875 ] loss :1.9971  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 1400 / 5645.21875 ] loss :1.8972  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 1500 / 5645.21875 ] loss :2.3894  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 1600 / 5645.21875 ] loss :2.6544  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 1700 / 5645.21875 ] loss :2.2595  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 1800 / 5645.21875 ] loss :2.6170  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 1900 / 5645.21875 ] loss :2.1579  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 2000 / 5645.21875 ] loss :2.1210  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2100 / 5645.21875 ] loss :2.1115  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2200 / 5645.21875 ] loss :2.0711  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2300 / 5645.21875 ] loss :2.1769  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 2400 / 5645.21875 ] loss :2.1980  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2500 / 5645.21875 ] loss :2.2360  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2600 / 5645.21875 ] loss :2.0443  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2700 / 5645.21875 ] loss :2.0456  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2800 / 5645.21875 ] loss :2.1884  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2900 / 5645.21875 ] loss :2.3737  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3000 / 5645.21875 ] loss :1.7559  , accuracy:  0.875 true nums: 8  ration : 0.125 acc : 0.875  f1 : 0.0
[ 1 : 3100 / 5645.21875 ] loss :1.8735  , accuracy:  0.859375 true nums: 9  ration : 0.140625 acc : 0.859375  f1 : 0.0
[ 1 : 3200 / 5645.21875 ] loss :2.1177  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3300 / 5645.21875 ] loss :2.4945  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 3400 / 5645.21875 ] loss :2.5262  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 3500 / 5645.21875 ] loss :2.0272  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 3600 / 5645.21875 ] loss :2.4105  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 3700 / 5645.21875 ] loss :2.2619  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 3800 / 5645.21875 ] loss :2.3519  , accuracy:  0.734375 true nums: 16  ration : 0.25 acc : 0.734375  f1 : 0.0
[ 1 : 3900 / 5645.21875 ] loss :2.7305  , accuracy:  0.671875 true nums: 21  ration : 0.328125 acc : 0.671875  f1 : 0.0
[ 1 : 4000 / 5645.21875 ] loss :2.2147  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4100 / 5645.21875 ] loss :2.1305  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 4200 / 5645.21875 ] loss :2.1560  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4300 / 5645.21875 ] loss :2.0394  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4400 / 5645.21875 ] loss :2.3601  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 4500 / 5645.21875 ] loss :2.1668  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4600 / 5645.21875 ] loss :2.0843  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 4700 / 5645.21875 ] loss :2.3748  , accuracy:  0.75 true nums: 17  ration : 0.265625 acc : 0.75  f1 : 0.1111111111111111
[ 1 : 4800 / 5645.21875 ] loss :2.2579  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 4900 / 5645.21875 ] loss :2.0094  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 5000 / 5645.21875 ] loss :2.3692  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 5100 / 5645.21875 ] loss :2.1572  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 5200 / 5645.21875 ] loss :2.2959  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 5300 / 5645.21875 ] loss :2.1733  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 5400 / 5645.21875 ] loss :2.2782  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 5500 / 5645.21875 ] loss :2.1388  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 5600 / 5645.21875 ] loss :2.2873  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
开始验证。。。
/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
Epoch:  25%|██▌       | 1/4 [51:24<2:34:13, 3084.48s/it]0 / 1411 tensor(2.1696, device='cuda:0')
100 / 1411 tensor(2.4016, device='cuda:0')
200 / 1411 tensor(1.9751, device='cuda:0')
300 / 1411 tensor(1.8495, device='cuda:0')
400 / 1411 tensor(2.1015, device='cuda:0')
500 / 1411 tensor(2.4198, device='cuda:0')
600 / 1411 tensor(2.3048, device='cuda:0')
700 / 1411 tensor(1.7252, device='cuda:0')
800 / 1411 tensor(2.2341, device='cuda:0')
900 / 1411 tensor(1.7955, device='cuda:0')
1000 / 1411 tensor(2.6561, device='cuda:0')
1100 / 1411 tensor(2.2868, device='cuda:0')
1200 / 1411 tensor(2.1121, device='cuda:0')
1300 / 1411 tensor(1.9642, device='cuda:0')
1400 / 1411 tensor(2.6489, device='cuda:0')
验证结束，开始计算指标 3068.0729978084564
***** Eval results  *****
验证结果 ： {'acc': 0.7590582919914954, 'f1': 0.0, 'acc_and_f1': 0.3795291459957477}
Saving model checkpoint to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
Saving optimizer and scheduler states to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
[ 1 : 0 / 5645.21875 ] loss :2.3487  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 100 / 5645.21875 ] loss :2.2865  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 200 / 5645.21875 ] loss :2.2753  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 300 / 5645.21875 ] loss :2.3346  , accuracy:  0.703125 true nums: 17  ration : 0.265625 acc : 0.703125  f1 : 0.0
[ 1 : 400 / 5645.21875 ] loss :2.3711  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 500 / 5645.21875 ] loss :1.7074  , accuracy:  0.859375 true nums: 9  ration : 0.140625 acc : 0.859375  f1 : 0.0
[ 1 : 600 / 5645.21875 ] loss :2.3428  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 700 / 5645.21875 ] loss :2.0431  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 800 / 5645.21875 ] loss :2.2964  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 900 / 5645.21875 ] loss :2.0875  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 1000 / 5645.21875 ] loss :2.1266  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 1100 / 5645.21875 ] loss :1.9967  , accuracy:  0.84375 true nums: 10  ration : 0.15625 acc : 0.84375  f1 : 0.0
[ 1 : 1200 / 5645.21875 ] loss :2.1196  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 1300 / 5645.21875 ] loss :1.9702  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 1400 / 5645.21875 ] loss :2.7413  , accuracy:  0.65625 true nums: 22  ration : 0.34375 acc : 0.65625  f1 : 0.0
[ 1 : 1500 / 5645.21875 ] loss :2.0394  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 1600 / 5645.21875 ] loss :2.2163  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1700 / 5645.21875 ] loss :1.9769  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 1800 / 5645.21875 ] loss :2.2641  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1900 / 5645.21875 ] loss :2.0781  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2000 / 5645.21875 ] loss :2.0082  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2100 / 5645.21875 ] loss :2.3157  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2200 / 5645.21875 ] loss :2.0234  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 2300 / 5645.21875 ] loss :2.6670  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 2400 / 5645.21875 ] loss :2.2112  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 2500 / 5645.21875 ] loss :2.2255  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2600 / 5645.21875 ] loss :1.9162  , accuracy:  0.84375 true nums: 10  ration : 0.15625 acc : 0.84375  f1 : 0.0
[ 1 : 2700 / 5645.21875 ] loss :2.5437  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 2800 / 5645.21875 ] loss :2.3853  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 2900 / 5645.21875 ] loss :2.0940  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 3000 / 5645.21875 ] loss :2.3997  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 3100 / 5645.21875 ] loss :2.2795  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3200 / 5645.21875 ] loss :2.3767  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 3300 / 5645.21875 ] loss :2.3296  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 3400 / 5645.21875 ] loss :2.1480  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 3500 / 5645.21875 ] loss :2.2009  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3600 / 5645.21875 ] loss :2.1972  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 3700 / 5645.21875 ] loss :1.9731  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 3800 / 5645.21875 ] loss :2.2043  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3900 / 5645.21875 ] loss :2.1646  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 4000 / 5645.21875 ] loss :2.1692  , accuracy:  0.796875 true nums: 14  ration : 0.21875 acc : 0.796875  f1 : 0.13333333333333333
[ 1 : 4100 / 5645.21875 ] loss :2.3897  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 4200 / 5645.21875 ] loss :2.3854  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 4300 / 5645.21875 ] loss :2.3025  , accuracy:  0.734375 true nums: 15  ration : 0.234375 acc : 0.734375  f1 : 0.0
[ 1 : 4400 / 5645.21875 ] loss :2.2635  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 4500 / 5645.21875 ] loss :2.4628  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 4600 / 5645.21875 ] loss :2.4640  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 4700 / 5645.21875 ] loss :2.3090  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 4800 / 5645.21875 ] loss :2.1253  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4900 / 5645.21875 ] loss :2.0615  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 5000 / 5645.21875 ] loss :1.9304  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 5100 / 5645.21875 ] loss :2.0208  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 5200 / 5645.21875 ] loss :2.5200  , accuracy:  0.703125 true nums: 19  ration : 0.296875 acc : 0.703125  f1 : 0.0
[ 1 : 5300 / 5645.21875 ] loss :2.3320  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 5400 / 5645.21875 ] loss :2.2192  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 5500 / 5645.21875 ] loss :1.7558  , accuracy:  0.875 true nums: 8  ration : 0.125 acc : 0.875  f1 : 0.0
[ 1 : 5600 / 5645.21875 ] loss :2.1654  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
开始验证。。。
Epoch:  50%|█████     | 2/4 [1:42:57<1:42:59, 3089.72s/it]0 / 1411 tensor(2.5364, device='cuda:0')
100 / 1411 tensor(2.0366, device='cuda:0')
200 / 1411 tensor(2.3484, device='cuda:0')
300 / 1411 tensor(2.4301, device='cuda:0')
400 / 1411 tensor(2.8920, device='cuda:0')
500 / 1411 tensor(2.6651, device='cuda:0')
600 / 1411 tensor(2.3888, device='cuda:0')
700 / 1411 tensor(1.8394, device='cuda:0')
800 / 1411 tensor(2.1117, device='cuda:0')
900 / 1411 tensor(2.9799, device='cuda:0')
1000 / 1411 tensor(2.3901, device='cuda:0')
1100 / 1411 tensor(1.9800, device='cuda:0')
1200 / 1411 tensor(1.9787, device='cuda:0')
1300 / 1411 tensor(2.3870, device='cuda:0')
1400 / 1411 tensor(2.2765, device='cuda:0')
验证结束，开始计算指标 3133.4098271131516
***** Eval results  *****
验证结果 ： {'acc': 0.7590472182849043, 'f1': 0.0, 'acc_and_f1': 0.37952360914245215}
Saving model checkpoint to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
Saving optimizer and scheduler states to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
[ 1 : 0 / 5645.21875 ] loss :2.0883  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 100 / 5645.21875 ] loss :2.1186  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 200 / 5645.21875 ] loss :2.6646  , accuracy:  0.65625 true nums: 22  ration : 0.34375 acc : 0.65625  f1 : 0.0
[ 1 : 300 / 5645.21875 ] loss :2.3673  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 400 / 5645.21875 ] loss :1.6570  , accuracy:  0.875 true nums: 8  ration : 0.125 acc : 0.875  f1 : 0.0
[ 1 : 500 / 5645.21875 ] loss :2.1442  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 600 / 5645.21875 ] loss :2.2598  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 700 / 5645.21875 ] loss :2.3759  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 800 / 5645.21875 ] loss :2.3337  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 900 / 5645.21875 ] loss :2.0342  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 1000 / 5645.21875 ] loss :2.1374  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 1100 / 5645.21875 ] loss :2.1314  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 1200 / 5645.21875 ] loss :1.7869  , accuracy:  0.859375 true nums: 9  ration : 0.140625 acc : 0.859375  f1 : 0.0
[ 1 : 1300 / 5645.21875 ] loss :2.1737  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1400 / 5645.21875 ] loss :2.1725  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 1500 / 5645.21875 ] loss :2.1467  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 1600 / 5645.21875 ] loss :2.2967  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 1700 / 5645.21875 ] loss :2.0657  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1800 / 5645.21875 ] loss :2.3044  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 1900 / 5645.21875 ] loss :2.0300  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 2000 / 5645.21875 ] loss :2.3832  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 2100 / 5645.21875 ] loss :2.1419  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2200 / 5645.21875 ] loss :2.1201  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 2300 / 5645.21875 ] loss :2.5336  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 2400 / 5645.21875 ] loss :2.0759  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 2500 / 5645.21875 ] loss :2.0020  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 2600 / 5645.21875 ] loss :2.0033  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 2700 / 5645.21875 ] loss :2.2806  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
[ 1 : 2800 / 5645.21875 ] loss :2.0480  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 2900 / 5645.21875 ] loss :2.1567  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3000 / 5645.21875 ] loss :2.0117  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 3100 / 5645.21875 ] loss :2.3508  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 3200 / 5645.21875 ] loss :2.4568  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 3300 / 5645.21875 ] loss :2.3701  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 3400 / 5645.21875 ] loss :2.1128  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 3500 / 5645.21875 ] loss :2.1898  , accuracy:  0.765625 true nums: 15  ration : 0.234375 acc : 0.765625  f1 : 0.0
[ 1 : 3600 / 5645.21875 ] loss :2.3060  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 3700 / 5645.21875 ] loss :2.2358  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 3800 / 5645.21875 ] loss :2.3967  , accuracy:  0.6875 true nums: 20  ration : 0.3125 acc : 0.6875  f1 : 0.0
[ 1 : 3900 / 5645.21875 ] loss :2.2931  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4000 / 5645.21875 ] loss :2.1644  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 4100 / 5645.21875 ] loss :2.0114  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 4200 / 5645.21875 ] loss :2.0906  , accuracy:  0.796875 true nums: 13  ration : 0.203125 acc : 0.796875  f1 : 0.0
[ 1 : 4300 / 5645.21875 ] loss :2.1353  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4400 / 5645.21875 ] loss :2.9598  , accuracy:  0.578125 true nums: 27  ration : 0.421875 acc : 0.578125  f1 : 0.0
[ 1 : 4500 / 5645.21875 ] loss :2.3611  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 4600 / 5645.21875 ] loss :1.9889  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 4700 / 5645.21875 ] loss :2.1083  , accuracy:  0.78125 true nums: 14  ration : 0.21875 acc : 0.78125  f1 : 0.0
[ 1 : 4800 / 5645.21875 ] loss :1.9634  , accuracy:  0.828125 true nums: 11  ration : 0.171875 acc : 0.828125  f1 : 0.0
[ 1 : 4900 / 5645.21875 ] loss :2.7239  , accuracy:  0.59375 true nums: 26  ration : 0.40625 acc : 0.59375  f1 : 0.0
[ 1 : 5000 / 5645.21875 ] loss :1.9972  , accuracy:  0.8125 true nums: 12  ration : 0.1875 acc : 0.8125  f1 : 0.0
[ 1 : 5100 / 5645.21875 ] loss :2.5522  , accuracy:  0.671875 true nums: 21  ration : 0.328125 acc : 0.671875  f1 : 0.0
[ 1 : 5200 / 5645.21875 ] loss :2.2425  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 5300 / 5645.21875 ] loss :2.4050  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 5400 / 5645.21875 ] loss :2.3061  , accuracy:  0.75 true nums: 16  ration : 0.25 acc : 0.75  f1 : 0.0
[ 1 : 5500 / 5645.21875 ] loss :2.3618  , accuracy:  0.71875 true nums: 18  ration : 0.28125 acc : 0.71875  f1 : 0.0
[ 1 : 5600 / 5645.21875 ] loss :2.3380  , accuracy:  0.734375 true nums: 17  ration : 0.265625 acc : 0.734375  f1 : 0.0
开始验证。。。
Epoch:  75%|███████▌  | 3/4 [2:34:33<51:32, 3092.48s/it]  0 / 1411 tensor(1.7580, device='cuda:0')
100 / 1411 tensor(2.2183, device='cuda:0')
200 / 1411 tensor(2.2648, device='cuda:0')
300 / 1411 tensor(1.7739, device='cuda:0')
400 / 1411 tensor(2.5244, device='cuda:0')
500 / 1411 tensor(2.1763, device='cuda:0')
600 / 1411 tensor(2.1973, device='cuda:0')
700 / 1411 tensor(1.8243, device='cuda:0')
800 / 1411 tensor(2.3890, device='cuda:0')
900 / 1411 tensor(2.2690, device='cuda:0')
1000 / 1411 tensor(2.0119, device='cuda:0')
1100 / 1411 tensor(1.5409, device='cuda:0')
1200 / 1411 tensor(2.2492, device='cuda:0')
1300 / 1411 tensor(2.4407, device='cuda:0')
1400 / 1411 tensor(2.9003, device='cuda:0')
验证结束，开始计算指标 3090.590757369995
***** Eval results  *****
验证结果 ： {'acc': 0.7590582919914954, 'f1': 0.00036754571349811627, 'acc_and_f1': 0.37971291885249675}
Saving model checkpoint to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
Saving optimizer and scheduler states to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-last
Saving model checkpoint to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-best
Saving optimizer and scheduler states to %s /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-best
