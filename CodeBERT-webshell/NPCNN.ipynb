{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow版本代码 用来做验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# \n",
    "\n",
    "# from keras.utils import to_categorical#transform one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial = tf.constant(0.1,shape=[100])\n",
    "initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1=tf.constant(2.0,shape=[32,1,1,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 40, 300, 1) (3, 300, 1, 100)\n",
      "(32, 38, 1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 38, 1, 100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = np.array([[\n",
    "  [[2], [1], [2], [0], [1]],\n",
    "  [[1], [3], [2], [2], [3]],\n",
    "  [[1], [1], [3], [3], [0]],\n",
    "  [[2], [2], [0], [1], [1]],\n",
    "  [[0], [0], [3], [1], [2]], ]])\n",
    "kernel_in = np.array([\n",
    " [ [[2, 0.1,2,2,2]], [[3, 0.2,2,2,2]] ],\n",
    " [ [[0, 0.3,2,2,2]],[[1, 0.4,2,2,2]] ], ])\n",
    "input1 = tf.constant(1,shape=[32,40,300,1], dtype=tf.float32)\n",
    "kernel = tf.constant(0.1,shape=[3,300,1,100], dtype=tf.float32)\n",
    "print(x.shape,kernel.shape)\n",
    "out1=tf.nn.conv2d(input1, kernel, strides=[1, 1, 1, 1], padding='VALID')+initial\n",
    "print(out1.shape)\n",
    "h_conv1=tf.nn.relu(out1)\n",
    "h_conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 1, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_poo11 = tf.nn.max_pool(h_conv1,ksize=[1,input1.shape[1]-3+1,1,1],strides=[1,1,1,1],padding='VALID')\n",
    "h_poo11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = tf.concat([output1,h_poo11],axis=3) #把卷积核得出的特征向量连接起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 1, 300])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 300, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2=tf.reshape(output1,[-1,8,300,1])\n",
    "input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for training\n",
      "(2108, 308) (2108, 100, 40) (2108,) (4206, 300)\n",
      "finish reading\n"
     ]
    }
   ],
   "source": [
    "#测试NPCNN_hdj的代码数据加载部分\n",
    "print(\"loading data for training\")\n",
    "test_num = 58\n",
    "X = pickle.load(open('/home/hdj/NPCNN_hdj/parameters.in','rb'))\n",
    "train_report,train_code,train_labels,W = X[0],X[1],X[2],X[3]\n",
    "embedding = nn.Embedding.from_pretrained(torch.tensor(W))#从已有的weight导入embedding\n",
    "train_code = embedding(torch.tensor(train_code))\n",
    "train_report =embedding(torch.tensor(train_report))\n",
    "print(train_code.shape,train_report.shape)\n",
    "#被废弃的效率极低的代码\n",
    "# train_report = np.array(train_report)\n",
    "# train_code = np.array(train_code)\n",
    "# train_labels = np.array(train_labels)\n",
    "# # train_labels = to_categorical(train_labels)\n",
    "# W = np.array(W)\n",
    "# print(np.array(train_report).shape, np.array(train_code).shape, np.array(train_labels).shape, np.array(W).shape)\n",
    "print(\"finish reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2108, 100, 40, 300]) torch.Size([2108, 308, 300])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding.from_pretrained(torch.tensor(W))\n",
    "train_code = embedding(torch.tensor(train_code))\n",
    "train_report =embedding(torch.tensor(train_report))\n",
    "print(train_code.shape,train_report.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这一步操作及其慢，需要优化\n",
    "W[[[[0,1]]]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2108, 308])\n"
     ]
    }
   ],
   "source": [
    "#测试torch的embedding使用\n",
    "embedding = nn.Embedding(4206, 300)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.tensor(train_report)\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2108, 100, 40, 300])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeTensor = torch.tensor(train_code)\n",
    "output=embedding(codeTensor)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2108, 308, 300])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=embedding(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_code[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_code[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_report[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_report[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code = W[train_code]\n",
    "train_report = W[train_report]\n",
    "print(np.array(train_code).shape,np.array(train_report).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading data for training\n",
    "(3292, 208) (3292, 50, 20) (3292,) (3578, 300)\n",
    "finish reading\n",
    "(3292, 50, 20, 300) (3292, 208, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这里使用CNN来进行code和report的编码 之后和codeBert的信息进行融合看能否得到提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义 code是两次卷积 report是一次卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "# from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, AdamW\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import (compute_metrics, convert_examples_to_features,\n",
    "                        output_modes, processors)\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "# from transformers import (WEIGHTS_NAME, get_linear_schedule_with_warmup, AdamW,\n",
    "#                           RobertaConfig,\n",
    "#                           RobertaForSequenceClassification,\n",
    "#                           RobertaTokenizer)\n",
    "from CodeBertModel import TextCNNClassifer\n",
    "import os\n",
    "# for i in range(58):\n",
    "#     os.system('python3 run_classifier.py --model_type roberta --model_name_or_path microsoft/codebert-base --task_name codesearch --do_predict --output_dir ../data/codesearch/test/ --data_dir ../data/codesearch/test/ --max_seq_length 512 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-5 --num_train_epochs 8 --test_file aspectj_'+str(i)+'.txt  --pred_model_dir ./models/java/checkpoint-best/ --test_result_dir ./results/java/batch_result_'+str(i)+'.txt')\n",
    "from more_itertools import chunked\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "def calculate_same_value(labels_sorted, test_p_sorted, start_pos):\n",
    "    i = start_pos\n",
    "    num_same = 0\n",
    "    num_p = 0\n",
    "    while test_p_sorted[start_pos] == test_p_sorted[i]:\n",
    "        num_same = num_same + 1\n",
    "        if labels_sorted[i] ==1 : num_p = num_p + 1\n",
    "        i = i + 1\n",
    "        if i == len(labels_sorted ): break\n",
    "    return num_p, num_same\n",
    "def eval_mrr(test_p, labels):#在第二维相似度得分，真实标签\n",
    "    test_p_sorted = test_p\n",
    "    test_p_index = sorted(range(len(test_p_sorted)), key=lambda k: test_p_sorted[k], reverse=True)  # 降序排序\n",
    "    test_p_sorted = sorted(test_p, reverse=True)\n",
    "\n",
    "    labels_sorted = []\n",
    "    for index in test_p_index:\n",
    "        labels_sorted.append(labels[index])\n",
    "\n",
    "    top_num = 10\n",
    "    top10rank = 0\n",
    "    for i in range(top_num):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            '''\n",
    "            num_p, num_s = calculate_same_value(labels_sorted, test_p_sorted, i)\n",
    "            num_r = top_num - i\n",
    "            if num_p > (num_s-num_r):\n",
    "                top10rank = 1\n",
    "                break\n",
    "            v1 = perm(num_s-num_r, num_p)*perm(num_s-num_p,num_s-num_p)\n",
    "            v2 = perm(num_s,num_s)\n",
    "            top10rank = 1-(float)((float)(v1)/(float)(v2))\n",
    "            if top10rank > 1: top10rank=1\n",
    "            if top10rank!=top10rank: top10rank=1\n",
    "            break\n",
    "\n",
    "    return top10rank\n",
    "\n",
    "    '''\n",
    "            top10rank = 1\n",
    "            break\n",
    "    num_p, num_s = calculate_same_value(labels_sorted, test_p_sorted, 10)\n",
    "    if (num_p >= 1): top10rank = 1  # 统计在第十位并列排名相同的文件中，是否含有相关文件\n",
    "\n",
    "    MRRrank = 0.0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            MRRrank = MRRrank + float(1 / (i + 1))\n",
    "            break\n",
    "\n",
    "    MAPrank = 0.0\n",
    "    pos_num = 0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            pos_num = pos_num + 1\n",
    "            MAPrank = MAPrank + float(pos_num / (i + 1))\n",
    "    if pos_num==0:\n",
    "        print('出现不存在pos的例子')\n",
    "        pos_num=1\n",
    "    MAPrank = float(MAPrank / pos_num)\n",
    "#     MRRrank = float(MRRrank / pos_num)\n",
    "    \n",
    "    return top10rank, MRRrank, MAPrank\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "#     print(type(preds),type(labels))\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc_and_f1(preds, labels):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"acc_and_f1\": (acc + f1) / 2,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "\n",
    "    return acc_and_f1(preds, labels)\n",
    "#设置种子，为了结果复现\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "def minibatches(inputs_x1 = None,inputs_x2 = None,targets = None,batch_size = None,shuffle = False):\n",
    "    if shuffle:#判断是否混合\n",
    "        indices = np.arange(len(inputs_x1))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0,len(inputs_x1)-batch_size+1,batch_size):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx+batch_size]\n",
    "        else:\n",
    "            excerpt = slice(start_idx,start_idx+batch_size)\n",
    "        yield inputs_x1[excerpt],inputs_x2[excerpt],targets[excerpt]\n",
    "\n",
    "def get_testsets(test_code,test_report,test_label):\n",
    "    code_x = test_code[0]\n",
    "    for i in range(300-1):\n",
    "        code_x = np.vstack((code_x,test_code[i+1]))\n",
    "    report_x = test_report\n",
    "    y = test_label\n",
    "    return code_x,report_x,y\n",
    "def calculate_same_value(labels_sorted, test_p_sorted, start_pos):\n",
    "    i = start_pos\n",
    "    num_same = 0\n",
    "    num_p = 0\n",
    "    while test_p_sorted[start_pos] == test_p_sorted[i]:\n",
    "        num_same = num_same + 1\n",
    "        if labels_sorted[i] ==1 : num_p = num_p + 1\n",
    "        i = i + 1\n",
    "        if i == len(labels_sorted ): break\n",
    "    return num_p, num_same\n",
    "\n",
    "def eval_y (test_p, labels ):\n",
    "    test_p_sorted = test_p\n",
    "    test_p_index = sorted(range(len(test_p_sorted)) ,key = lambda k: test_p_sorted[k], reverse =True )#降序排序\n",
    "    test_p_sorted = sorted(test_p, reverse = True)\n",
    "\n",
    "    labels_sorted = []\n",
    "    for index in test_p_index:\n",
    "        labels_sorted.append(labels[index])\n",
    "\n",
    "    top_num = 10\n",
    "    top10rank = 0\n",
    "    for i in range(top_num):\n",
    "        if(labels_sorted[i] ==1 ):\n",
    "            '''\n",
    "            num_p, num_s = calculate_same_value(labels_sorted, test_p_sorted, i)\n",
    "            num_r = top_num - i\n",
    "            if num_p > (num_s-num_r):\n",
    "                top10rank = 1\n",
    "                break\n",
    "            v1 = perm(num_s-num_r, num_p)*perm(num_s-num_p,num_s-num_p)\n",
    "            v2 = perm(num_s,num_s)\n",
    "            top10rank = 1-(float)((float)(v1)/(float)(v2))\n",
    "            if top10rank > 1: top10rank=1\n",
    "            if top10rank!=top10rank: top10rank=1\n",
    "            break\n",
    "\n",
    "    return top10rank\n",
    "\n",
    "    '''\n",
    "            top10rank = 1\n",
    "            break\n",
    "    num_p, num_s = calculate_same_value(labels_sorted,test_p_sorted,10)\n",
    "    if(num_p >=1 ): top10rank = 1 #统计在第十位并列排名相同的文件中，是否含有相关文件\n",
    "\n",
    "    MRRrank = 0.0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if( labels_sorted[i] == 1 ):\n",
    "            MRRrank = MRRrank +  float(1/(i+1))\n",
    "            break\n",
    "\n",
    "    MAPrank = 0.0\n",
    "    pos_num = 0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if( labels_sorted[i] == 1):\n",
    "            pos_num = pos_num + 1\n",
    "            MAPrank = MAPrank + float(pos_num/(i+1))\n",
    "    try:\n",
    "        MAPrank =  float(MAPrank/pos_num)\n",
    "    except:\n",
    "        print('出现pos_num为0的情况',pos_num)\n",
    "        return 1,1,1\n",
    "#     MRRrank = float(MRRrank/pos_num)\n",
    "   \n",
    "    return top10rank, MRRrank, MAPrank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 38, 1])\n"
     ]
    }
   ],
   "source": [
    "#测试torch代码所用\n",
    "# #输入[batch_size,in_channels,height,weight]\n",
    "# #输出 [batch_size,out_channles,H_out,W_out]\n",
    "# inputCode = torch.randn(32, 1, 40, 300)\n",
    "# conv2 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(3, 300), stride=(1, 1), bias=True)\n",
    "# out=conv2(inputCode)\n",
    "# print(out.shape)\n",
    "# # out\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "# outRelu=F.relu(out)\n",
    "# print(outRelu.shape)\n",
    "# # pool of square window of size=3, stride=2\n",
    "# # m = nn.MaxPool2d(3, stride=2)\n",
    "# # pool of non-square window\n",
    "# m = nn.MaxPool2d(kernel_size=(38, 1), stride=(1, 1))\n",
    "# input = torch.randn(32, 100, 38, 1)\n",
    "# output = m(input)\n",
    "# print(output.shape)\n",
    "# listOut=[output,output]\n",
    "# out = torch.cat(listOut, dim=1)\n",
    "# print(out.shape)\n",
    "# out = out.view(-1, 1, 8,200)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型配置和定义部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100\n"
     ]
    }
   ],
   "source": [
    "class TCNNConfig(object):\n",
    "    def __init__(self):\n",
    "        self.in_channels=1\n",
    "        self.out_channels=100\n",
    "        self.embedding_size=300\n",
    "        self.vocab_size=100\n",
    "        self.wordNums=40\n",
    "        self.codeLineNums=100\n",
    "        self.reportLineNums=308\n",
    "        self.window_sizes=[3,4,5]\n",
    "        self.num_class=2\n",
    "config=TCNNConfig()\n",
    "print(config.in_channels,config.out_channels)\n",
    "#torch \n",
    "'''\n",
    "in_channels(int) – 输入信号的通道\n",
    "out_channels(int) – 卷积产生的通道\n",
    "kerner_size(int or tuple) - 卷积核的尺寸\n",
    "stride(int or tuple, optional) - 卷积步长\n",
    "padding(int or tuple, optional) - 输入的每一条边补充0的层数\n",
    "dilation(int or tuple, optional) – 卷积核元素之间的间距\n",
    "groups(int, optional) – 从输入通道到输出通道的阻塞连接数\n",
    "bias(bool, optional) - 如果bias=True，添加偏置\n",
    "'''\n",
    "class CodeTextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CodeTextCNN, self).__init__()\n",
    "        self.config=config\n",
    "#         self.embedding = nn.Embedding(num_embeddings=config.vocab_size, embedding_dim=config.embedding_size)\n",
    "        #(32, 1, 40, 300)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                          nn.Conv2d(in_channels=config.in_channels, out_channels=config.out_channels, kernel_size=(h,config.embedding_size ), stride=(1, 1), bias=True),\n",
    "                          #                              nn.BatchNorm1d(num_features=config.feature_size),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(kernel_size=(config.wordNums-h+1, 1), stride=(1, 1))\n",
    "            )\n",
    "#                           nn.MaxPool1d(kernel_size=config.max_text_len - h + 1))\n",
    "            for h in config.window_sizes\n",
    "        ])\n",
    "        #(32, 1, 100,300)\n",
    "        self.convs_lines = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv2d(in_channels=config.in_channels, out_channels=config.out_channels, kernel_size=(h, config.out_channels*len(config.window_sizes)), stride=(1, 1), bias=True),\n",
    "                          #                              nn.BatchNorm1d(num_features=config.feature_size),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(kernel_size=(config.codeLineNums-h+1, 1), stride=(1, 1))\n",
    "                         )\n",
    "            for h in config.window_sizes\n",
    "        ])\n",
    "    \n",
    "        self.report_convs = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv2d(in_channels=config.in_channels, out_channels=config.out_channels, kernel_size=(h, config.embedding_size), stride=(1, 1), bias=True),\n",
    "                          #                              nn.BatchNorm1d(num_features=config.feature_size),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(kernel_size=(config.reportLineNums-h+1, 1), stride=(1, 1))\n",
    "                         )\n",
    "            for h in config.window_sizes\n",
    "        ])\n",
    "#         self.fc0=nn.Linear(in_features=config.out_channels*len(config.window_sizes)*2,out_features=config.out_channels*len(config.window_sizes)*2,bias=True)\n",
    "        self.fc1 = nn.Linear(in_features=config.out_channels*len(config.window_sizes) * 2,out_features=config.num_class,bias=True)\n",
    "#         self.fc0=nn.Linear(in_features=config.embedding_size*2,out_features=config.embedding_size*2,bias=True)\n",
    "#         self.fc1 = nn.Linear(in_features=config.embedding_size * 2,out_features=config.num_class,bias=True)\n",
    "#         self.drop=nn.Dropout(0.1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier=nn.Linear(in_features=768*2,out_features=config.num_class,bias=True)\n",
    "        # if os.path.exists(config.embedding_path) and config.is_training and config.is_pretrain:\n",
    "        # print(\"Loading pretrain embedding...\")\n",
    "        # self.embedding.weight.data.copy_(torch.from_numpy(np.load(config.embedding_path)))\n",
    "#         self.transformer=RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "    def forward(self, x_code,y_report,report_ids,report_mask,code_ids,code_mask):\n",
    "        #这是codeBert的编码\n",
    "#         h_report = self.transformer(input_ids=report_ids, attention_mask=report_mask)\n",
    "#         out_report=h_report[1]\n",
    "#         h_code = self.transformer(input_ids=code_ids, attention_mask=code_mask)\n",
    "#         out_code=h_code[1]\n",
    "# #         abs_dist = torch.abs(torch.add(out_report, -out_code))\n",
    "#         abs_dist=torch.cat((out_report,out_code),1)\n",
    "#         codeBertOut=self.classifier(abs_dist)\n",
    "#         return codeBertOut\n",
    "        #这是codeBert的编码\n",
    "        \n",
    "        # embed_x = self.embedding(x)self.out_channels\n",
    "        embed_x = x_code.view(-1,1,self.config.wordNums,config.embedding_size)#[32*100,40,300]-->[32*100,1,40,300]\n",
    "#         embed_y=y_report.view(-1,1,self.config.reportLineNums,config.out_channels*len(config.window_sizes))#[32,150,300]-->[32,1,150,300]\n",
    "#         embed_x = x_code.view(-1,1,self.config.wordNums,config.embedding_size)#[32*100,40,300]-->[32*100,1,40,300]\n",
    "        embed_y=y_report.view(-1,1,self.config.reportLineNums,config.embedding_size)#[32,150,300]-->[32,1,150,300]\n",
    "#         print('embed_x ',embed_x.shape,' embed_y ',embed_y.shape)\n",
    "        out = [conv(embed_x) for conv in self.convs]  #[32*100,1,40,300]--> [32*100,100,38,1]--->pool [32*100,100,1,1]\n",
    "        out = torch.cat(out, dim=1)\n",
    "#         print('code第一次拼接的shape',out.shape)#[32*100, 300, 1, 1]\n",
    "        out = out.view(-1, 1, config.codeLineNums,config.out_channels*len(config.window_sizes))#[32,1,100,300]\n",
    "#         out = out.view(-1, 1, config.codeLineNums,config.embedding_size)#[32,1,100,300]\n",
    "#         print('code第一次卷积',out.shape)\n",
    "\n",
    "        # 开始在行间做二次卷积\n",
    "        out2 = [conv(out) for conv in self.convs_lines]#[32,1,100,300]-->[32,100,98,1]-->pool[32,100,1,1]\n",
    "#         for o in out2:\n",
    "#             print('o2', o.size())  # ([32, 100, 1, 1])\n",
    "        outMerge = torch.cat(out2, dim=1)  # [32,300,1,1]\n",
    "#         print('code二次卷积size：',outMerge.size())  # [32,300,1,1]\n",
    "        \n",
    "        report_out = [conv(embed_y) for conv in self.report_convs]  # [32,1,150,300]-->[32,100,148,1]-->pool[32,100,1,1]\n",
    "        report_outMerge = torch.cat(report_out, dim=1)#[32,300,1,1]\n",
    "#         print('report 卷积size:',report_outMerge.size())\n",
    "        report_outMerge = report_outMerge.view(-1, report_outMerge.size(1))#\n",
    "        \n",
    "        outMerge = outMerge.view(-1, outMerge.size(1))\n",
    "#         print('code size report size : ',outMerge.size(),report_outMerge.size())#torch.Size([32, 300]) torch.Size([32, 300])\n",
    "        #合并code和report编码得到的向量\n",
    "        merge=torch.cat([outMerge,report_outMerge],dim=1)\n",
    "#         print('merge得到的size大小：',merge.shape)\n",
    "#         merge=self.drop(merge)\n",
    "#         output0=self.fc0(merge)\n",
    "        merge = self.dropout(merge)\n",
    "        output1=self.fc1(merge)\n",
    "#         print('fc后的输出size',output1.shape)\n",
    "        # if not self.use_element:\n",
    "        #     out2 = F.dropout(input=out2, p=self.dropout_rate)\n",
    "        #     out2 = self.fc(out2)\n",
    "#         return out2,report_out\n",
    "#         cos_simi=torch.mean(torch.cosine_similarity(outMerge, report_outMerge, dim=1))\n",
    "        return output1\n",
    "#         return outMerge,report_outMerge,output1\n",
    "model=CodeTextCNN(config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) tensor(0.3583) tensor([ 9.5252e-04, -7.2193e-01,  2.1057e-01,  9.7696e-01,  8.7698e-01,\n",
      "         9.3521e-01,  6.4361e-01, -5.6055e-02])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(8, 2)\n",
    "input2 = torch.randn(8, 2)\n",
    "cos_simi=torch.cosine_similarity(input1, input2, dim=1)\n",
    "mean_cos_simi=torch.mean(cos_simi)\n",
    "print(cos_simi.shape,mean_cos_simi,cos_simi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_type = 'roberta'\n",
    "        self.output_dir='/data/hdj/data/CodeBERT/codesearch/models/java'\n",
    "        self.test_result_dir='/data/hdj/data/CodeBERT/codesearch/results/java/test_v1_0414.txt'\n",
    "        self.start_epoch=0\n",
    "        self.num_train_epochs=1\n",
    "        self.model_type='roberta'\n",
    "        self.config_name=''\n",
    "        self.model_name_or_path=None\n",
    "        self.task_name='codesearch'\n",
    "        self.tokenizer_name=''\n",
    "        self.model_name_or_path='microsoft/codebert-base'\n",
    "        self.do_lower_case=True\n",
    "        self.seed=42\n",
    "        self.gradient_accumulation_steps=1\n",
    "        self.weight_decay=0.0\n",
    "        self.max_grad_norm=1.0\n",
    "        self.learning_rate=1e-4\n",
    "        self.adam_epsilon=1e-8\n",
    "        self.warmup_steps=0\n",
    "        self.max_steps=-1\n",
    "        self.num_train_epochs=6\n",
    "# class args(object):\n",
    "#     \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.model_type = 'codesearch'\n",
    "#         self.output_dir='/data/hdj/data/CodeBERT/codesearch/models/java'\n",
    "#         self.test_result_dir='/data/hdj/data/CodeBERT/codesearch/results/java/test_v1_0414.txt'\n",
    "#         self.start_epoch=0\n",
    "#         self.num_train_epochs=1\n",
    "#         self.model_type='roberta'\n",
    "args=args()\n",
    "#带权重的交叉熵\n",
    "# weights=torch.tensor([0.2,0.8]).cuda()\n",
    "# loss_fun=CrossEntropyLoss(weight=weights)\n",
    "#更换损失函数\n",
    "# lossRankFunction = nn.MarginRankingLoss()\n",
    "#不带权重的交叉熵\n",
    "loss_fun=CrossEntropyLoss()\n",
    "#设置种子 复现结果\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (WEIGHTS_NAME, get_linear_schedule_with_warmup, AdamW)\n",
    "early_stop=3\n",
    "eval_loss=0.0\n",
    "\n",
    "\n",
    "if  True:\n",
    "    #Google: 使用的优化器和迭代器\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    #Google\n",
    "else:\n",
    "#     hdj: textCNNClassifier 使用的优化器和计划器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-04)#, betas=(0.9, 0.999)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "#     hdj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('report shape :',train_x2.shape,' code shape:',train_x1.shape,' train_labels shape:',torch.tensor(train_labels).shape,' embedding shape:',embedding.num_embeddings)\n",
    "# #15:40--16:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要为数据的code生成文本形式\n",
    "def code_merge(raw_code_list):\n",
    "    code_list=[]\n",
    "    for raw_code in raw_code_list:\n",
    "        code_list.append(raw_code['text'])\n",
    "    code_text=' '.join(code_list)\n",
    "    return code_text\n",
    "\n",
    "def data_tensor_generate(data,project,tokenizer,maxLength=512,ttype='train'):\n",
    "    '''\n",
    "        输入是dataframe 包含bug_id\tcnn_report_idx\tcode_idx\tlabel\tpath\traw_report\traw_code\n",
    "    '''\n",
    "    #将raw_code里dict形式合并生成code_text\n",
    "    data['raw_code_text']=data['raw_code'].apply(code_merge)\n",
    "    #生成完成\n",
    "    all_labels=list(data['label'])\n",
    "    all_cnn_report_idx=list(data['cnn_report_idx'])\n",
    "    all_code_idx=list(data['code_idx'])\n",
    "    raw_report=list(data['raw_report'])\n",
    "    raw_code=list(data['raw_code_text'])\n",
    "#     reportInputs=tokenizer.batch_encode_plus(raw_report,add_special_tokens=True,max_length=maxLength,pad_to_max_length=True,return_token_type_ids=True,truncation=True)\n",
    "#     codeInputs=tokenizer.batch_encode_plus(raw_code,add_special_tokens=True,max_length=maxLength,pad_to_max_length=True,return_token_type_ids=True,truncation=True)\n",
    "#     all_report_input_ids=reportInputs['input_ids']\n",
    "#     all_report_input_mask=reportInputs['attention_mask']\n",
    "#     all_code_input_ids=codeInputs['input_ids']\n",
    "#     all_code_input_mask=codeInputs['attention_mask']\n",
    "    all_report_input_ids=[[0]for i in range(len(raw_code))]\n",
    "    all_report_input_mask=[[0]for i in range(len(raw_code))]\n",
    "    all_code_input_ids=[[0]for i in range(len(raw_code))]\n",
    "    all_code_input_mask=[[0]for i in range(len(raw_code))]\n",
    "    all_report_input_ids = torch.tensor(all_report_input_ids, dtype=torch.long)\n",
    "    all_report_input_mask = torch.tensor(all_report_input_mask, dtype=torch.long)\n",
    "    all_code_input_ids = torch.tensor(all_code_input_ids, dtype=torch.long)\n",
    "    all_code_input_mask = torch.tensor(all_code_input_mask, dtype=torch.long)\n",
    "    \n",
    "    all_cnn_report_idx=torch.tensor(all_cnn_report_idx, dtype=torch.long)\n",
    "    all_code_idx=torch.tensor(all_code_idx, dtype=torch.long)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.long)\n",
    "    pickle.dump([all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels],open(\"/data/hdj/cross_project_trans/encode_data/\"+project+\"parameters_\"+ttype+\".in\", \"wb\"),protocol = 4)\n",
    "    dataset = TensorDataset(all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels)\n",
    "#     if ttype=='train':\n",
    "    return dataset\n",
    "#     else:\n",
    "#         return dataset,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, AdamW\n",
    "project='swt_'\n",
    "more_train_data=pd.read_pickle('/data/hdj/cross_project_trans/report/bert/'+project+'more_train_data.pkl')\n",
    "# swt_more_train_data=pd.read_pickle('/home/hdj/cross_project_trans/report/swt_more_train_data.pkl')\n",
    "# zxing_more_train_data=pd.read_pickle('/home/hdj/cross_project_trans/report/zxing_more_train_data.pkl')\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "# project='aspectj_'\n",
    "# project='swt_'\n",
    "# project='zxing_'\n",
    "train_set=data_tensor_generate(more_train_data,project,tokenizer=None,maxLength=256)\n",
    "batch_size=8\n",
    "training_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
    "    #\n",
    "# raw_report[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "training_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21384, 1]),\n",
       " torch.Size([21384, 1]),\n",
       " torch.Size([21384, 1]),\n",
       " torch.Size([21384, 1]),\n",
       " torch.Size([21384, 308]),\n",
       " torch.Size([21384, 100, 40]),\n",
       " torch.Size([21384]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #直接从保存的文件里读取train和test数据\n",
    "batch_size=32\n",
    "aspectj_train = pickle.load(open('/data/hdj/cross_project_trans/encode_data/'+project+'parameters_train.in','rb'))\n",
    "all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,all_code_idx, all_labels=aspectj_train[0],aspectj_train[1],aspectj_train[2],aspectj_train[3],aspectj_train[4],aspectj_train[5],aspectj_train[6]\n",
    "train_set = TensorDataset(all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels)\n",
    "training_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "train_set.tensors[0].shape,train_set.tensors[1].shape,train_set.tensors[2].shape,train_set.tensors[3].shape,train_set.tensors[4].shape,train_set.tensors[5].shape,train_set.tensors[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.MarginRankingLoss()\n",
    "# input1 = torch.tensor([[1.0,2.0,3.0]], requires_grad=True)\n",
    "# input2 = torch.tensor([[4.0,5.0,6.0]], requires_grad=True)\n",
    "# print(input1)\n",
    "# print(input2)\n",
    "# # target = torch.randn(3).sign()\n",
    "# target=torch.tensor([[1]])\n",
    "# output = loss(input1, input2, target)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 : 0 / 668.25 ] loss :0.5663  , accuracy:  0.75 true nums: 5  ration : 0.15625 acc : 0.75  f1 : 0.0\n",
      "[ 0 : 20 / 668.25 ] loss :0.5152  , accuracy:  0.78125 true nums: 7  ration : 0.21875 acc : 0.78125  f1 : 0.36363636363636365\n",
      "[ 0 : 40 / 668.25 ] loss :0.5361  , accuracy:  0.65625 true nums: 10  ration : 0.3125 acc : 0.65625  f1 : 0.0\n",
      "[ 0 : 60 / 668.25 ] loss :0.4456  , accuracy:  0.8125 true nums: 10  ration : 0.3125 acc : 0.8125  f1 : 0.5714285714285715\n",
      "[ 0 : 80 / 668.25 ] loss :0.4698  , accuracy:  0.78125 true nums: 6  ration : 0.1875 acc : 0.78125  f1 : 0.2222222222222222\n",
      "[ 0 : 100 / 668.25 ] loss :0.6273  , accuracy:  0.6875 true nums: 12  ration : 0.375 acc : 0.6875  f1 : 0.2857142857142857\n",
      "[ 0 : 120 / 668.25 ] loss :0.5200  , accuracy:  0.84375 true nums: 4  ration : 0.125 acc : 0.84375  f1 : 0.28571428571428575\n",
      "[ 0 : 140 / 668.25 ] loss :0.6753  , accuracy:  0.6875 true nums: 11  ration : 0.34375 acc : 0.6875  f1 : 0.28571428571428575\n",
      "[ 0 : 160 / 668.25 ] loss :0.5703  , accuracy:  0.6875 true nums: 9  ration : 0.28125 acc : 0.6875  f1 : 0.0\n",
      "[ 0 : 180 / 668.25 ] loss :0.4191  , accuracy:  0.84375 true nums: 4  ration : 0.125 acc : 0.84375  f1 : 0.0\n",
      "[ 0 : 200 / 668.25 ] loss :0.4874  , accuracy:  0.78125 true nums: 10  ration : 0.3125 acc : 0.78125  f1 : 0.4615384615384615\n",
      "[ 0 : 220 / 668.25 ] loss :0.4919  , accuracy:  0.8125 true nums: 9  ration : 0.28125 acc : 0.8125  f1 : 0.5714285714285714\n",
      "[ 0 : 240 / 668.25 ] loss :0.2982  , accuracy:  0.90625 true nums: 5  ration : 0.15625 acc : 0.90625  f1 : 0.5714285714285715\n",
      "[ 0 : 260 / 668.25 ] loss :0.3407  , accuracy:  0.8125 true nums: 5  ration : 0.15625 acc : 0.8125  f1 : 0.0\n",
      "[ 0 : 280 / 668.25 ] loss :0.4827  , accuracy:  0.75 true nums: 7  ration : 0.21875 acc : 0.75  f1 : 0.3333333333333333\n",
      "[ 0 : 300 / 668.25 ] loss :0.4987  , accuracy:  0.8125 true nums: 9  ration : 0.28125 acc : 0.8125  f1 : 0.5\n",
      "[ 0 : 320 / 668.25 ] loss :0.4530  , accuracy:  0.78125 true nums: 5  ration : 0.15625 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 0 : 340 / 668.25 ] loss :0.5210  , accuracy:  0.78125 true nums: 10  ration : 0.3125 acc : 0.78125  f1 : 0.588235294117647\n",
      "[ 0 : 360 / 668.25 ] loss :0.3322  , accuracy:  0.875 true nums: 2  ration : 0.0625 acc : 0.875  f1 : 0.3333333333333333\n",
      "[ 0 : 380 / 668.25 ] loss :0.4805  , accuracy:  0.78125 true nums: 10  ration : 0.3125 acc : 0.78125  f1 : 0.5333333333333333\n",
      "[ 0 : 400 / 668.25 ] loss :0.4546  , accuracy:  0.8125 true nums: 9  ration : 0.28125 acc : 0.8125  f1 : 0.5\n",
      "[ 0 : 420 / 668.25 ] loss :0.6558  , accuracy:  0.625 true nums: 11  ration : 0.34375 acc : 0.625  f1 : 0.0\n",
      "[ 0 : 440 / 668.25 ] loss :0.5502  , accuracy:  0.6875 true nums: 12  ration : 0.375 acc : 0.6875  f1 : 0.375\n",
      "[ 0 : 460 / 668.25 ] loss :0.5664  , accuracy:  0.71875 true nums: 10  ration : 0.3125 acc : 0.71875  f1 : 0.30769230769230765\n",
      "[ 0 : 480 / 668.25 ] loss :0.3271  , accuracy:  0.9375 true nums: 3  ration : 0.09375 acc : 0.9375  f1 : 0.5\n",
      "[ 0 : 500 / 668.25 ] loss :0.4300  , accuracy:  0.84375 true nums: 8  ration : 0.25 acc : 0.84375  f1 : 0.5454545454545454\n",
      "[ 0 : 520 / 668.25 ] loss :0.4229  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.4444444444444444\n",
      "[ 0 : 540 / 668.25 ] loss :0.4477  , accuracy:  0.8125 true nums: 8  ration : 0.25 acc : 0.8125  f1 : 0.5\n",
      "[ 0 : 560 / 668.25 ] loss :0.4074  , accuracy:  0.78125 true nums: 7  ration : 0.21875 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 0 : 580 / 668.25 ] loss :0.6252  , accuracy:  0.625 true nums: 12  ration : 0.375 acc : 0.625  f1 : 0.0\n",
      "[ 0 : 600 / 668.25 ] loss :0.3528  , accuracy:  0.84375 true nums: 5  ration : 0.15625 acc : 0.84375  f1 : 0.28571428571428575\n",
      "[ 0 : 620 / 668.25 ] loss :0.5412  , accuracy:  0.75 true nums: 10  ration : 0.3125 acc : 0.75  f1 : 0.33333333333333337\n",
      "[ 0 : 640 / 668.25 ] loss :0.3892  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.4444444444444444\n",
      "[ 0 : 660 / 668.25 ] loss :0.6207  , accuracy:  0.71875 true nums: 7  ration : 0.21875 acc : 0.71875  f1 : 0.30769230769230765\n",
      "0 509.71875 668 0.7630520209580839 0.27897469730539426\n",
      "[ 1 : 0 / 668.25 ] loss :0.4528  , accuracy:  0.8125 true nums: 8  ration : 0.25 acc : 0.8125  f1 : 0.4\n",
      "[ 1 : 20 / 668.25 ] loss :0.4409  , accuracy:  0.875 true nums: 8  ration : 0.25 acc : 0.875  f1 : 0.6666666666666666\n",
      "[ 1 : 40 / 668.25 ] loss :0.3915  , accuracy:  0.875 true nums: 5  ration : 0.15625 acc : 0.875  f1 : 0.5\n",
      "[ 1 : 60 / 668.25 ] loss :0.5352  , accuracy:  0.8125 true nums: 7  ration : 0.21875 acc : 0.8125  f1 : 0.4\n",
      "[ 1 : 80 / 668.25 ] loss :0.6380  , accuracy:  0.65625 true nums: 16  ration : 0.5 acc : 0.65625  f1 : 0.47619047619047616\n",
      "[ 1 : 100 / 668.25 ] loss :0.4935  , accuracy:  0.75 true nums: 7  ration : 0.21875 acc : 0.75  f1 : 0.0\n",
      "[ 1 : 120 / 668.25 ] loss :0.4168  , accuracy:  0.875 true nums: 6  ration : 0.1875 acc : 0.875  f1 : 0.6\n",
      "[ 1 : 140 / 668.25 ] loss :0.5918  , accuracy:  0.75 true nums: 9  ration : 0.28125 acc : 0.75  f1 : 0.19999999999999998\n",
      "[ 1 : 160 / 668.25 ] loss :0.4407  , accuracy:  0.75 true nums: 7  ration : 0.21875 acc : 0.75  f1 : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1465: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 : 180 / 668.25 ] loss :0.3823  , accuracy:  0.8125 true nums: 6  ration : 0.1875 acc : 0.8125  f1 : 0.25\n",
      "[ 1 : 200 / 668.25 ] loss :0.4018  , accuracy:  0.8125 true nums: 6  ration : 0.1875 acc : 0.8125  f1 : 0.4\n",
      "[ 1 : 220 / 668.25 ] loss :0.4476  , accuracy:  0.75 true nums: 10  ration : 0.3125 acc : 0.75  f1 : 0.5\n",
      "[ 1 : 240 / 668.25 ] loss :0.4923  , accuracy:  0.75 true nums: 11  ration : 0.34375 acc : 0.75  f1 : 0.42857142857142855\n",
      "[ 1 : 260 / 668.25 ] loss :0.3962  , accuracy:  0.8125 true nums: 9  ration : 0.28125 acc : 0.8125  f1 : 0.5\n",
      "[ 1 : 280 / 668.25 ] loss :0.5408  , accuracy:  0.71875 true nums: 12  ration : 0.375 acc : 0.71875  f1 : 0.47058823529411764\n",
      "[ 1 : 300 / 668.25 ] loss :0.5278  , accuracy:  0.78125 true nums: 5  ration : 0.15625 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 1 : 320 / 668.25 ] loss :0.3716  , accuracy:  0.8125 true nums: 9  ration : 0.28125 acc : 0.8125  f1 : 0.5\n",
      "[ 1 : 340 / 668.25 ] loss :0.4763  , accuracy:  0.75 true nums: 10  ration : 0.3125 acc : 0.75  f1 : 0.4285714285714285\n",
      "[ 1 : 360 / 668.25 ] loss :0.4736  , accuracy:  0.8125 true nums: 7  ration : 0.21875 acc : 0.8125  f1 : 0.25\n",
      "[ 1 : 380 / 668.25 ] loss :0.5161  , accuracy:  0.71875 true nums: 11  ration : 0.34375 acc : 0.71875  f1 : 0.3076923076923077\n",
      "[ 1 : 400 / 668.25 ] loss :0.5784  , accuracy:  0.6875 true nums: 13  ration : 0.40625 acc : 0.6875  f1 : 0.4444444444444444\n",
      "[ 1 : 420 / 668.25 ] loss :0.3406  , accuracy:  0.875 true nums: 4  ration : 0.125 acc : 0.875  f1 : 0.5\n",
      "[ 1 : 440 / 668.25 ] loss :0.4949  , accuracy:  0.78125 true nums: 6  ration : 0.1875 acc : 0.78125  f1 : 0.0\n",
      "[ 1 : 460 / 668.25 ] loss :0.3495  , accuracy:  0.90625 true nums: 5  ration : 0.15625 acc : 0.90625  f1 : 0.5714285714285715\n",
      "[ 1 : 480 / 668.25 ] loss :0.4908  , accuracy:  0.71875 true nums: 9  ration : 0.28125 acc : 0.71875  f1 : 0.0\n",
      "[ 1 : 500 / 668.25 ] loss :0.6108  , accuracy:  0.71875 true nums: 10  ration : 0.3125 acc : 0.71875  f1 : 0.18181818181818182\n",
      "[ 1 : 520 / 668.25 ] loss :0.6128  , accuracy:  0.6875 true nums: 10  ration : 0.3125 acc : 0.6875  f1 : 0.16666666666666669\n",
      "[ 1 : 540 / 668.25 ] loss :0.6601  , accuracy:  0.65625 true nums: 12  ration : 0.375 acc : 0.65625  f1 : 0.26666666666666666\n",
      "[ 1 : 560 / 668.25 ] loss :0.5553  , accuracy:  0.71875 true nums: 10  ration : 0.3125 acc : 0.71875  f1 : 0.18181818181818182\n",
      "[ 1 : 580 / 668.25 ] loss :0.4310  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.2857142857142857\n",
      "[ 1 : 600 / 668.25 ] loss :0.5239  , accuracy:  0.71875 true nums: 9  ration : 0.28125 acc : 0.71875  f1 : 0.0\n",
      "[ 1 : 620 / 668.25 ] loss :0.5888  , accuracy:  0.71875 true nums: 8  ration : 0.25 acc : 0.71875  f1 : 0.3076923076923077\n",
      "[ 1 : 640 / 668.25 ] loss :0.3838  , accuracy:  0.875 true nums: 5  ration : 0.15625 acc : 0.875  f1 : 0.5\n",
      "[ 1 : 660 / 668.25 ] loss :0.5158  , accuracy:  0.75 true nums: 11  ration : 0.34375 acc : 0.75  f1 : 0.42857142857142855\n",
      "1 510.15625 668 0.7637069610778443 0.3005517370676762\n",
      "[ 2 : 0 / 668.25 ] loss :0.5915  , accuracy:  0.71875 true nums: 9  ration : 0.28125 acc : 0.71875  f1 : 0.1818181818181818\n",
      "[ 2 : 20 / 668.25 ] loss :0.5190  , accuracy:  0.6875 true nums: 9  ration : 0.28125 acc : 0.6875  f1 : 0.2857142857142857\n",
      "[ 2 : 40 / 668.25 ] loss :0.4845  , accuracy:  0.75 true nums: 9  ration : 0.28125 acc : 0.75  f1 : 0.19999999999999998\n",
      "[ 2 : 60 / 668.25 ] loss :0.5094  , accuracy:  0.71875 true nums: 10  ration : 0.3125 acc : 0.71875  f1 : 0.4\n",
      "[ 2 : 80 / 668.25 ] loss :0.5879  , accuracy:  0.65625 true nums: 10  ration : 0.3125 acc : 0.65625  f1 : 0.0\n",
      "[ 2 : 100 / 668.25 ] loss :0.6471  , accuracy:  0.71875 true nums: 8  ration : 0.25 acc : 0.71875  f1 : 0.0\n",
      "[ 2 : 120 / 668.25 ] loss :0.5249  , accuracy:  0.75 true nums: 6  ration : 0.1875 acc : 0.75  f1 : 0.2\n",
      "[ 2 : 140 / 668.25 ] loss :0.6274  , accuracy:  0.71875 true nums: 11  ration : 0.34375 acc : 0.71875  f1 : 0.3076923076923077\n",
      "[ 2 : 160 / 668.25 ] loss :0.4220  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.4444444444444444\n",
      "[ 2 : 180 / 668.25 ] loss :0.6231  , accuracy:  0.6875 true nums: 14  ration : 0.4375 acc : 0.6875  f1 : 0.5\n",
      "[ 2 : 200 / 668.25 ] loss :0.4424  , accuracy:  0.8125 true nums: 6  ration : 0.1875 acc : 0.8125  f1 : 0.25\n",
      "[ 2 : 220 / 668.25 ] loss :0.3605  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.5454545454545454\n",
      "[ 2 : 240 / 668.25 ] loss :0.4305  , accuracy:  0.78125 true nums: 6  ration : 0.1875 acc : 0.78125  f1 : 0.5333333333333333\n",
      "[ 2 : 260 / 668.25 ] loss :0.3387  , accuracy:  0.84375 true nums: 6  ration : 0.1875 acc : 0.84375  f1 : 0.2857142857142857\n",
      "[ 2 : 280 / 668.25 ] loss :0.4850  , accuracy:  0.71875 true nums: 8  ration : 0.25 acc : 0.71875  f1 : 0.18181818181818182\n",
      "[ 2 : 300 / 668.25 ] loss :0.4168  , accuracy:  0.78125 true nums: 5  ration : 0.15625 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 2 : 320 / 668.25 ] loss :0.5050  , accuracy:  0.84375 true nums: 7  ration : 0.21875 acc : 0.84375  f1 : 0.4444444444444445\n",
      "[ 2 : 340 / 668.25 ] loss :0.4268  , accuracy:  0.84375 true nums: 7  ration : 0.21875 acc : 0.84375  f1 : 0.5454545454545454\n",
      "[ 2 : 360 / 668.25 ] loss :0.2970  , accuracy:  0.875 true nums: 6  ration : 0.1875 acc : 0.875  f1 : 0.5\n",
      "[ 2 : 380 / 668.25 ] loss :0.4504  , accuracy:  0.78125 true nums: 7  ration : 0.21875 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 2 : 400 / 668.25 ] loss :0.5002  , accuracy:  0.71875 true nums: 10  ration : 0.3125 acc : 0.71875  f1 : 0.4\n",
      "[ 2 : 420 / 668.25 ] loss :0.5095  , accuracy:  0.78125 true nums: 7  ration : 0.21875 acc : 0.78125  f1 : 0.22222222222222224\n",
      "[ 2 : 440 / 668.25 ] loss :0.6704  , accuracy:  0.6875 true nums: 12  ration : 0.375 acc : 0.6875  f1 : 0.2857142857142857\n",
      "[ 2 : 460 / 668.25 ] loss :0.5732  , accuracy:  0.65625 true nums: 10  ration : 0.3125 acc : 0.65625  f1 : 0.15384615384615383\n",
      "[ 2 : 480 / 668.25 ] loss :0.4728  , accuracy:  0.75 true nums: 10  ration : 0.3125 acc : 0.75  f1 : 0.33333333333333337\n",
      "[ 2 : 500 / 668.25 ] loss :0.5227  , accuracy:  0.75 true nums: 11  ration : 0.34375 acc : 0.75  f1 : 0.5555555555555556\n",
      "[ 2 : 520 / 668.25 ] loss :0.5838  , accuracy:  0.65625 true nums: 12  ration : 0.375 acc : 0.65625  f1 : 0.15384615384615385\n",
      "[ 2 : 540 / 668.25 ] loss :0.4645  , accuracy:  0.84375 true nums: 7  ration : 0.21875 acc : 0.84375  f1 : 0.4444444444444445\n",
      "[ 2 : 560 / 668.25 ] loss :0.4357  , accuracy:  0.78125 true nums: 8  ration : 0.25 acc : 0.78125  f1 : 0.36363636363636365\n",
      "[ 2 : 580 / 668.25 ] loss :0.3790  , accuracy:  0.84375 true nums: 9  ration : 0.28125 acc : 0.84375  f1 : 0.6153846153846153\n",
      "[ 2 : 600 / 668.25 ] loss :0.4882  , accuracy:  0.75 true nums: 11  ration : 0.34375 acc : 0.75  f1 : 0.6\n",
      "[ 2 : 620 / 668.25 ] loss :0.4641  , accuracy:  0.8125 true nums: 8  ration : 0.25 acc : 0.8125  f1 : 0.5\n",
      "[ 2 : 640 / 668.25 ] loss :0.4434  , accuracy:  0.75 true nums: 9  ration : 0.28125 acc : 0.75  f1 : 0.42857142857142855\n",
      "[ 2 : 660 / 668.25 ] loss :0.4664  , accuracy:  0.75 true nums: 8  ration : 0.25 acc : 0.75  f1 : 0.0\n",
      "2 512.6875 668 0.7674962574850299 0.3143688195167607\n"
     ]
    }
   ],
   "source": [
    "# t_total = len(train_x1) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "model.zero_grad()\n",
    "model.train()\n",
    "w= pickle.load(open('/data/hdj/cross_project_trans/report/bert/'+project+'test_middle/w_parameters.in','rb'))\n",
    "# embedding = nn.Embedding.from_pretrained(torch.tensor(aspectj_w[0]))#从已有的weight导入embedding\n",
    "# swt_w= pickle.load(open('/home/hdj/cross_project_trans/report/swt_test_middle/w_parameters.in','rb'))\n",
    "# w= pickle.load(open('/home/hdj/cross_project_trans/report/zxing_test_middle/w_parameters.in','rb'))\n",
    "embedding = nn.Embedding.from_pretrained(torch.tensor(w[0]))#从已有的weight导入embedding\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, args.warmup_steps, t_total)\n",
    "# batch_size=128\n",
    "for epoche in range(3):\n",
    "    total_acc=0.0\n",
    "    total_f1=0.0\n",
    "    total_nums=0\n",
    "    i=0\n",
    "    num_batch = len(train_set) / batch_size #总共训练次数\n",
    "    \n",
    "    for _, data in enumerate(training_loader, 0):#start=0 默认就是0\n",
    "        #这是NPCNN需要的数据\n",
    "        train_x1_batch=embedding(data[5])\n",
    "        train_x2_batch=embedding(data[4])\n",
    "        y_train=data[6].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         print(train_x1_batch.shape,train_x2_batch.shape)\n",
    "        train_x1_batch = train_x1_batch.reshape(train_x1_batch.shape[0]*train_x1_batch.shape[1],train_x1_batch.shape[2],train_x1_batch.shape[3])\n",
    "        train_x1_batch = train_x1_batch.to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "        train_x2_batch = train_x2_batch.to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "        y_train = y_train.to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         print('train_x1_batch ',train_x1_batch.shape)\n",
    "#         print('train_x2_batch ',train_x2_batch.shape)\n",
    "#         print('y_train ',y_train.shape)\n",
    "        #NPCNN需要的数据\n",
    "        #codeBert需要的数据\n",
    "        report_ids=None\n",
    "        report_mask=None\n",
    "        code_ids=None\n",
    "        code_mask=None\n",
    "#         report_ids=data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         report_mask=data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         code_ids=data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         code_mask=data[3].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        #codeBert需要的数据\n",
    "#         outputs=model(train_x1_batch,train_x2_batch,report_ids,report_mask,code_ids,code_mask)\n",
    "        outputs=model(train_x1_batch,train_x2_batch,report_ids,report_mask,code_ids,code_mask)\n",
    "        pred_choice = outputs.max(1)[1]\n",
    "#         print('cos_simi type',type(cos_simi),cos_simi)\n",
    "#         print(type(y_train),y_train)\n",
    "#         print('output y_train shape:',outputs.shape,y_train.shape)\n",
    "        loss=loss_fun(outputs, y_train)\n",
    "#         print('codeEmd shape:',codeEmd.shape,reportEmd.shape,y_train.shape)\n",
    "#         lossRank=lossRankFunction(codeEmd,reportEmd,y_train.reshape(-1,1))\n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "#         if args.gradient_accumulation_steps > 1:\n",
    "#              loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "        loss.backward()\n",
    "#         lossRank.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "#         if(i+1)%args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "#             scheduler.step()\n",
    "        model.zero_grad()\n",
    "        correct = pred_choice.eq(y_train).cpu().sum()\n",
    "        metrics = compute_metrics(pred_choice.cpu().numpy(), y_train.cpu().numpy())\n",
    "#         print(metrics)\n",
    "#         if i %4 == 0:\n",
    "#             print('[',epoche,':',i,'/',num_batch,']',\"loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(y_train.cpu().numpy()),' ration :',sum(y_train.cpu().numpy())/len(y_train),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "        #print(train_x1_batch.shape,train_x2_batch.shape,y_train.shape)\n",
    "        total_acc+=metrics['acc']\n",
    "        total_f1+=metrics['f1']\n",
    "        total_nums+=1\n",
    "        if i%20==0:\n",
    "            print('[',epoche,':',i,'/',num_batch,']',\"loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(y_train.cpu().numpy()),' ration :',sum(y_train.cpu().numpy())/len(y_train),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#         file_path = '/home/hdj/tencent/textCNN/model_v2_age_0606_predicted.hdf5'\n",
    "        i+=1\n",
    "    curr_acc=total_acc/total_nums\n",
    "    curr_f1=total_f1/total_nums\n",
    "    print(epoche,total_acc,total_nums,curr_acc,curr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #之前版本的代码\n",
    "# t_total = len(train_x1) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "# model.zero_grad()\n",
    "# model.train()\n",
    "# # scheduler = get_linear_schedule_with_warmup(optimizer, args.warmup_steps, t_total)\n",
    "# batch_size=128\n",
    "# for epoche in range(10):\n",
    "#     total_acc=0.0\n",
    "#     total_nums=0\n",
    "#     i=0\n",
    "#     num_batch = len(train_x1) / batch_size #总共训练次数\n",
    "#     for train_x1_batch,train_x2_batch,y_train in  minibatches(train_x1,train_x2,train_y,batch_size,True):\n",
    "#         train_x1_batch = train_x1_batch.reshape(train_x1_batch.shape[0]*train_x1_batch.shape[1],train_x1_batch.shape[2],train_x1_batch.shape[3])\n",
    "#         train_x1_batch = torch.tensor(train_x1_batch).to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "#         train_x2_batch = torch.tensor(train_x2_batch).to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "#         y_train = torch.tensor(y_train).to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         outputs=model(train_x1_batch,train_x2_batch)\n",
    "#         pred_choice = outputs.max(1)[1]\n",
    "        \n",
    "# #         print(type(y_train),y_train)\n",
    "#         loss=loss_fun(outputs, y_train)\n",
    "#         eval_loss += loss.item()\n",
    "        \n",
    "# #         if args.gradient_accumulation_steps > 1:\n",
    "# #              loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "# #         if(i+1)%args.gradient_accumulation_steps == 0:\n",
    "#         optimizer.step()\n",
    "# #             scheduler.step()\n",
    "#         model.zero_grad()\n",
    "#         correct = pred_choice.eq(y_train).cpu().sum()\n",
    "#         metrics = compute_metrics(pred_choice.cpu().numpy(), y_train.cpu().numpy())\n",
    "# #         print(metrics)\n",
    "#         if i %4 == 0:\n",
    "#             print('[',epoche,':',i,'/',num_batch,']',\"loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(y_train.cpu().numpy()),' ration :',sum(y_train.cpu().numpy())/len(y_train),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#         #print(train_x1_batch.shape,train_x2_batch.shape,y_train.shape)\n",
    "# #         file_path = '/home/hdj/tencent/textCNN/model_v2_age_0606_predicted.hdf5'\n",
    "#         i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/data/hdj/cross_project_trans/report/bert/npcnn_model_0621.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('/home/hdj/NPCNN_hdj/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('/home/hdj/NPCNN_hdj/parameters.in','rb'))\n",
    "\n",
    "train_report,train_code,train_labels,W = X[0],X[1],X[2],X[3]\n",
    "embedding = nn.Embedding.from_pretrained(torch.tensor(W))#从已有的weight导入embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspectj_w= pickle.load(open('/home/hdj/cross_project_trans/report/aspectj_test_middle/w_parameters.in','rb'))\n",
    "embedding = nn.Embedding.from_pretrained(torch.tensor(aspectj_w[0]))#从已有的weight导入embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30000, 1]) torch.Size([30000, 1]) torch.Size([30000, 1]) torch.Size([30000, 1]) torch.Size([30000, 308]) torch.Size([30000, 100, 40]) torch.Size([30000])\n"
     ]
    }
   ],
   "source": [
    "#将test数据集合并\n",
    "report_path='/data/hdj/cross_project_trans/report/bert/'\n",
    "all_test=pd.read_pickle('/data/hdj/cross_project_trans/report/bert/'+project+'test_middle/test'+str(0)+'.pkl')\n",
    "# all_test=pd.read_pickle('/home/hdj/cross_project_trans/report/swt_test_middle/test'+str(0)+'.pkl')\n",
    "# all_test=pd.read_pickle('/home/hdj/cross_project_trans/report/zxing_test_middle/test'+str(0)+'.pkl')\n",
    "test_path=report_path+project+'test/'\n",
    "test_num=len(os.listdir(test_path))\n",
    "for test_index in range(1,100):\n",
    "# for test_index in range(1,20):\n",
    "# for test_index in range(1,4):\n",
    "    test=pd.read_pickle('/data/hdj/cross_project_trans/report/bert/'+project+'test_middle/test'+str(test_index)+'.pkl')\n",
    "#     test=pd.read_pickle('/home/hdj/cross_project_trans/report/swt_test_middle/test'+str(test_index)+'.pkl')\n",
    "#     test=pd.read_pickle('/home/hdj/cross_project_trans/report/zxing_test_middle/test'+str(test_index)+'.pkl')\n",
    "    all_test=pd.concat([all_test,test])\n",
    "test_set=data_tensor_generate(all_test,project,tokenizer=None,maxLength=256,ttype='test')\n",
    "print(test_set.tensors[0].shape,test_set.tensors[1].shape,test_set.tensors[2].shape,test_set.tensors[3].shape,test_set.tensors[4].shape,test_set.tensors[5].shape,test_set.tensors[6].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set.tensors[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6454, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7123, device='cuda:0')\n",
      "40 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5098, device='cuda:0')\n",
      "60 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5219, device='cuda:0')\n",
      "80 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6948, device='cuda:0')\n",
      "100 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7864, device='cuda:0')\n",
      "120 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5468, device='cuda:0')\n",
      "140 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7559, device='cuda:0')\n",
      "160 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6512, device='cuda:0')\n",
      "180 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7316, device='cuda:0')\n",
      "200 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7396, device='cuda:0')\n",
      "220 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.8034, device='cuda:0')\n",
      "240 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.9050, device='cuda:0')\n",
      "260 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7486, device='cuda:0')\n",
      "280 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.8487, device='cuda:0')\n",
      "300 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.9623, device='cuda:0')\n",
      "320 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7620, device='cuda:0')\n",
      "340 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7206, device='cuda:0')\n",
      "360 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6243, device='cuda:0')\n",
      "380 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6636, device='cuda:0')\n",
      "400 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7969, device='cuda:0')\n",
      "420 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6868, device='cuda:0')\n",
      "440 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.8410, device='cuda:0')\n",
      "460 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5505, device='cuda:0')\n",
      "480 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7910, device='cuda:0')\n",
      "500 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6744, device='cuda:0')\n",
      "520 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6767, device='cuda:0')\n",
      "540 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6046, device='cuda:0')\n",
      "560 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7443, device='cuda:0')\n",
      "580 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7559, device='cuda:0')\n",
      "600 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7754, device='cuda:0')\n",
      "620 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5916, device='cuda:0')\n",
      "640 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5923, device='cuda:0')\n",
      "660 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6150, device='cuda:0')\n",
      "680 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7758, device='cuda:0')\n",
      "700 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5612, device='cuda:0')\n",
      "720 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7616, device='cuda:0')\n",
      "740 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7681, device='cuda:0')\n",
      "760 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7278, device='cuda:0')\n",
      "780 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5461, device='cuda:0')\n",
      "800 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7547, device='cuda:0')\n",
      "820 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7356, device='cuda:0')\n",
      "840 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.5547, device='cuda:0')\n",
      "860 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.8442, device='cuda:0')\n",
      "880 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.7553, device='cuda:0')\n",
      "900 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.4465, device='cuda:0')\n",
      "920 / 937.5 torch.Size([32, 100, 40, 300]) torch.Size([32, 308, 300])\n",
      "test loss : tensor(0.6793, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "top10_all = []\n",
    "MRR_all = []\n",
    "MAP_all = []\n",
    "#直接从保存的文件里读取train和test数据\n",
    "# batch_size=4\n",
    "test = pickle.load(open('/data/hdj/cross_project_trans/encode_data/'+project+'parameters_test.in','rb'))\n",
    "# test = pickle.load(open('/data/hdj/cross_project_trans/encode_data/swt_parameters_test.in','rb'))\n",
    "# test = pickle.load(open('/data/hdj/cross_project_trans/encode_data/zxing_parameters_test.in','rb'))\n",
    "all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,all_code_idx, all_labels=test[0],test[1],test[2],test[3],test[4],test[5],test[6]\n",
    "test_set = TensorDataset(all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels)\n",
    "\n",
    "# test_set=data_tensor_generate(all_test,tokenizer=tokenizer,maxLength=10)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=32, shuffle=False, num_workers=4, drop_last=False)\n",
    "test_p=[]\n",
    "test_y_labels=[]\n",
    "for i, data in enumerate(test_loader, 0):#start=0 默认就是0\n",
    "    with torch.no_grad():\n",
    "        train_x1_batch=embedding(data[5])\n",
    "        train_x2_batch=embedding(data[4])\n",
    "        test_labels=data[6]\n",
    "#         print()\n",
    "        if i%20==0:\n",
    "            print(i,'/',len(test_set)/batch_size,train_x1_batch.shape,train_x2_batch.shape)\n",
    "        #NPCNN的数据处理\n",
    "        train_x1_batch = train_x1_batch.reshape(train_x1_batch.shape[0]*train_x1_batch.shape[1],train_x1_batch.shape[2],train_x1_batch.shape[3])\n",
    "        train_x1_batch = train_x1_batch.to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "        train_x2_batch = train_x2_batch.to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "        #NPCNN的数据处理\n",
    "        \n",
    "        #codeBert的数据处理\n",
    "        \n",
    "        report_ids= None #data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        report_mask=None #data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        code_ids=   None #data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        code_mask=  None #data[3].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        #codeBert需要的数据\n",
    "        outputs=model(train_x1_batch,train_x2_batch,report_ids,report_mask,code_ids,code_mask)\n",
    "        y_train = test_labels.to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        loss=loss_fun(outputs, y_train)\n",
    "        if i%20==0:\n",
    "            print('test loss :',loss)\n",
    "#         outputs=model(train_x1_batch,train_x2_batch)\n",
    "        outputs = F.softmax(torch.tensor(outputs))\n",
    "        test_p.extend(outputs[:,1].cpu())\n",
    "        test_y_labels.extend(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.5151) tensor(0)\n",
      "1 tensor(0.3715) tensor(0)\n",
      "2 tensor(0.5810) tensor(0)\n",
      "3 tensor(0.2859) tensor(1)\n",
      "4 tensor(0.5733) tensor(0)\n",
      "5 tensor(0.5540) tensor(0)\n",
      "6 tensor(0.4765) tensor(0)\n",
      "7 tensor(0.5426) tensor(0)\n",
      "8 tensor(0.2721) tensor(0)\n",
      "9 tensor(0.5004) tensor(0)\n",
      "10 tensor(0.5678) tensor(0)\n",
      "11 tensor(0.2542) tensor(0)\n",
      "12 tensor(0.2076) tensor(0)\n",
      "13 tensor(0.1398) tensor(0)\n",
      "14 tensor(0.1988) tensor(0)\n",
      "15 tensor(0.1193) tensor(0)\n",
      "16 tensor(0.2959) tensor(0)\n",
      "17 tensor(0.1648) tensor(0)\n",
      "18 tensor(0.4333) tensor(1)\n",
      "19 tensor(0.1595) tensor(0)\n",
      "20 tensor(0.2943) tensor(0)\n",
      "21 tensor(0.1101) tensor(0)\n",
      "22 tensor(0.6559) tensor(0)\n",
      "23 tensor(0.1448) tensor(0)\n",
      "24 tensor(0.5029) tensor(0)\n",
      "25 tensor(0.2134) tensor(0)\n",
      "26 tensor(0.0268) tensor(0)\n",
      "27 tensor(0.5396) tensor(0)\n",
      "28 tensor(0.1535) tensor(0)\n",
      "29 tensor(0.2034) tensor(0)\n",
      "30 tensor(0.5325) tensor(0)\n",
      "31 tensor(0.0716) tensor(0)\n",
      "32 tensor(0.2905) tensor(0)\n",
      "33 tensor(0.3880) tensor(0)\n",
      "34 tensor(0.2277) tensor(0)\n",
      "35 tensor(0.7974) tensor(0)\n",
      "36 tensor(0.1382) tensor(0)\n",
      "37 tensor(0.1362) tensor(0)\n",
      "38 tensor(0.4088) tensor(0)\n",
      "39 tensor(0.3651) tensor(0)\n",
      "40 tensor(0.2852) tensor(0)\n",
      "41 tensor(0.4635) tensor(0)\n",
      "42 tensor(0.1158) tensor(0)\n",
      "43 tensor(0.4115) tensor(0)\n",
      "44 tensor(0.3918) tensor(0)\n",
      "45 tensor(0.4018) tensor(0)\n",
      "46 tensor(0.1005) tensor(0)\n",
      "47 tensor(0.2133) tensor(0)\n",
      "48 tensor(0.4057) tensor(0)\n",
      "49 tensor(0.7672) tensor(0)\n",
      "50 tensor(0.1218) tensor(0)\n",
      "51 tensor(0.7976) tensor(0)\n",
      "52 tensor(0.4550) tensor(0)\n",
      "53 tensor(0.1710) tensor(0)\n",
      "54 tensor(0.2162) tensor(0)\n",
      "55 tensor(0.6502) tensor(0)\n",
      "56 tensor(0.1350) tensor(0)\n",
      "57 tensor(0.5543) tensor(0)\n",
      "58 tensor(0.3003) tensor(0)\n",
      "59 tensor(0.0099) tensor(0)\n",
      "60 tensor(0.1506) tensor(0)\n",
      "61 tensor(0.1216) tensor(0)\n",
      "62 tensor(0.5264) tensor(0)\n",
      "63 tensor(0.1600) tensor(0)\n",
      "64 tensor(0.3860) tensor(0)\n",
      "65 tensor(0.0614) tensor(0)\n",
      "66 tensor(0.2108) tensor(0)\n",
      "67 tensor(0.4221) tensor(0)\n",
      "68 tensor(0.3376) tensor(0)\n",
      "69 tensor(0.3955) tensor(0)\n",
      "70 tensor(0.7191) tensor(0)\n",
      "71 tensor(0.2525) tensor(0)\n",
      "72 tensor(0.3035) tensor(0)\n",
      "73 tensor(0.2305) tensor(0)\n",
      "74 tensor(0.4197) tensor(0)\n",
      "75 tensor(0.5380) tensor(0)\n",
      "76 tensor(0.2930) tensor(0)\n",
      "77 tensor(0.1424) tensor(0)\n",
      "78 tensor(0.2769) tensor(0)\n",
      "79 tensor(0.2679) tensor(0)\n",
      "80 tensor(0.1374) tensor(0)\n",
      "81 tensor(0.0906) tensor(0)\n",
      "82 tensor(0.7619) tensor(0)\n",
      "83 tensor(0.2659) tensor(0)\n",
      "84 tensor(0.6568) tensor(0)\n",
      "85 tensor(0.4644) tensor(0)\n",
      "86 tensor(0.3740) tensor(0)\n",
      "87 tensor(0.3559) tensor(0)\n",
      "88 tensor(0.4898) tensor(0)\n",
      "89 tensor(0.3436) tensor(0)\n",
      "90 tensor(0.3823) tensor(0)\n",
      "91 tensor(0.4419) tensor(0)\n",
      "92 tensor(0.5072) tensor(0)\n",
      "93 tensor(0.4220) tensor(0)\n",
      "94 tensor(0.5274) tensor(0)\n",
      "95 tensor(0.5015) tensor(0)\n",
      "96 tensor(0.5491) tensor(0)\n",
      "97 tensor(0.4063) tensor(0)\n",
      "98 tensor(0.3866) tensor(0)\n",
      "99 tensor(0.3792) tensor(0)\n",
      "100 tensor(0.7239) tensor(0)\n",
      "101 tensor(0.2011) tensor(0)\n",
      "102 tensor(0.0842) tensor(0)\n",
      "103 tensor(0.0669) tensor(0)\n",
      "104 tensor(0.1601) tensor(0)\n",
      "105 tensor(0.2054) tensor(0)\n",
      "106 tensor(0.2118) tensor(0)\n",
      "107 tensor(0.2301) tensor(0)\n",
      "108 tensor(0.0237) tensor(0)\n",
      "109 tensor(0.2680) tensor(0)\n",
      "110 tensor(0.2501) tensor(0)\n",
      "111 tensor(0.1274) tensor(0)\n",
      "112 tensor(0.2281) tensor(0)\n",
      "113 tensor(0.0895) tensor(0)\n",
      "114 tensor(0.2657) tensor(0)\n",
      "115 tensor(0.2567) tensor(0)\n",
      "116 tensor(0.5051) tensor(0)\n",
      "117 tensor(0.1645) tensor(0)\n",
      "118 tensor(0.1627) tensor(0)\n",
      "119 tensor(0.4448) tensor(0)\n",
      "120 tensor(0.0953) tensor(0)\n",
      "121 tensor(0.3795) tensor(0)\n",
      "122 tensor(0.5716) tensor(0)\n",
      "123 tensor(0.0788) tensor(0)\n",
      "124 tensor(0.1291) tensor(0)\n",
      "125 tensor(0.2120) tensor(0)\n",
      "126 tensor(0.1150) tensor(0)\n",
      "127 tensor(0.0620) tensor(0)\n",
      "128 tensor(0.2881) tensor(0)\n",
      "129 tensor(0.0763) tensor(0)\n",
      "130 tensor(0.4839) tensor(0)\n",
      "131 tensor(0.2986) tensor(0)\n",
      "132 tensor(0.3923) tensor(0)\n",
      "133 tensor(0.0739) tensor(0)\n",
      "134 tensor(0.5550) tensor(0)\n",
      "135 tensor(0.3338) tensor(0)\n",
      "136 tensor(0.0671) tensor(0)\n",
      "137 tensor(0.0785) tensor(0)\n",
      "138 tensor(0.3211) tensor(0)\n",
      "139 tensor(0.0905) tensor(0)\n",
      "140 tensor(0.1322) tensor(0)\n",
      "141 tensor(0.2836) tensor(0)\n",
      "142 tensor(0.5509) tensor(0)\n",
      "143 tensor(0.4084) tensor(0)\n",
      "144 tensor(0.1192) tensor(0)\n",
      "145 tensor(0.1907) tensor(0)\n",
      "146 tensor(0.2063) tensor(0)\n",
      "147 tensor(0.2878) tensor(0)\n",
      "148 tensor(0.4882) tensor(0)\n",
      "149 tensor(0.2997) tensor(0)\n",
      "150 tensor(0.2843) tensor(0)\n",
      "151 tensor(0.4023) tensor(0)\n",
      "152 tensor(0.2732) tensor(0)\n",
      "153 tensor(0.0977) tensor(0)\n",
      "154 tensor(0.2371) tensor(0)\n",
      "155 tensor(0.4378) tensor(0)\n",
      "156 tensor(0.1816) tensor(0)\n",
      "157 tensor(0.6916) tensor(0)\n",
      "158 tensor(0.5445) tensor(0)\n",
      "159 tensor(0.3177) tensor(0)\n",
      "160 tensor(0.0973) tensor(0)\n",
      "161 tensor(0.1055) tensor(0)\n",
      "162 tensor(0.0629) tensor(0)\n",
      "163 tensor(0.4386) tensor(0)\n",
      "164 tensor(0.1895) tensor(0)\n",
      "165 tensor(0.6302) tensor(0)\n",
      "166 tensor(0.3337) tensor(0)\n",
      "167 tensor(0.4068) tensor(0)\n",
      "168 tensor(0.1905) tensor(0)\n",
      "169 tensor(0.5180) tensor(0)\n",
      "170 tensor(0.1651) tensor(0)\n",
      "171 tensor(0.3016) tensor(0)\n",
      "172 tensor(0.5076) tensor(0)\n",
      "173 tensor(0.3600) tensor(0)\n",
      "174 tensor(0.5361) tensor(0)\n",
      "175 tensor(0.6039) tensor(0)\n",
      "176 tensor(0.2984) tensor(0)\n",
      "177 tensor(0.3840) tensor(0)\n",
      "178 tensor(0.4311) tensor(0)\n",
      "179 tensor(0.3553) tensor(0)\n",
      "180 tensor(0.0640) tensor(0)\n",
      "181 tensor(0.3429) tensor(0)\n",
      "182 tensor(0.5843) tensor(0)\n",
      "183 tensor(0.1381) tensor(0)\n",
      "184 tensor(0.3174) tensor(0)\n",
      "185 tensor(0.4812) tensor(0)\n",
      "186 tensor(0.4461) tensor(0)\n",
      "187 tensor(0.1416) tensor(0)\n",
      "188 tensor(0.4202) tensor(0)\n",
      "189 tensor(0.2307) tensor(0)\n",
      "190 tensor(0.3122) tensor(0)\n",
      "191 tensor(0.5017) tensor(0)\n",
      "192 tensor(0.3959) tensor(0)\n",
      "193 tensor(0.2299) tensor(0)\n",
      "194 tensor(0.4163) tensor(0)\n",
      "195 tensor(0.4224) tensor(0)\n",
      "196 tensor(0.3871) tensor(0)\n",
      "197 tensor(0.3959) tensor(0)\n",
      "198 tensor(0.3736) tensor(0)\n",
      "199 tensor(0.4127) tensor(0)\n",
      "200 tensor(0.1616) tensor(0)\n",
      "201 tensor(0.3140) tensor(0)\n",
      "202 tensor(0.5790) tensor(0)\n",
      "203 tensor(0.3411) tensor(0)\n",
      "204 tensor(0.3342) tensor(0)\n",
      "205 tensor(0.4001) tensor(0)\n",
      "206 tensor(0.1864) tensor(0)\n",
      "207 tensor(0.1567) tensor(0)\n",
      "208 tensor(0.3256) tensor(0)\n",
      "209 tensor(0.3510) tensor(0)\n",
      "210 tensor(0.2350) tensor(0)\n",
      "211 tensor(0.3388) tensor(0)\n",
      "212 tensor(0.2446) tensor(0)\n",
      "213 tensor(0.0795) tensor(0)\n",
      "214 tensor(0.0255) tensor(0)\n",
      "215 tensor(0.2345) tensor(0)\n",
      "216 tensor(0.2270) tensor(0)\n",
      "217 tensor(0.4078) tensor(0)\n",
      "218 tensor(0.0898) tensor(0)\n",
      "219 tensor(0.2401) tensor(0)\n",
      "220 tensor(0.4086) tensor(0)\n",
      "221 tensor(0.3584) tensor(0)\n",
      "222 tensor(0.4873) tensor(0)\n",
      "223 tensor(0.1633) tensor(0)\n",
      "224 tensor(0.3951) tensor(0)\n",
      "225 tensor(0.4270) tensor(0)\n",
      "226 tensor(0.2428) tensor(0)\n",
      "227 tensor(0.1584) tensor(0)\n",
      "228 tensor(0.1801) tensor(0)\n",
      "229 tensor(0.2932) tensor(0)\n",
      "230 tensor(0.1070) tensor(0)\n",
      "231 tensor(0.2769) tensor(0)\n",
      "232 tensor(0.2602) tensor(0)\n",
      "233 tensor(0.2637) tensor(0)\n",
      "234 tensor(0.2668) tensor(0)\n",
      "235 tensor(0.4089) tensor(0)\n",
      "236 tensor(0.3581) tensor(0)\n",
      "237 tensor(0.2694) tensor(0)\n",
      "238 tensor(0.2311) tensor(0)\n",
      "239 tensor(0.2264) tensor(0)\n",
      "240 tensor(0.1231) tensor(0)\n",
      "241 tensor(0.2402) tensor(0)\n",
      "242 tensor(0.1876) tensor(0)\n",
      "243 tensor(0.2612) tensor(0)\n",
      "244 tensor(0.3421) tensor(0)\n",
      "245 tensor(0.5318) tensor(0)\n",
      "246 tensor(0.4758) tensor(0)\n",
      "247 tensor(0.2524) tensor(0)\n",
      "248 tensor(0.2397) tensor(0)\n",
      "249 tensor(0.1385) tensor(0)\n",
      "250 tensor(0.5311) tensor(0)\n",
      "251 tensor(0.2746) tensor(0)\n",
      "252 tensor(0.2716) tensor(0)\n",
      "253 tensor(0.3461) tensor(0)\n",
      "254 tensor(0.0920) tensor(0)\n",
      "255 tensor(0.1011) tensor(0)\n",
      "256 tensor(0.3146) tensor(0)\n",
      "257 tensor(0.4194) tensor(0)\n",
      "258 tensor(0.4814) tensor(0)\n",
      "259 tensor(0.6221) tensor(0)\n",
      "260 tensor(0.4178) tensor(0)\n",
      "261 tensor(0.2975) tensor(0)\n",
      "262 tensor(0.3820) tensor(0)\n",
      "263 tensor(0.2963) tensor(0)\n",
      "264 tensor(0.3200) tensor(0)\n",
      "265 tensor(0.1092) tensor(0)\n",
      "266 tensor(0.0466) tensor(0)\n",
      "267 tensor(0.3973) tensor(0)\n",
      "268 tensor(0.3034) tensor(0)\n",
      "269 tensor(0.0720) tensor(0)\n",
      "270 tensor(0.3837) tensor(0)\n",
      "271 tensor(0.3217) tensor(0)\n",
      "272 tensor(0.4442) tensor(0)\n",
      "273 tensor(0.3083) tensor(0)\n",
      "274 tensor(0.2981) tensor(0)\n",
      "275 tensor(0.2632) tensor(0)\n",
      "276 tensor(0.2528) tensor(0)\n",
      "277 tensor(0.2688) tensor(0)\n",
      "278 tensor(0.2896) tensor(0)\n",
      "279 tensor(0.1866) tensor(0)\n",
      "280 tensor(0.2019) tensor(0)\n",
      "281 tensor(0.1736) tensor(0)\n",
      "282 tensor(0.4896) tensor(0)\n",
      "283 tensor(0.0692) tensor(0)\n",
      "284 tensor(0.3518) tensor(0)\n",
      "285 tensor(0.3834) tensor(0)\n",
      "286 tensor(0.2539) tensor(0)\n",
      "287 tensor(0.2695) tensor(0)\n",
      "288 tensor(0.1977) tensor(0)\n",
      "289 tensor(0.0805) tensor(0)\n",
      "290 tensor(0.1659) tensor(0)\n",
      "291 tensor(0.1519) tensor(0)\n",
      "292 tensor(0.4490) tensor(0)\n",
      "293 tensor(0.3595) tensor(0)\n",
      "294 tensor(0.1522) tensor(0)\n",
      "295 tensor(0.5064) tensor(0)\n",
      "296 tensor(0.2864) tensor(0)\n",
      "297 tensor(0.4184) tensor(0)\n",
      "298 tensor(0.3768) tensor(0)\n",
      "299 tensor(0.1471) tensor(0)\n",
      "300 tensor(0.4439) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "len(test_p)\n",
    "for i,(p,y) in enumerate(zip(test_p,test_y_labels)):\n",
    "    print(i,p,y)\n",
    "    if i==300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "出现pos_num为0的情况 0\n",
      "top10: 0.225\n",
      "MRR: 0.1850253038637951\n",
      "MAP: 0.1161799111839623\n"
     ]
    }
   ],
   "source": [
    "print(len(test_p),len(test_y_labels))\n",
    "for i in range(100):\n",
    "# for i in range(20):\n",
    "# for i in range(4):\n",
    "#     top10,MRR,MAP = eval_y(test_p[i*1000:(i+1)*1000], test_y_labels[i*1000:(i+1)*1000])\n",
    "    top10,MRR,MAP = eval_y(test_p[i*300:(i+1)*300], test_y_labels[i*300:(i+1)*300])\n",
    "    top10_all.append(top10)\n",
    "    MRR_all.append(MRR)\n",
    "    MAP_all.append(MAP)\n",
    "\n",
    "print('top10:', np.mean(top10_all))\n",
    "print('MRR:', np.mean(MRR_all))\n",
    "print('MAP:',np.mean(MAP_all))\n",
    "#16:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26333333333333336\n",
      "0.375\n",
      "0.38833333333333336\n",
      "0.35999999999999993\n",
      "0.4116666666666667\n"
     ]
    }
   ],
   "source": [
    "# MAP\n",
    "print((0.31+0.23+0.14+0.25+0.43+0.22)/6)\n",
    "print((0.44+0.39+0.16+0.40+0.49+0.37)/6)\n",
    "print((0.44+0.37+0.18+0.41+0.50+0.43)/6)\n",
    "print((0.41+0.34+0.20+0.37+0.52+0.32)/6)\n",
    "print((0.46+0.39+0.20+0.43+0.54+0.45)/6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32166666666666666\n",
      "0.44\n",
      "0.45999999999999996\n",
      "0.4683333333333333\n",
      "0.48666666666666664\n"
     ]
    }
   ],
   "source": [
    "#MRR\n",
    "print((0.37+0.30+0.18+0.28+0.48+0.32)/6)\n",
    "print((0.51+0.47+0.21+0.46+0.55+0.44)/6)\n",
    "print((0.51+0.46+0.24+0.47+0.57+0.51)/6)\n",
    "print((0.51+0.45+0.28+0.45+0.60+0.52)/6)\n",
    "print((0.53+0.48+0.26+0.50+0.60+0.55)/6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5366666666666666\n",
      "0.525\n",
      "0.6766666666666666\n",
      "0.7466666666666666\n",
      "0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "# TOP10\n",
    "print((0.60+0.51+0.32+0.51+0.71+0.57)/6)\n",
    "print((0.75+0.74+0.21+0.46+0.55+0.44)/6)\n",
    "print((0.73+0.74+0.38+0.75+0.78+0.68)/6)\n",
    "print((0.78+0.74+0.51+0.80+0.80+0.85)/6)\n",
    "print((0.75+0.72+0.45+0.77+0.81+0.70)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38666666666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP\n",
    "(0.43+ 0.36 + 0.19 + 0.40 +0.52 + 0.42)/6\n",
    "# MRR\n",
    "# (0.50 + 0.45 + 0.25 + 0.45 + 0.59 +0.53)/6\n",
    "#TOP 10\n",
    "# (0.73 + 0.72 + 0.40 +0.73 + 0.80 + 0.69)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769230769230768\n",
      "0.07894736842105256\n",
      "0.05128205128205118\n",
      "0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "MAP\n",
    "fl=0.41\n",
    "for num in [0.26,0.38,0.39,0.35]:\n",
    "    print((fl-num)/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5312499999999999\n",
      "0.1136363636363636\n",
      "0.06521739130434775\n",
      "0.04255319148936174\n"
     ]
    }
   ],
   "source": [
    "# MRR\n",
    "fl=0.49\n",
    "for num in [0.32,0.44,0.46,0.47]:\n",
    "    print((fl-num)/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2962962962962961\n",
      "0.32075471698113195\n",
      "0.029411764705882214\n"
     ]
    }
   ],
   "source": [
    "fl=0.70\n",
    "for num in [0.54,0.53,0.68]:\n",
    "    print((fl-num)/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053672316384180845\n",
      "0.046920821114369377\n",
      "0.13098236775818636\n",
      "0.043301759133964855\n",
      "0.07856191744340886\n",
      "0.029850746268656577\n"
     ]
    }
   ],
   "source": [
    "#ablation\n",
    "org=[0.708,0.682,0.397,0.739,0.751,0.67]\n",
    "fine=[0.746,0.714,0.449,0.771,0.810, 0.69]\n",
    "for o,f in zip(org,fine):\n",
    "    print((f-o)/o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059642147117296276\n",
      "0.05518763796909485\n",
      "0.13043478260869565\n",
      "0.07112068965517235\n",
      "0.04929577464788737\n",
      "0.0745098039215687\n"
     ]
    }
   ],
   "source": [
    "#ablation MRR\n",
    "org=[0.503,0.453,0.230,0.464,0.568,0.51]\n",
    "fine=[0.533,0.478,0.260,0.497, 0.596 ,0.548]\n",
    "for o,f in zip(org,fine):\n",
    "    print((f-o)/o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06526806526806533\n",
      "0.05945945945945951\n",
      "0.14606741573033705\n",
      "0.0748129675810473\n",
      "0.06361829025844937\n",
      "0.02272727272727275\n"
     ]
    }
   ],
   "source": [
    "#ablation MAP\n",
    "org=[0.429,0.370,0.178,0.401,0.503,0.44]\n",
    "fine=[0.457,0.392,0.204,0.431,0.535 ,0.45]\n",
    "for o,f in zip(org,fine):\n",
    "    print((f-o)/o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for training\n",
      "finish reading\n"
     ]
    }
   ],
   "source": [
    "#被废弃代码\n",
    "#import pickle\n",
    "# index=2\n",
    "# print(\"loading data for training\")\n",
    "# test_num = 58\n",
    "# X = pickle.load(open('/home/hdj/NPCNN_hdj/parameters.in','rb'))\n",
    "\n",
    "# train_report,train_code,train_labels,W = X[0],X[1],X[2],X[3]\n",
    "# embedding = nn.Embedding.from_pretrained(torch.tensor(W))#从已有的weight导入embedding\n",
    "# train_code = embedding(torch.tensor(train_code))\n",
    "# train_report =embedding(torch.tensor(train_report))\n",
    "# # train_report = np.array(train_report)\n",
    "# # train_code = np.array(train_code)\n",
    "# train_labels = np.array(train_labels)\n",
    "# # W = np.array(W)\n",
    "# # print(np.array(train_report).shape, np.array(train_code).shape, np.array(train_labels).shape, np.array(W).shape)\n",
    "# print(\"finish reading\")\n",
    "# #在W中找到所需的单词向量，维度多一维\n",
    "# # train_code = W[train_code]\n",
    "# # train_report = W[train_report]\n",
    "# # print(np.array(train_code).shape,np.array(train_report).shape)\n",
    "\n",
    "# train_x1 = train_code\n",
    "# train_x2 = train_report\n",
    "# train_y = train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为python脚本NP_CNN_hdj准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要为数据的code生成文本形式\n",
    "def get_testsets(test_code,test_report,test_label):\n",
    "    code_x = test_code[0]\n",
    "    for i in range(300-1):\n",
    "        code_x = np.vstack((code_x,test_code[i+1]))\n",
    "    report_x = test_report\n",
    "    y = test_label\n",
    "    return code_x,report_x,y\n",
    "def code_merge(raw_code_list):\n",
    "    code_list=[]\n",
    "    for raw_code in raw_code_list:\n",
    "        code_list.append(raw_code['text'])\n",
    "    code_text=' '.join(code_list)\n",
    "    return code_text\n",
    "\n",
    "def data_tensor_generate_test(data,project,tokenizer,maxLength=512,ttype='train'):\n",
    "    '''\n",
    "        输入是dataframe 包含bug_id\tcnn_report_idx\tcode_idx\tlabel\tpath\traw_report\traw_code\n",
    "    '''\n",
    "    #将raw_code里dict形式合并生成code_text\n",
    "    data['raw_code_text']=data['raw_code'].apply(code_merge)\n",
    "    #生成完成\n",
    "    all_labels=list(data['label'])\n",
    "    all_cnn_report_idx=list(data['cnn_report_idx'])\n",
    "    all_code_idx=list(data['code_idx'])\n",
    "    raw_report=list(data['raw_report'])\n",
    "    raw_code=list(data['raw_code_text'])\n",
    "#     reportInputs=tokenizer.batch_encode_plus(raw_report,add_special_tokens=True,max_length=maxLength,pad_to_max_length=True,return_token_type_ids=True,truncation=True)\n",
    "#     codeInputs=tokenizer.batch_encode_plus(raw_code,add_special_tokens=True,max_length=maxLength,pad_to_max_length=True,return_token_type_ids=True,truncation=True)\n",
    "#     all_report_input_ids=reportInputs['input_ids']\n",
    "#     all_report_input_mask=reportInputs['attention_mask']\n",
    "#     all_code_input_ids=codeInputs['input_ids']\n",
    "#     all_code_input_mask=codeInputs['attention_mask']\n",
    "    all_report_input_ids=[[0]for i in range(len(raw_code))]\n",
    "    all_report_input_mask=[[0]for i in range(len(raw_code))]\n",
    "    all_code_input_ids=[[0]for i in range(len(raw_code))]\n",
    "    all_code_input_mask=[[0]for i in range(len(raw_code))]\n",
    "    all_report_input_ids = torch.tensor(all_report_input_ids, dtype=torch.long)\n",
    "    all_report_input_mask = torch.tensor(all_report_input_mask, dtype=torch.long)\n",
    "    all_code_input_ids = torch.tensor(all_code_input_ids, dtype=torch.long)\n",
    "    all_code_input_mask = torch.tensor(all_code_input_mask, dtype=torch.long)\n",
    "    \n",
    "    all_cnn_report_idx=torch.tensor(all_cnn_report_idx, dtype=torch.long)\n",
    "    all_code_idx=torch.tensor(all_code_idx, dtype=torch.long)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.long)\n",
    "    pickle.dump([all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels],open(\"/data/hdj/cross_project_trans/report/bert/\"+project+\"test_middle/test_\"+ttype+\".in\", \"wb\"),protocol = 4)\n",
    "    dataset = TensorDataset(all_report_input_ids, all_report_input_mask, all_code_input_ids, all_code_input_mask,all_cnn_report_idx,\n",
    "                          all_code_idx, all_labels)\n",
    "#     if ttype=='train':\n",
    "    return dataset\n",
    "#     else:\n",
    "#         return dataset,data\n",
    "import torch\n",
    "project='swt_'\n",
    "for test_index in range(100):\n",
    "    test=pd.read_pickle('/data/hdj/cross_project_trans/report/bert/'+project+'test_middle/test'+str(test_index)+'.pkl')\n",
    "    data_tensor_generate_test(test,project,tokenizer=None,maxLength=256,ttype=str(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为python脚本NP_CNN_hdj准备数据结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"/data/hdj/cross_project_trans/report/bert/test_middle0.csv\",\"rb\"))\n",
    "import pickle\n",
    "Y = pickle.load(open(\"/data/hdj/cross_project_trans/report/bert/swt_test_middle/test0.pkl\",\"rb\"))\n",
    "# #老版本代码\n",
    "# top10_all = []\n",
    "# MRR_all = []\n",
    "# MAP_all = []\n",
    "\n",
    "# for test_index in range(58):\n",
    "#     X = pickle.load(open(\"/home/hdj/NPCNN_hdj/middle/test_middle\"+str(test_index)+\".csv\",\"rb\"))\n",
    "#     test_report,test_code,test_labels = X[0],X[1],X[2]\n",
    "#     test_report = np.array(test_report,dtype='int')[:,:308]#TODO 308 表示最大report长度+2*filter_h\n",
    "#     test_code = np.array(test_code,dtype='int')\n",
    "#     test_labels = np.array(test_labels,dtype='int')\n",
    "#    # print(test_code.shape,test_report.shape,train_labels.shape)\n",
    "#     test_code_x, test_report_x, test_label = get_testsets(test_code,test_report,test_labels)\n",
    "# #     test_code_x = W[test_code_x].reshape(300*config.codeLineNums,config.wordNums,config.embedding_size)#300*50 TODO 100 表示最大语句数量 40表示每个statement最大词汇\n",
    "# #     test_report_x = W[test_report_x]\n",
    "#     test_code_x = embedding(torch.tensor(test_code_x)).reshape(300*config.codeLineNums,config.wordNums,config.embedding_size)\n",
    "#     test_report_x=embedding(torch.tensor(test_report_x))\n",
    "#     test_code_x = torch.tensor(test_code_x).to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "#     test_report_x = torch.tensor(test_report_x).to(device, dtype=torch.float).cuda(non_blocking=True)\n",
    "#     print('test_code_x :',test_code_x.shape,'test_report_x :',test_report_x.shape)\n",
    "#     output=model(test_code_x,test_report_x)\n",
    "# #     y_train = torch.tensor(y_train).to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#     #print(test_code_x.shape,test_report_x.shape)\n",
    "    \n",
    "#     #pre,label = sess.run([prediction,output_label],feed_dict={x1:test_code_x,x2:test_report_x,keep_prob:0.25})\n",
    "#     #print(pre,label)\n",
    "#     test_p = output[:,1]\n",
    "#     test_y_labels = test_labels\n",
    "#    # top10 = eval_y(test_p, label, test_y_labels)\n",
    "#     #top10_all.append(top10)\n",
    "# #print('top10:', np.mean(top10_all))\n",
    "\n",
    "\n",
    "#     top10,MRR,MAP = eval_y(test_p, test_y_labels)\n",
    "#     top10_all.append(top10)\n",
    "#     MRR_all.append(MRR)\n",
    "#     MAP_all.append(MAP)\n",
    "\n",
    "# print('top10:', np.mean(top10_all))\n",
    "# print('MRR:', np.mean(MRR_all))\n",
    "# print('MAP:',np.mean(MAP_all))\n",
    "# #16:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeInput = torch.randn(32*100, 40,300)\n",
    "# reportInput=torch.randn(32,150,300)\n",
    "# output=cnnMode(codeInput,reportInput)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
