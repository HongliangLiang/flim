{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载包 定义相关util函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python3 run_classifier_mymodel.py \\\n",
    "--model_type roberta \\\n",
    "--task_name codesearch \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--eval_all_checkpoints \\\n",
    "--train_file aspectj_train.txt \\\n",
    "--dev_file aspectj_val.txt \\\n",
    "--max_seq_length 256 \\\n",
    "--per_gpu_train_batch_size 32 \\\n",
    "--per_gpu_eval_batch_size 32 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 10 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--overwrite_output_dir \\\n",
    "--data_dir /data/hdj/SourceFile/data/sourceFile_aspectj/train_valid \\\n",
    "--output_dir ./models/java/ghm  \\\n",
    "--model_name_or_path microsoft/codebert-base > ghm_10epoches_0506_summary_code_256.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python3 run_classifier.py \\\n",
    "--model_type roberta \\\n",
    "--task_name codesearch \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--eval_all_checkpoints \\\n",
    "--train_file aspectj_train.txt \\\n",
    "--dev_file aspectj_val.txt \\\n",
    "--max_seq_length 512 \\\n",
    "--per_gpu_train_batch_size 8 \\\n",
    "--per_gpu_eval_batch_size 8 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 10 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--overwrite_output_dir \\\n",
    "--data_dir /data/hdj/SourceFile/data/sourceFile_aspectj/train_valid \\\n",
    "--output_dir ./models/java  \\\n",
    "--model_name_or_path microsoft/codebert-base > 0507_10ep_512_summary_code_256.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python3 run_classifier.py \\\n",
    "--model_type roberta \\\n",
    "--model_name_or_path microsoft/codebert-base \\\n",
    "--task_name codesearch \\\n",
    "--do_predict \\\n",
    "--output_dir ../data/codesearch/test/aspectj_test/aspectj/ \\\n",
    "--data_dir /data/hdj/SourceFile/data/sourceFile_aspectj/train_valid/ \\\n",
    "--max_seq_length 512 \\\n",
    "--per_gpu_train_batch_size 256 \\\n",
    "--per_gpu_eval_batch_size 256 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 8 \\\n",
    "--test_file aspectj_test.txt  \\\n",
    "--pred_model_dir /data/hdj/data/CodeBERT/codesearch/models/java/checkpoint-best \\\n",
    "--test_result_dir ./results/java/0507_10epoches_aspectj_summary_code_512.txt > 0507_10epoches_aspectj_summary_code_512.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python3 main.py > res.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, AdamW\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import (compute_metrics, convert_examples_to_features,\n",
    "                        output_modes, processors)\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from transformers import (WEIGHTS_NAME, get_linear_schedule_with_warmup, AdamW,\n",
    "                          RobertaConfig,\n",
    "                          RobertaForSequenceClassification,\n",
    "                          RobertaTokenizer)\n",
    "from CodeBertModel import TextCNNClassifer_pair,TextCNNClassifer_pair_nofeature,TextCNNClassifer_cosloss\n",
    "import os\n",
    "# for i in range(58):\n",
    "#     os.system('python3 run_classifier.py --model_type roberta --model_name_or_path microsoft/codebert-base --task_name codesearch --do_predict --output_dir ../data/codesearch/test/ --data_dir ../data/codesearch/test/ --max_seq_length 512 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-5 --num_train_epochs 8 --test_file aspectj_'+str(i)+'.txt  --pred_model_dir ./models/java/checkpoint-best/ --test_result_dir ./results/java/batch_result_'+str(i)+'.txt')\n",
    "from more_itertools import chunked\n",
    "def calculate_same_value(labels_sorted, test_p_sorted, start_pos):\n",
    "    i = start_pos\n",
    "    num_same = 0\n",
    "    num_p = 0\n",
    "    while test_p_sorted[start_pos] == test_p_sorted[i]:\n",
    "        num_same = num_same + 1\n",
    "        if labels_sorted[i] ==1 : num_p = num_p + 1\n",
    "        i = i + 1\n",
    "        if i == len(labels_sorted ): break\n",
    "    return num_p, num_same\n",
    "def eval_mrr(test_p, labels):#在第二维相似度得分，真实标签\n",
    "    test_p_sorted = test_p\n",
    "    test_p_index = sorted(range(len(test_p_sorted)), key=lambda k: test_p_sorted[k], reverse=True)  # 降序排序\n",
    "    test_p_sorted = sorted(test_p, reverse=True)\n",
    "\n",
    "    labels_sorted = []\n",
    "    for index in test_p_index:\n",
    "        labels_sorted.append(labels[index])\n",
    "\n",
    "    top_num = 10\n",
    "    top10rank = 0\n",
    "    for i in range(top_num):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            '''\n",
    "            num_p, num_s = calculate_same_value(labels_sorted, test_p_sorted, i)\n",
    "            num_r = top_num - i\n",
    "            if num_p > (num_s-num_r):\n",
    "                top10rank = 1\n",
    "                break\n",
    "            v1 = perm(num_s-num_r, num_p)*perm(num_s-num_p,num_s-num_p)\n",
    "            v2 = perm(num_s,num_s)\n",
    "            top10rank = 1-(float)((float)(v1)/(float)(v2))\n",
    "            if top10rank > 1: top10rank=1\n",
    "            if top10rank!=top10rank: top10rank=1\n",
    "            break\n",
    "\n",
    "    return top10rank\n",
    "\n",
    "    '''\n",
    "            top10rank = 1\n",
    "            break\n",
    "    num_p, num_s = calculate_same_value(labels_sorted, test_p_sorted, 10)\n",
    "    if (num_p >= 1): top10rank = 1  # 统计在第十位并列排名相同的文件中，是否含有相关文件\n",
    "\n",
    "    MRRrank = 0.0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            MRRrank = MRRrank + float(1 / (i + 1))\n",
    "\n",
    "    MAPrank = 0.0\n",
    "    pos_num = 0\n",
    "    for i in range(len(labels_sorted)):\n",
    "        if (labels_sorted[i] == 1):\n",
    "            pos_num = pos_num + 1\n",
    "            MAPrank = MAPrank + float(pos_num / (i + 1))\n",
    "    if pos_num==0:\n",
    "        print('出现不存在pos的例子')\n",
    "        pos_num=1\n",
    "    MAPrank = float(MAPrank / pos_num)\n",
    "    MRRrank = float(MRRrank / pos_num)\n",
    "\n",
    "    return top10rank, MRRrank, MAPrank\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "#     print(type(preds),type(labels))\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc_and_f1(preds, labels):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"acc_and_f1\": (acc + f1) / 2,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "\n",
    "    return acc_and_f1(preds, labels)\n",
    "#设置种子，为了结果复现\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_type = 'roberta'\n",
    "        self.output_dir='/data/hdj/data/CodeBERT/codesearch/models/java'\n",
    "        self.test_result_dir='/data/hdj/tracking_buggy_files/joblib_memmap_eclipse/notebook_0607_test_2hard_2_data.txt'\n",
    "        self.start_epoch=0\n",
    "        self.config_name=''\n",
    "        self.model_name_or_path=None\n",
    "        self.task_name='codesearch'\n",
    "        self.tokenizer_name=''\n",
    "        self.model_name_or_path='microsoft/codebert-base'\n",
    "        self.do_lower_case=True\n",
    "        self.seed=42\n",
    "        self.gradient_accumulation_steps=1\n",
    "        self.weight_decay=0.0\n",
    "        self.max_grad_norm=1.0\n",
    "        self.learning_rate=2e-5#1e-6 5e-5\n",
    "        self.adam_epsilon=1e-8\n",
    "        self.warmup_steps=0\n",
    "        self.max_steps=-1\n",
    "        self.num_train_epochs=4\n",
    "# class args(object):\n",
    "#     \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.model_type = 'codesearch'\n",
    "#         self.output_dir='/data/hdj/data/CodeBERT/codesearch/models/java'\n",
    "#         self.test_result_dir='/data/hdj/data/CodeBERT/codesearch/results/java/test_v1_0414.txt'\n",
    "#         self.start_epoch=0\n",
    "#         self.num_train_epochs=1\n",
    "#         self.model_type='roberta'\n",
    "args=args()\n",
    "#带权重的交叉熵\n",
    "# weights=torch.tensor([0.2,0.8]).cuda()\n",
    "# loss_fun=CrossEntropyLoss(weight=weights)\n",
    "#不带权重的交叉熵\n",
    "loss_fun=CrossEntropyLoss()\n",
    "#设置种子 复现结果\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8356)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=torch.tensor([[0.1,0.3],[0.2,0.5],[0.6,0.3]])\n",
    "targets=torch.tensor([0,0,1])\n",
    "loss_fun(pred,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#加载GraphCodeBert模型代码\n",
    "# from transformers import AutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "# model = AutoModel.from_pretrained(\"/home/hdj/graphcodebert-base\")\n",
    "#加载完毕\n",
    "\n",
    "# print(model) 打印模型结构信息\n",
    "# model.config 打印模型配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hdj/tracking_buggy_files/joblib_memmap_swt/one_vs_two/cached_train_train_3hard_1_train_data_codebert-base_256_codesearch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttype='train'\n",
    "# test_file = \"test_3hard_2_data.txt\"#目前只使用一个例子来进行测试，后期增加数据量\n",
    "# train_file='aspectj_train_oversample.txt'\n",
    "train_file='train_3hard_1_train_data.txt'\n",
    "# dev_file = \"aspectj_val_oversample.txt\"\n",
    "max_seq_length=512\n",
    "task='codesearch'\n",
    "data_dir=\"/data/hdj/tracking_buggy_files/joblib_memmap_swt/one_vs_two/\"\n",
    "file_name = train_file.split('.')[0]\n",
    "# dev_file = \"train_3hard_1_valid_data.txt\"\n",
    "cached_features_file = os.path.join(data_dir, 'cached_{}_{}_{}_{}_{}'.format(\n",
    "        ttype,\n",
    "        file_name,\n",
    "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
    "        str(max_seq_length),\n",
    "        str(task)))\n",
    "cached_features_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载并向量化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据并保存在cache里\n",
    "def load_and_cache_examples(file_prefix,data_dir,train_file,dev_file,test_file, task, tokenizer,max_seq_length, ttype='train',need_feature=False):\n",
    "    '''\n",
    "        data_dir:数据目录\n",
    "        train_file:训练文件\n",
    "        dev_file:验证文件\n",
    "        test_file:测试文件\n",
    "        task:任务名 固定为codesearch\n",
    "        tokenizer:分词器\n",
    "        max_seq_length:最大序列长度 convert_examples_to_features使用到了\n",
    "        ttype:类型 train dev test\n",
    "        \n",
    "        return：包装好的数据集 [all_input_ids, all_input_mask, all_segment_ids, all_label_ids]\n",
    "    '''\n",
    "    processor = processors[task]()#拿到CodesearchProcessor\n",
    "    output_mode = output_modes[task]#输出模式 固定为 classification\n",
    "    # if os.path.exists(cached_features_file):\n",
    "\n",
    "    label_list = processor.get_labels()#固定为 [\"0\",\"1\"]\n",
    "\n",
    "    '''\n",
    "        example结构：[InputExample(uid 'test-1',report,code,label)]\n",
    "    '''\n",
    "    if ttype == 'train':\n",
    "        file_name = train_file.split('.')[0]\n",
    "    elif ttype == 'dev':\n",
    "        file_name = dev_file.split('.')[0]\n",
    "    elif ttype == 'test':\n",
    "        file_name = test_file.split('.')[0]\n",
    "    cached_features_file = os.path.join(data_dir, 'cached_{}_{}_{}_{}_{}'.format(\n",
    "        ttype,\n",
    "        file_name,\n",
    "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
    "        str(max_seq_length),\n",
    "        str(task)))\n",
    "    try:\n",
    "        print('直接加载cache文件')\n",
    "        print('cached_features_file :',cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "        if ttype == 'test':\n",
    "            examples, instances = processor.get_test_examples(data_dir, test_file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('生成cache文件')\n",
    "        examples=None\n",
    "        if ttype == 'train':\n",
    "            examples = processor.get_train_examples(data_dir, train_file)\n",
    "        elif ttype == 'dev':\n",
    "            examples = processor.get_dev_examples(data_dir=data_dir, dev_file= dev_file)\n",
    "        elif ttype == 'test':\n",
    "            #如果是test的话，instances就是[每一行是一条代测试的数据]\n",
    "            examples, instances = processor.get_test_examples(data_dir, test_file)\n",
    "\n",
    "        '''\n",
    "            example:[[uid,report,code,label],[]...]\n",
    "            label_list:['0','1']\n",
    "            max_seq_length:200\n",
    "            tokenizer:分词器\n",
    "            output_mode:输出模式 固定为 classification\n",
    "            cls_token:用来分类的token     '<s>', 0, \n",
    "            sep_token:用来分割语句的token '</s>', 2\n",
    "\n",
    "            return：[  [       ( input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id)\n",
    "                        ]\n",
    "                    ]\n",
    "                    instances：[[\"0\",\"5222\",\"i am a noy\",\"public class\"],[],,]\n",
    "        '''\n",
    "    #     features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\n",
    "    #                                             cls_token=tokenizer.cls_token,\n",
    "    #                                             sep_token=tokenizer.sep_token,\n",
    "    #                                            )\n",
    "        features =convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\n",
    "                                                    cls_token_at_end=bool(args.model_type in ['xlnet']),\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    cls_token_segment_id=2 if args.model_type in ['xlnet'] else 1,\n",
    "                                                    pad_on_left=bool(args.model_type in ['xlnet']),\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token_segment_id=4 if args.model_type in ['xlnet'] else 0)\n",
    "        torch.save(features, cached_features_file)\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    \n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    if need_feature:\n",
    "        feature=torch.tensor([f.feature for f in features],dtype=torch.float16)\n",
    "        print('human_feature :',feature)\n",
    "        dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,feature)\n",
    "    else:\n",
    "        dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    if (ttype == 'test'):\n",
    "        return dataset, instances\n",
    "    else:\n",
    "        return dataset\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\",do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_len=[]\n",
    "code_len=[]\n",
    "nl_content=set()\n",
    "code_content=set()\n",
    "with open('/data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/train_2hard_1_train_source_nomethod.txt','r',encoding='utf-8') as f_in:\n",
    "    for line in f_in:\n",
    "        contents=line.split('<CODESPLIT>')\n",
    "        nl_content.add(contents[3])\n",
    "        code_content.add(contents[4])\n",
    "for con in nl_content:\n",
    "    nl_tokens=tokenizer.tokenize(con)\n",
    "    nl_len.append(len(nl_tokens))\n",
    "for con in code_content:\n",
    "    nl_tokens=tokenizer.tokenize(con)\n",
    "    code_len.append(len(nl_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4267, 32399)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nl_len),len(code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl_len code 的 10% 13.0\n",
      "20 : 23.0\n",
      "30 : 40.0\n",
      "40 : 53.0\n",
      "50 : 67.0\n",
      "60 : 84.0\n",
      "70 : 112.0\n",
      "80 : 161.0\n",
      "90 : 362.4000000000001\n",
      "code_len code 的 10% 30.0\n",
      "20 : 52.0\n",
      "30 : 77.0\n",
      "40 : 105.0\n",
      "50 : 141.0\n",
      "60 : 187.0\n",
      "70 : 250.0\n",
      "80 : 348.0\n",
      "90 : 547.0\n"
     ]
    }
   ],
   "source": [
    "# summary_len=[]\n",
    "def statis(sourceLen,name):#list\n",
    "    a = np.array(sourceLen)\n",
    "    print(name,'code 的 10%', np.percentile(a, 10))\n",
    "    print('20 :', np.percentile(a, 20))\n",
    "    print('30 :', np.percentile(a, 30))\n",
    "    print('40 :', np.percentile(a, 40))\n",
    "    print('50 :', np.median(a))\n",
    "    print('60 :', np.percentile(a, 60))\n",
    "    print('70 :', np.percentile(a, 70))\n",
    "    print('80 :', np.percentile(a, 80))\n",
    "    print('90 :', np.percentile(a, 90))\n",
    "statis(nl_len,'nl_len')\n",
    "statis(code_len,'code_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "def convert_examples_to_features_hdj(examples,label_list,nl_max_len,max_len,tokenizer):\n",
    "    #code\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            print(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "            \n",
    "      \n",
    "       \n",
    "        nl=example.text_a\n",
    "        nl_tokens=tokenizer.tokenize(nl)\n",
    "#         print('nl token len :',len(nl_tokens))\n",
    "#         print('nl :',nl_tokens)\n",
    "        nl_tokens=nl_tokens[:nl_max_len]     \n",
    "        code=example.text_b\n",
    "        code_tokens=tokenizer.tokenize(code)\n",
    "#         print('code token len :',len(code_tokens))\n",
    "#         print('code :',code_tokens)\n",
    "        _truncate_seq_pair(nl_tokens, code_tokens, max_len - 3)\n",
    "        tokens = [tokenizer.cls_token]+nl_tokens + [tokenizer.sep_token]+code_tokens+ [tokenizer.sep_token]\n",
    "       \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        label_id = label_map[example.label]\n",
    "        padding_length = max_len - len(input_ids)\n",
    "        input_ids = input_ids + ([tokenizer.pad_token_id] * padding_length)\n",
    "        input_mask = input_mask + ([0] * padding_length)\n",
    "#         print('input_ids :',input_ids)\n",
    "#         print('input_mask :',input_mask)\n",
    "       \n",
    "        features.append(\n",
    "            InputFeatures_hdj(input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          label_id=label_id))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据并保存在cache里\n",
    "class InputFeatures_hdj(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_ids,\n",
    "                 input_mask,\n",
    "                 label_id,\n",
    "\n",
    "    ):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask=input_mask\n",
    "        self.label_id=label_id\n",
    "class InputFeatures_hdj_split(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 code_tokens,\n",
    "                 code_ids,\n",
    "                 code_mask,\n",
    "                 nl_tokens,\n",
    "                 nl_ids,\n",
    "                 nl_mask,\n",
    "                 label_id,\n",
    "\n",
    "    ):\n",
    "        self.code_tokens = code_tokens\n",
    "        self.code_ids = code_ids\n",
    "        self.code_mask=code_mask\n",
    "        self.nl_tokens = nl_tokens\n",
    "        self.nl_ids = nl_ids\n",
    "        self.nl_mask=nl_mask\n",
    "        self.label_id=label_id\n",
    "def convert_examples_to_features_hdj_split(examples,label_list,nl_max_len,max_len,tokenizer):\n",
    "    #code\n",
    "#     label_map = {'0':-1,'1':1}\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            print(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "            \n",
    "        code=example.text_b\n",
    "        code_tokens=tokenizer.tokenize(code)[:max_len-2]\n",
    "        code_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "        code_ids =  tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "        code_input_mask = [1] * len(code_ids)\n",
    "        padding_length = max_len - len(code_ids)\n",
    "        code_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "        code_input_mask+=[0]*padding_length\n",
    "\n",
    "        nl=example.text_a\n",
    "        nl_tokens=tokenizer.tokenize(nl)[:max_len-2]\n",
    "        nl_tokens =[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
    "        nl_ids =  tokenizer.convert_tokens_to_ids(nl_tokens)\n",
    "        nl_input_mask = [1] * len(nl_ids)\n",
    "        padding_length = max_len - len(nl_ids)\n",
    "        nl_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "        nl_input_mask+=[0]*padding_length\n",
    "        label_id = label_map[example.label]\n",
    "#         print('code_tokens :',code_tokens)\n",
    "#         print('code_ids :',code_ids)\n",
    "#         print('code_mask :',code_input_mask)\n",
    "        features.append(\n",
    "            InputFeatures_hdj_split(code_tokens = code_tokens,\n",
    "                            code_ids = code_ids,\n",
    "                            code_mask=code_input_mask,\n",
    "                            nl_tokens = nl_tokens,\n",
    "                            nl_ids = nl_ids,\n",
    "                            nl_mask=nl_input_mask,\n",
    "                            label_id=label_id))\n",
    "    return features\n",
    "def load_and_cache_examples_hdj(file_prefix,data_dir,train_file,dev_file,test_file, task, tokenizer,max_seq_length, ttype='train',need_feature=False):\n",
    "    '''\n",
    "        data_dir:数据目录\n",
    "        train_file:训练文件\n",
    "        dev_file:验证文件\n",
    "        test_file:测试文件\n",
    "        task:任务名 固定为codesearch\n",
    "        tokenizer:分词器\n",
    "        max_seq_length:最大序列长度 convert_examples_to_features使用到了\n",
    "        ttype:类型 train dev test\n",
    "        \n",
    "        return：包装好的数据集 [all_input_ids, all_input_mask, all_segment_ids, all_label_ids]\n",
    "    '''\n",
    "    processor = processors[task]()#拿到CodesearchProcessor\n",
    "    output_mode = output_modes[task]#输出模式 固定为 classification\n",
    "    # if os.path.exists(cached_features_file):\n",
    "\n",
    "    label_list = processor.get_labels()#固定为 [\"0\",\"1\"]\n",
    "\n",
    "    '''\n",
    "        example结构：[InputExample(uid 'test-1',report,code,label)]\n",
    "    '''\n",
    "    if ttype == 'train':\n",
    "        file_name = train_file.split('.')[0]\n",
    "    elif ttype == 'dev':\n",
    "        file_name = dev_file.split('.')[0]\n",
    "    elif ttype == 'test':\n",
    "        file_name = test_file.split('.')[0]\n",
    "    cached_features_file = os.path.join(data_dir, 'cached_{}_{}_{}_{}_{}'.format(\n",
    "        ttype,\n",
    "        file_name,\n",
    "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
    "        str(max_seq_length),\n",
    "        str(task)))\n",
    "    try:\n",
    "        print('直接加载cache文件')\n",
    "        print('cached_features_file :',cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "        if ttype == 'test':\n",
    "            examples, instances = processor.get_test_examples(data_dir, test_file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('生成cache文件')\n",
    "        examples=None\n",
    "        if ttype == 'train':\n",
    "            examples = processor.get_train_examples(data_dir, train_file)\n",
    "        elif ttype == 'dev':\n",
    "            examples = processor.get_dev_examples(data_dir=data_dir, dev_file= dev_file)\n",
    "        elif ttype == 'test':\n",
    "            #如果是test的话，instances就是[每一行是一条代测试的数据]\n",
    "            examples, instances = processor.get_test_examples(data_dir, test_file)\n",
    "\n",
    "        '''\n",
    "            example:[[uid,report,code,label],[]...]\n",
    "            label_list:['0','1']\n",
    "            max_seq_length:200\n",
    "            tokenizer:分词器\n",
    "            output_mode:输出模式 固定为 classification\n",
    "            cls_token:用来分类的token     '<s>', 0, \n",
    "            sep_token:用来分割语句的token '</s>', 2\n",
    "\n",
    "            return：[  [       ( input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id)\n",
    "                        ]\n",
    "                    ]\n",
    "                    instances：[[\"0\",\"5222\",\"i am a noy\",\"public class\"],[],,]\n",
    "        '''\n",
    "    #     features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\n",
    "    #                                             cls_token=tokenizer.cls_token,\n",
    "    #                                             sep_token=tokenizer.sep_token,\n",
    "    #                                            )\n",
    "        features =convert_examples_to_features_hdj_split(examples, label_list, nl_max_len,max_seq_length, tokenizer)\n",
    "        torch.save(features, cached_features_file)\n",
    "    # Convert to Tensors and build dataset\n",
    "#     all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "#     all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_code_input_ids = torch.tensor([f.code_ids for f in features], dtype=torch.long)\n",
    "    all_code_input_mask = torch.tensor([f.code_mask for f in features], dtype=torch.long)\n",
    "    all_nl_input_ids = torch.tensor([f.nl_ids for f in features], dtype=torch.long)\n",
    "    all_nl_input_mask = torch.tensor([f.nl_mask for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    if need_feature:\n",
    "        feature=torch.tensor([f.feature for f in features],dtype=torch.float16)\n",
    "        print('human_feature :',feature)\n",
    "        dataset = TensorDataset(all_code_input_ids, all_code_input_mask, all_nl_input_ids, all_nl_input_mask,all_label_ids,feature)\n",
    "    else:\n",
    "#         dataset = TensorDataset(all_input_ids, all_input_mask, all_label_ids)\n",
    "        dataset = TensorDataset(all_code_input_ids, all_code_input_mask, all_nl_input_ids,all_nl_input_mask,all_label_ids)\n",
    "    if (ttype == 'test'):\n",
    "        return dataset, instances\n",
    "    else:\n",
    "        return dataset\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")#,do_lower_case="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接加载cache文件\n",
      "cached_features_file : /data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_train_train_2hard_1_train_source_nomethod_less_codebert-base_512_codesearch\n",
      "直接加载cache文件\n",
      "cached_features_file : /data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_dev_train_2hard_1_val_source_nomethod_less_codebert-base_512_codesearch\n"
     ]
    }
   ],
   "source": [
    "project='eclipse'\n",
    "file_prefix='/data/hdj/tracking_buggy_files/'+project+'/'+project\n",
    "data_dir = \"/data/hdj/tracking_buggy_files/joblib_memmap_\"+project+\"/one_vs_two/\"\n",
    "test_dir=\"/data/hdj/tracking_buggy_files/joblib_memmap_\"+project+\"/one_vs_two/\" #注意目前测试集的目录是单独的，更换测试数据需要更改\n",
    "# train_file = \"aspectj_train_small.txt\"\n",
    "# dev_file = \"aspectj_val_small.txt\"\n",
    "test_file = \"test_2hard_2_2tok5meth_data.txt\"#目前只使用一个例子来进行测试，后期增加数据量\n",
    "# train_file='aspectj_train_oversample.txt'\n",
    "train_file='train_2hard_1_train_source_nomethod_less.txt'\n",
    "# dev_file = \"aspectj_val_oversample.txt\"\n",
    "dev_file = \"train_2hard_1_val_source_nomethod_less.txt\"\n",
    "task_name = \"codesearch\"\n",
    "max_seq_length = 512#关键参数设置 整个序列的最大长度\n",
    "need_feature=False\n",
    "nl_max_len=128\n",
    "train_set = load_and_cache_examples_hdj(file_prefix,data_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'train')\n",
    "val_set=load_and_cache_examples_hdj(file_prefix,data_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_set.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   22782 MB |   22824 MB |   36076 MB |   13294 MB |\n",
      "|       from large pool |   22778 MB |   22820 MB |   36070 MB |   13292 MB |\n",
      "|       from small pool |       3 MB |       3 MB |       5 MB |       1 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   22782 MB |   22824 MB |   36076 MB |   13294 MB |\n",
      "|       from large pool |   22778 MB |   22820 MB |   36070 MB |   13292 MB |\n",
      "|       from small pool |       3 MB |       3 MB |       5 MB |       1 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   22844 MB |   22868 MB |   22868 MB |   24576 KB |\n",
      "|       from large pool |   22840 MB |   22864 MB |   22864 MB |   24576 KB |\n",
      "|       from small pool |       4 MB |       4 MB |       4 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   63299 KB |   70745 KB |     933 MB |     872 MB |\n",
      "|       from large pool |   63232 KB |   69120 KB |     925 MB |     864 MB |\n",
      "|       from small pool |      67 KB |    2067 KB |       7 MB |       7 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     655    |     656    |    1116    |     461    |\n",
      "|       from large pool |     428    |     429    |     729    |     301    |\n",
      "|       from small pool |     227    |     227    |     387    |     160    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     655    |     656    |    1116    |     461    |\n",
      "|       from large pool |     428    |     429    |     729    |     301    |\n",
      "|       from small pool |     227    |     227    |     387    |     160    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     342    |     343    |     343    |       1    |\n",
      "|       from large pool |     340    |     341    |     341    |       1    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      25    |      26    |      93    |      68    |\n",
      "|       from large pool |      21    |      21    |      68    |      47    |\n",
      "|       from small pool |       4    |       7    |      25    |      21    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接加载cache文件\n",
      "cached_features_file : /data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_train_train_2hard_1_train_source_nomethod_codebert-base_256_codesearch\n",
      "[Errno 2] No such file or directory: '/data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_train_train_2hard_1_train_source_nomethod_codebert-base_256_codesearch'\n",
      "生成cache文件\n",
      "直接加载cache文件\n",
      "cached_features_file : /data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_dev_train_2hard_1_val_source_nomethod_codebert-base_256_codesearch\n",
      "[Errno 2] No such file or directory: '/data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_dev_train_2hard_1_val_source_nomethod_codebert-base_256_codesearch'\n",
      "生成cache文件\n"
     ]
    }
   ],
   "source": [
    "#数据集的配置参数\n",
    "project='eclipse'\n",
    "file_prefix='/data/hdj/tracking_buggy_files/'+project+'/'+project\n",
    "data_dir = \"/data/hdj/tracking_buggy_files/joblib_memmap_\"+project+\"/one_vs_two/\"\n",
    "test_dir=\"/data/hdj/tracking_buggy_files/joblib_memmap_\"+project+\"/one_vs_two/\" #注意目前测试集的目录是单独的，更换测试数据需要更改\n",
    "# train_file = \"aspectj_train_small.txt\"\n",
    "# dev_file = \"aspectj_val_small.txt\"\n",
    "test_file = \"test_2hard_2_2tok5meth_data.txt\"#目前只使用一个例子来进行测试，后期增加数据量\n",
    "# train_file='aspectj_train_oversample.txt'\n",
    "train_file='train_2hard_1_train_source_nomethod_less.txt'\n",
    "# dev_file = \"aspectj_val_oversample.txt\"\n",
    "dev_file = \"train_2hard_1_val_source_nomethod_less.txt\"\n",
    "task_name = \"codesearch\"\n",
    "max_seq_length = 256#关键参数设置 整个序列的最大长度\n",
    "need_feature=False\n",
    "#加载数据集\n",
    "#这里load_and_cache_examples 是没有将数据进行缓存的，和codeBert里的同名函数意义不一样，所以统一按照每次都读取数据这样的模式来处理\n",
    "train_set = load_and_cache_examples(file_prefix,data_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'train')\n",
    "val_set = load_and_cache_examples(file_prefix,data_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'dev')\n",
    "# # test_set, instances=load_and_cache_examples(test_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #将数据进行batch_size设置\n",
    "batch_size = 8 #关键参数\n",
    "training_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=False)\n",
    "#测试集顺序不应该打乱，不然后期就对不上了 shuffle的作用是在枚举的时候才会改变顺序 \n",
    "# testing_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64 #关键参数\n",
    "# val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集比例 tensor(-52621) 148299 tensor(-0.3548)\n",
      "验证集比例 tensor(-5974) 16450 tensor(-0.3632)\n"
     ]
    }
   ],
   "source": [
    "#目前train val数据集比较不均衡 test数据集比较均衡\n",
    "print('训练集比例',sum(list(training_loader.dataset.tensors[2])),len(training_loader.dataset.tensors[2]),sum(list(training_loader.dataset.tensors[2]))/len(training_loader.dataset.tensors[2]))\n",
    "print('验证集比例',sum(list(val_loader.dataset.tensors[2])),len(val_loader.dataset.tensors[2]),sum(list(val_loader.dataset.tensors[2]))/len(val_loader.dataset.tensors[2]))\n",
    "# print('测试集比例',sum(list(testing_loader.dataset.tensors[3])),len(testing_loader.dataset.tensors[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载 设计好 小数据 均匀一些 方便切换大数据 \n",
    "#方便添加多个训练集的数据 进行数据拆分重组\n",
    "#添加数据统计模块 数据均衡度如何 \n",
    "#定义好数据的格式 比例\n",
    "#各个函数的参数类型 格式 方便查找 不然又忘了\n",
    "#train val test\n",
    "\n",
    "#训练采用codeBERT GraphCodeBert 或者使用cnn/ast + codeBERT/GraphCodeBert\n",
    "#模型1 [codeBert]\n",
    "#模型2 [GraphCodeBert]\n",
    "#模型3 [cnn,codeBert]\n",
    "#模型4 [cnn,GraphCodeBert]\n",
    "#模型5 [ast,codeBert]\n",
    "#模型6 [ast,GraphCodeBert]\n",
    "#模型7 [cnn,ast,codeBert/GraphCodeBert]\n",
    "#模型8 [cnn,ast,codeBert/GraphCodeBert]\n",
    "#训练采用cross_entroy作为损失函数/复杂一点的使用triplet loss,val时就采用 f1、map mrr top来衡量 测试也是使用一样的指标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型加载和信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/hdj/data/CodeBERT/Siamese-model/saved_models/java/checkpoint-best-mrr/model.bin\n"
     ]
    }
   ],
   "source": [
    "#模型1的实现\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "google_v=False #当为true时，使用RobertClassification模型\n",
    "num_labels=2\n",
    "class Model(nn.Module):   \n",
    "    def __init__(self, encoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "      \n",
    "    def forward(self, code_inputs=None, nl_inputs=None): \n",
    "        if code_inputs is not None:\n",
    "            return self.encoder(code_inputs,attention_mask=code_inputs.ne(1))[1]\n",
    "        else:\n",
    "            return self.encoder(nl_inputs,attention_mask=nl_inputs.ne(1))[1]\n",
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)}\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path,\n",
    "                                     num_labels=num_labels, finetuning_task=args.task_name)\n",
    "# if google_v:\n",
    "#     model = model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path),\n",
    "#                                     config=config)\n",
    "#     print('使用RobertClassification 模型')\n",
    "# else:\n",
    "#     if need_feature:\n",
    "#         model = TextCNNClassifer_pair()\n",
    "#     else:\n",
    "#         model = TextCNNClassifer_pair_nofeature()\n",
    "# #         model=TextCNNClassifer_cosloss()\n",
    "#     print('使用TextCNNClassifier模型')\n",
    "checkpoint_prefix = 'checkpoint-best-mrr/model.bin'\n",
    "output_dir = os.path.join('/data/hdj/data/CodeBERT/Siamese-model/saved_models/java', '{}'.format(checkpoint_prefix)) \n",
    "print(output_dir)\n",
    "model = RobertaModel.from_pretrained(args.model_name_or_path)    \n",
    "model=Model(model)\n",
    "model.load_state_dict(torch.load(output_dir),strict=False)      \n",
    "# model.to(args.device)\n",
    "_ = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_v or True:\n",
    "    #Google: 使用的优化器和迭代器\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    #Google\n",
    "else:\n",
    "#     hdj: textCNNClassifier 使用的优化器和计划器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-05, betas=(0.9, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "#     hdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "tb_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用cosloss的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始验证模型的有效性 把模型预测结果连同数据一起保存起来 然后再去判断top mrr mAP\n",
    "#流程 1.训练过程中 每个10轮去在val集上验证 比较f1值是否优于之前，是就保存结果到best，2.每次保存上一次验证的结果 3.最后再在test集上进行测试\n",
    "\n",
    "#check 词表是否与之前model有很大的不同 如果有那么该怎么改善，之前embedding矩阵是否就作废了\n",
    "def evaluate(args, model,eval_loader,instances,tokenizer, checkpoint=None, prefix=\"\", mode='dev'):\n",
    "    '''\n",
    "        args:模型训练时关键参数\n",
    "        model：待验证的模型\n",
    "        eval_loader:待验证的数据集 DataLoader 类型的参数\n",
    "        instances: 若为test模式，则将原始数据输入进来，然后将预测结果一起保存，等待后面计算TOP MAP MRR使用\n",
    "        tokenizer:分词器\n",
    "        checkpoint: 检查点\n",
    "        prefix:前缀\n",
    "        mode: 模式 分为 dev 和 test（需要保存数据）\n",
    "        \n",
    "        return: dict{'acc':,'f1':,'acc_f1'} 主要关注f1的值 越大说明正例的预测越准\n",
    "    '''\n",
    "    #待返回的验证结果\n",
    "    results={}\n",
    "    eval_loss = 0.0 #验证损失累加\n",
    "#     nb_eval_steps = len(test_set)/batch_size #验证批次\n",
    "    preds = None #保存预测的值\n",
    "    out_label_ids = None #保存真实标签target\n",
    "    print('开始验证。。。')\n",
    "    for _, data in enumerate(eval_loader, 0):#start=0 默认就是0\n",
    "        with torch.no_grad():\n",
    "            code_input_ids = data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            code_input_mask = data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            nl_input_ids= data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            nl_input_mask= data[3].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        #     token_type_ids = data[2].to(device, dtype=torch.long).cuda(non_blocking=True) 因为模型不支持2维设置 所以不再输入这个参数\n",
    "            targets = data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            if need_feature:\n",
    "                feature = data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            if google_v:\n",
    "                pred = model(input_ids=ids, attention_mask=mask,token_type_ids=None, labels=targets)\n",
    "                loss=pred[0]\n",
    "            else:\n",
    "                if need_feature:\n",
    "                    pred = model(ids, mask,feature)#输出是[batch_size,2]\n",
    "                else:\n",
    "                    #get code and nl vectors\n",
    "                    code_vec = model(code_inputs=code_input_ids)\n",
    "                    nl_vec = model(nl_inputs=nl_input_ids)\n",
    "#                     loss,code_vec,nl_vec = model(code_input_ids, code_input_mask,nl_input_ids,nl_input_mask,targets)\n",
    "#                     print(loss,code_vec,nl_vec)\n",
    "            # print(pred, target)\n",
    "#             loss=floss(pred,targets)\n",
    "#             loss = loss_fun(pred, targets)\n",
    "#             pred_choice = pred.max(1)[1]\n",
    "#             correct = pred_choice.eq(targets).cpu().sum()\n",
    "#             metrics = compute_metrics(pred_choice.cpu().numpy(), targets.cpu().numpy())\n",
    "#             print('[',epoch,': ',_,'/',nb_eval_steps,'] ',blue('val'),\" loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(targets.cpu().numpy()),' ration :',sum(targets.cpu().numpy())/len(targets),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#             loss_list_val.append(loss.item())  \n",
    "            global eval_step\n",
    "            tb_writer.add_scalar('eval_loss', loss.item(), eval_step)\n",
    "#             tb_writer.add_scalar('eval_acc', correct.item() / float(batch_size), eval_step)\n",
    "#             tb_writer.add_scalar('eval_f1', metrics['f1'], eval_step)\n",
    "            eval_step+=1\n",
    "#             print(eval_step)\n",
    "            eval_loss += loss.item()\n",
    "            if(_%100==0):\n",
    "                print(_,'/',len(eval_loader),loss)\n",
    "#         nb_eval_steps += 1\n",
    "        #将preds值和标签进行保存\n",
    "#         if preds is None:\n",
    "#             if google_v:\n",
    "#                 preds = pred[1].detach().cpu()\n",
    "#             else:\n",
    "#                 preds=pred.detach().cpu()\n",
    "#             out_label_ids = targets.detach().cpu()\n",
    "#         else:\n",
    "#             if google_v:\n",
    "#                 preds = np.append(preds, pred[1].detach().cpu().numpy(), axis=0)\n",
    "#             else:    \n",
    "#                 preds = np.append(preds, pred.detach().cpu().numpy(), axis=0)\n",
    "#             out_label_ids = np.append(out_label_ids, targets.detach().cpu().numpy(), axis=0)       \n",
    "#     print('验证结束，开始计算指标',eval_loss)\n",
    "#     #计算指标，并更新结果\n",
    " \n",
    "#     #ndarra转换为tensor类型\n",
    "#     preds=torch.tensor(preds)\n",
    "#     out_label_ids=torch.tensor(out_label_ids)\n",
    "# #     print(type(preds),preds.shape,preds)\n",
    "# #     print(type(out_label_ids),out_label_ids.shape,out_label_ids)    \n",
    "#     pred_choice = preds.max(1)[1]#[batch_size,2]\n",
    "#     correct = pred_choice.eq(out_label_ids).cpu().sum() #eq需要tensor类型的数据\n",
    "#     #但是compute_metrics 需要numpy的数据类型 真烦人\n",
    "#     metrics = compute_metrics(pred_choice.numpy(), out_label_ids.numpy())\n",
    "#     results.update(metrics)\n",
    "    #计算完成\n",
    "    \n",
    "    #下面分dev 和 test 模式来完成数据模型的保存工作\n",
    "#     if(mode=='dev'):\n",
    "#         #这里只是把result字典里acc和f1给保存到文件\n",
    "#         output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "#         with open(output_eval_file, \"a+\") as writer:\n",
    "#             print(\"***** Eval results {} *****\".format(prefix))\n",
    "#             writer.write('evaluate %s\\n' % checkpoint)\n",
    "#             for key in sorted(results.keys()):\n",
    "#                 writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "#     elif(mode=='test'):\n",
    "#         #test结果目录 将test数据连同预测结果进行保存\n",
    "#         if(instances==None or len(instances)==0):\n",
    "#             print('输入的测试数据有问题 为None 或者 长度为0')\n",
    "#         #如果目录不存在就创建\n",
    "#         output_test_file = args.test_result_dir\n",
    "#         output_dir = os.path.dirname(output_test_file)\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "#         #检验创建目录完成\n",
    "#         with open(output_test_file, \"w\") as writer:\n",
    "#             print(\"***** Output test results *****\")\n",
    "#             preds = F.softmax(torch.tensor(preds))\n",
    "#             all_logits = preds.tolist()\n",
    "#             for i, logit in tqdm(enumerate(all_logits), desc='Testing'):#desc是进度条的标题\n",
    "#                 #instances即代表test集里每一行数据的值\n",
    "#                 instance_rep = '<CODESPLIT>'.join([item.encode('ascii', 'ignore').decode('ascii') for item in instances[i]])\n",
    "#                 writer.write(instance_rep + '<CODESPLIT>' + '<CODESPLIT>'.join([str(l) for l in logit]) + '\\n')\n",
    "#             #打印验证的结果\n",
    "#             for key in sorted(results.keys()):\n",
    "#                 print(\"%s = %s\" % (key, str(results[key])))\n",
    "#     return results\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training!!!\n",
      "5\n",
      "loss :0.1485\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0046\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0024\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0019\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0008\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0006\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0011\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0005\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0003\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0004\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0002\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0002\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0000\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0002\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0002\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "loss :0.0001\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "开始验证。。。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [13:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-81c1675327fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#             tb_writer.add_scalar('train_f1', metrics['f1'], global_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m#下面是在训练过程中进行验证 每一轮都会验证一次，保存模型最好的 和最近一次的模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;31m#     print('验证结果 ：',results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#torch.save(model, '%s/cls_model_%d.pth' % ('models', epoch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-89fed7cc75be>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args, model, eval_loader, instances, tokenizer, checkpoint, prefix, mode)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#             loss_list_val.append(loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mglobal\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#             tb_writer.add_scalar('eval_acc', correct.item() / float(batch_size), eval_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             tb_writer.add_scalar('eval_f1', metrics['f1'], eval_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#模型应该保存效果最好的那个，而不是训练到最后的那个模型\n",
    "print(\"training!!!\")\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "epoch=1\n",
    "best_f1=0.0 #保存最好的f1的模型\n",
    "model.zero_grad()\n",
    "set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "#这里就是在指定 一共训练多少Epoch [start_epoch,num_train_epcchs]\n",
    "t_total = len(training_loader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, args.warmup_steps, t_total)\n",
    "global_step=0\n",
    "eval_step=0\n",
    "embedding_loss=torch.nn.CosineEmbeddingLoss(margin=0.5, size_average=None, reduce=None, reduction='mean')\n",
    "train_iterator = trange(args.start_epoch, int(args.num_train_epochs), desc=\"Epoch\")\n",
    "model.train()\n",
    "for idx, p in enumerate(train_iterator):\n",
    "    num_batch = len(train_set) / batch_size #总共训练次数\n",
    "    for _, data in enumerate(training_loader, 0):#start=0 默认就是0\n",
    "        code_input_ids = data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        code_input_mask = data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        nl_input_ids= data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        nl_input_mask= data[3].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "    #     token_type_ids = data[2].to(device, dtype=torch.long).cuda(non_blocking=True) 因为模型不支持2维设置 所以不再输入这个参数\n",
    "        targets = data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        if need_feature:\n",
    "            feature=data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         print('feature shape: ',feature.shape)\n",
    "#         print(feature)\n",
    "        if google_v:\n",
    "#             outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=None, labels=targets)\n",
    "            loss=outputs[0]#google loss\n",
    "#             print(outputs)\n",
    "#             loss_hdj = loss_fun(outputs[1], targets)\n",
    "#             print('google loss ',loss,' loss_hdj :',loss_hdj)\n",
    "            pred_choice = outputs[1].max(1)[1]\n",
    "        else:\n",
    "            if need_feature:\n",
    "                outputs = model(ids, mask,feature)#输出是[batch_size,2]\n",
    "            else:\n",
    "                code_vec = model(code_inputs=code_input_ids)\n",
    "                nl_vec = model(nl_inputs=nl_input_ids)\n",
    "                loss=embedding_loss(code_vec,nl_vec,targets)\n",
    "#                 code_vec,nl_vec = model(code_input_ids, code_input_mask,nl_input_ids,nl_input_mask)\n",
    "            #使用floss\n",
    "#             loss=floss(outputs,targets)\n",
    "            #使用floss\n",
    "            #使用ghmloss\n",
    "#             ghm_target = targets.view(-1, 1)\n",
    "#             ghm_target=ghm_target.cpu()\n",
    "#             ghm_target = torch.LongTensor(ghm_target)\n",
    "#             # print(\"before target :\",targets)\n",
    "#             ghm_target = torch.zeros(len(ghm_target), 2).scatter_(1, ghm_target, 1)\n",
    "#             outputs=outputs.cpu()\n",
    "#             loss=ghm(outputs,ghm_target)\n",
    "            #使用ghmloss\n",
    "            # print(outputs)\n",
    "            \n",
    "            #交叉熵loss\n",
    "#             loss = loss_fun(outputs, targets)\n",
    "            #交叉熵loss\n",
    "    \n",
    "    #         print('查看target和ouput的类型 检查max函数返回的东西是否正确',type(outputs),type(targets))\n",
    "        #     print(outputs)\n",
    "            #取outputs二维中最大维的下标\n",
    "#             pred_choice = outputs.max(1)[1]\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "             loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        \n",
    "#         targets=targets.cpu()\n",
    "#         correct = pred_choice.eq(targets).cpu().sum()\n",
    "#         metrics = compute_metrics(pred_choice.cpu().numpy(), targets.cpu().numpy())\n",
    "        if _ %100 == 0:\n",
    "            print(\"loss :%.4f\" % loss.item())\n",
    "#             print('[',epoch,':',_,'/',num_batch,']',\"loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(targets.cpu().numpy()),' ration :',sum(targets.cpu().numpy())/len(targets),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#         loss_list.append(loss.item())\n",
    "#         acc_list.append(correct.item() / float(batch_size))\n",
    "        if(_+1)%args.gradient_accumulation_steps == 0:\n",
    "            global_step+=1\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "            tb_writer.add_scalar('train_loss', loss.item(), global_step)\n",
    "#             tb_writer.add_scalar('train_acc', correct.item() / float(batch_size), global_step)\n",
    "#             tb_writer.add_scalar('train_f1', metrics['f1'], global_step)\n",
    "    #下面是在训练过程中进行验证 每一轮都会验证一次，保存模型最好的 和最近一次的模型\n",
    "    results = evaluate(args, model,val_loader,None ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='dev')\n",
    "#     print('验证结果 ：',results)\n",
    "    #torch.save(model, '%s/cls_model_%d.pth' % ('models', epoch))\n",
    "    #./models/java/checkpoint-last\n",
    "    last_output_dir = os.path.join(args.output_dir, 'checkpoint-last')\n",
    "    if not os.path.exists(last_output_dir):\n",
    "        os.makedirs(last_output_dir)\n",
    "#     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#     model_to_save.save_pretrained(last_output_dir)\n",
    "    torch.save(model, '%s/cls_model_%d.pth' % (last_output_dir, epoch))\n",
    "    print(\"Saving model checkpoint to %s\", last_output_dir)\n",
    "    #保存idx_file 文件 第几轮训练的记录\n",
    "    idx_file = os.path.join(last_output_dir, 'idx_file.txt')\n",
    "    with open(idx_file, 'w', encoding='utf-8') as idxf:\n",
    "        idxf.write(str(args.start_epoch + idx) + '\\n')\n",
    "    #保存idx_file完成\n",
    "    #保存优化器和计划器\n",
    "    torch.save(optimizer.state_dict(), os.path.join(last_output_dir, \"optimizer.pt\"))\n",
    "    torch.save(scheduler.state_dict(), os.path.join(last_output_dir, \"scheduler.pt\"))\n",
    "    print(\"Saving optimizer and scheduler states to %s\", last_output_dir)\n",
    "#     if _==1:\n",
    "#         break\n",
    "#     if (results['f1'] > best_f1):\n",
    "#         best_f1 = results['f1']\n",
    "#         #./models/checkpoint-best 检查目录是否存在 否则创建\n",
    "#         output_dir = os.path.join(args.output_dir, 'checkpoint-best')\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "#         #保存model\n",
    "# #         model_to_save = model.module if hasattr(model,'module') else model  # Take care of distributed/parallel training\n",
    "# #         model_to_save.save_pretrained(output_dir)\n",
    "#         torch.save(model, '%s/cls_model_%d.pth' % (output_dir, epoch))\n",
    "# #         torch.save(args, os.path.join(output_dir, 'training_{}.bin'.format(idx)))\n",
    "#         print(\"Saving model checkpoint to %s\", output_dir)\n",
    "#         #保存优化器的计划器\n",
    "#         torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "#         torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "#         print(\"Saving optimizer and scheduler states to %s\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = 'checkpoint-best-hdj'\n",
    "output_dir = os.path.join('/data/hdj/data/CodeBERT/Siamese-model/saved_models/java', '{}'.format(checkpoint_prefix))                        \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)         \n",
    "model_to_save = model.module if hasattr(model,'module') else model\n",
    "model_to_save.encoder.save_pretrained(output_dir)            \n",
    "output_dir = os.path.join(output_dir, '{}'.format('model.bin')) \n",
    "torch.save(model_to_save.state_dict(), output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用cosloss的代码结束"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 验证和test的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始验证模型的有效性 把模型预测结果连同数据一起保存起来 然后再去判断top mrr mAP\n",
    "#流程 1.训练过程中 每个10轮去在val集上验证 比较f1值是否优于之前，是就保存结果到best，2.每次保存上一次验证的结果 3.最后再在test集上进行测试\n",
    "\n",
    "#check 词表是否与之前model有很大的不同 如果有那么该怎么改善，之前embedding矩阵是否就作废了\n",
    "def evaluate(args, model,eval_loader,instances,tokenizer, checkpoint=None, prefix=\"\", mode='dev'):\n",
    "    '''\n",
    "        args:模型训练时关键参数\n",
    "        model：待验证的模型\n",
    "        eval_loader:待验证的数据集 DataLoader 类型的参数\n",
    "        instances: 若为test模式，则将原始数据输入进来，然后将预测结果一起保存，等待后面计算TOP MAP MRR使用\n",
    "        tokenizer:分词器\n",
    "        checkpoint: 检查点\n",
    "        prefix:前缀\n",
    "        mode: 模式 分为 dev 和 test（需要保存数据）\n",
    "        \n",
    "        return: dict{'acc':,'f1':,'acc_f1'} 主要关注f1的值 越大说明正例的预测越准\n",
    "    '''\n",
    "    #待返回的验证结果\n",
    "    results={}\n",
    "    eval_loss = 0.0 #验证损失累加\n",
    "#     nb_eval_steps = len(test_set)/batch_size #验证批次\n",
    "    preds = None #保存预测的值\n",
    "    out_label_ids = None #保存真实标签target\n",
    "    print('开始验证。。。')\n",
    "    for _, data in enumerate(eval_loader, 0):#start=0 默认就是0\n",
    "        with torch.no_grad():\n",
    "            ids = data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            mask = data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            token_type_ids=None#token_type_ids = data[2].to(device, dtype=torch.long).cuda(non_blocking=True) 因为模型不支持2维设置 所以不再输入这个参数\n",
    "            targets = data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            if need_feature:\n",
    "                feature = data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "            if google_v:\n",
    "                pred = model(input_ids=ids, attention_mask=mask,token_type_ids=None, labels=targets)\n",
    "                loss=pred[0]\n",
    "            else:\n",
    "                if need_feature:\n",
    "                    pred = model(ids, mask,feature)#输出是[batch_size,2]\n",
    "                else:\n",
    "                    pred = model(ids, mask,None)\n",
    "            # print(pred, target)\n",
    "#             loss=floss(pred,targets)\n",
    "            loss = loss_fun(pred, targets)\n",
    "            pred_choice = pred.max(1)[1]\n",
    "            correct = pred_choice.eq(targets).cpu().sum()\n",
    "            metrics = compute_metrics(pred_choice.cpu().numpy(), targets.cpu().numpy())\n",
    "#             print('[',epoch,': ',_,'/',nb_eval_steps,'] ',blue('val'),\" loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(targets.cpu().numpy()),' ration :',sum(targets.cpu().numpy())/len(targets),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#             loss_list_val.append(loss.item())  \n",
    "            global eval_step\n",
    "            tb_writer.add_scalar('eval_loss', loss.item(), eval_step)\n",
    "            tb_writer.add_scalar('eval_acc', correct.item() / float(batch_size), eval_step)\n",
    "            tb_writer.add_scalar('eval_f1', metrics['f1'], eval_step)\n",
    "            eval_step+=1\n",
    "#             print(eval_step)\n",
    "            eval_loss += loss.item()\n",
    "            if(_%100==0):\n",
    "                print(_,'/',len(eval_loader),loss)\n",
    "#         nb_eval_steps += 1\n",
    "        #将preds值和标签进行保存\n",
    "        if preds is None:\n",
    "            if google_v:\n",
    "                preds = pred[1].detach().cpu()\n",
    "            else:\n",
    "                preds=pred.detach().cpu()\n",
    "            out_label_ids = targets.detach().cpu()\n",
    "        else:\n",
    "            if google_v:\n",
    "                preds = np.append(preds, pred[1].detach().cpu().numpy(), axis=0)\n",
    "            else:    \n",
    "                preds = np.append(preds, pred.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, targets.detach().cpu().numpy(), axis=0)       \n",
    "    print('验证结束，开始计算指标',eval_loss)\n",
    "    #计算指标，并更新结果\n",
    " \n",
    "    #ndarra转换为tensor类型\n",
    "    preds=torch.tensor(preds)\n",
    "    out_label_ids=torch.tensor(out_label_ids)\n",
    "#     print(type(preds),preds.shape,preds)\n",
    "#     print(type(out_label_ids),out_label_ids.shape,out_label_ids)    \n",
    "    pred_choice = preds.max(1)[1]#[batch_size,2]\n",
    "    correct = pred_choice.eq(out_label_ids).cpu().sum() #eq需要tensor类型的数据\n",
    "    #但是compute_metrics 需要numpy的数据类型 真烦人\n",
    "    metrics = compute_metrics(pred_choice.numpy(), out_label_ids.numpy())\n",
    "    results.update(metrics)\n",
    "    #计算完成\n",
    "    \n",
    "    #下面分dev 和 test 模式来完成数据模型的保存工作\n",
    "    if(mode=='dev'):\n",
    "        #这里只是把result字典里acc和f1给保存到文件\n",
    "        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "        with open(output_eval_file, \"a+\") as writer:\n",
    "            print(\"***** Eval results {} *****\".format(prefix))\n",
    "            writer.write('evaluate %s\\n' % checkpoint)\n",
    "            for key in sorted(results.keys()):\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "    elif(mode=='test'):\n",
    "        #test结果目录 将test数据连同预测结果进行保存\n",
    "        if(instances==None or len(instances)==0):\n",
    "            print('输入的测试数据有问题 为None 或者 长度为0')\n",
    "        #如果目录不存在就创建\n",
    "        output_test_file = args.test_result_dir\n",
    "        output_dir = os.path.dirname(output_test_file)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        #检验创建目录完成\n",
    "        with open(output_test_file, \"w\") as writer:\n",
    "            print(\"***** Output test results *****\")\n",
    "            preds = F.softmax(torch.tensor(preds))\n",
    "            all_logits = preds.tolist()\n",
    "            for i, logit in tqdm(enumerate(all_logits), desc='Testing'):#desc是进度条的标题\n",
    "                #instances即代表test集里每一行数据的值\n",
    "                instance_rep = '<CODESPLIT>'.join([item.encode('ascii', 'ignore').decode('ascii') for item in instances[i]])\n",
    "                writer.write(instance_rep + '<CODESPLIT>' + '<CODESPLIT>'.join([str(l) for l in logit]) + '\\n')\n",
    "            #打印验证的结果\n",
    "            for key in sorted(results.keys()):\n",
    "                print(\"%s = %s\" % (key, str(results[key])))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes from 1 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-87f036ad76be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#输出是[batch_size,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m#使用floss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#             loss=floss(outputs,targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/waf/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes from 1 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "#模型应该保存效果最好的那个，而不是训练到最后的那个模型\n",
    "print(\"training!!!\")\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "epoch=1\n",
    "best_f1=0.0 #保存最好的f1的模型\n",
    "model.zero_grad()\n",
    "set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "#这里就是在指定 一共训练多少Epoch [start_epoch,num_train_epcchs]\n",
    "t_total = len(training_loader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, args.warmup_steps, t_total)\n",
    "global_step=0\n",
    "eval_step=0\n",
    "train_iterator = trange(args.start_epoch, int(args.num_train_epochs), desc=\"Epoch\")\n",
    "model.train()\n",
    "for idx, p in enumerate(train_iterator):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    loss_list_val = []\n",
    "    acc_list_val = []\n",
    "    num_batch = len(train_set) / batch_size #总共训练次数\n",
    "    for _, data in enumerate(training_loader, 0):#start=0 默认就是0\n",
    "        ids = data[0].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        mask = data[1].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        token_type_ids=None\n",
    "    #     token_type_ids = data[2].to(device, dtype=torch.long).cuda(non_blocking=True) 因为模型不支持2维设置 所以不再输入这个参数\n",
    "        targets = data[2].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "        if need_feature:\n",
    "            feature=data[4].to(device, dtype=torch.long).cuda(non_blocking=True)\n",
    "#         print('feature shape: ',feature.shape)\n",
    "#         print(feature)\n",
    "        if google_v:\n",
    "#             outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=None, labels=targets)\n",
    "            loss=outputs[0]#google loss\n",
    "#             print(outputs)\n",
    "#             loss_hdj = loss_fun(outputs[1], targets)\n",
    "#             print('google loss ',loss,' loss_hdj :',loss_hdj)\n",
    "            pred_choice = outputs[1].max(1)[1]\n",
    "        else:\n",
    "            if need_feature:\n",
    "                outputs = model(ids, mask,feature)#输出是[batch_size,2]\n",
    "            else:\n",
    "                outputs = model(ids, mask,None)\n",
    "            #使用floss\n",
    "#             loss=floss(outputs,targets)\n",
    "            #使用floss\n",
    "            #使用ghmloss\n",
    "#             ghm_target = targets.view(-1, 1)\n",
    "#             ghm_target=ghm_target.cpu()\n",
    "#             ghm_target = torch.LongTensor(ghm_target)\n",
    "#             # print(\"before target :\",targets)\n",
    "#             ghm_target = torch.zeros(len(ghm_target), 2).scatter_(1, ghm_target, 1)\n",
    "#             outputs=outputs.cpu()\n",
    "#             loss=ghm(outputs,ghm_target)\n",
    "            #使用ghmloss\n",
    "            # print(outputs)\n",
    "            \n",
    "            #交叉熵loss\n",
    "            loss = loss_fun(outputs, targets)\n",
    "            #交叉熵loss\n",
    "    \n",
    "    #         print('查看target和ouput的类型 检查max函数返回的东西是否正确',type(outputs),type(targets))\n",
    "        #     print(outputs)\n",
    "            #取outputs二维中最大维的下标\n",
    "            pred_choice = outputs.max(1)[1]\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "             loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        \n",
    "#         targets=targets.cpu()\n",
    "        correct = pred_choice.eq(targets).cpu().sum()\n",
    "        metrics = compute_metrics(pred_choice.cpu().numpy(), targets.cpu().numpy())\n",
    "        if _ %100 == 0:\n",
    "            print('[',epoch,':',_,'/',num_batch,']',\"loss :%.4f\" % loss.item(),' , accuracy: ',correct.item() / float(batch_size) ,'true nums:',sum(targets.cpu().numpy()),' ration :',sum(targets.cpu().numpy())/len(targets),\"acc :\",metrics['acc'],\" f1 :\",metrics['f1'])\n",
    "#         loss_list.append(loss.item())\n",
    "#         acc_list.append(correct.item() / float(batch_size))\n",
    "        if(_+1)%args.gradient_accumulation_steps == 0:\n",
    "            global_step+=1\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "            tb_writer.add_scalar('train_loss', loss.item(), global_step)\n",
    "            tb_writer.add_scalar('train_acc', correct.item() / float(batch_size), global_step)\n",
    "            tb_writer.add_scalar('train_f1', metrics['f1'], global_step)\n",
    "    #下面是在训练过程中进行验证 每一轮都会验证一次，保存模型最好的 和最近一次的模型\n",
    "    results = evaluate(args, model,val_loader,None ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='dev')\n",
    "    print('验证结果 ：',results)\n",
    "    #torch.save(model, '%s/cls_model_%d.pth' % ('models', epoch))\n",
    "    #./models/java/checkpoint-last\n",
    "    last_output_dir = os.path.join(args.output_dir, 'checkpoint-last')\n",
    "    if not os.path.exists(last_output_dir):\n",
    "        os.makedirs(last_output_dir)\n",
    "#     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#     model_to_save.save_pretrained(last_output_dir)\n",
    "    torch.save(model, '%s/cls_model_%d.pth' % (last_output_dir, epoch))\n",
    "    print(\"Saving model checkpoint to %s\", last_output_dir)\n",
    "    #保存idx_file 文件 第几轮训练的记录\n",
    "    idx_file = os.path.join(last_output_dir, 'idx_file.txt')\n",
    "    with open(idx_file, 'w', encoding='utf-8') as idxf:\n",
    "        idxf.write(str(args.start_epoch + idx) + '\\n')\n",
    "    #保存idx_file完成\n",
    "    #保存优化器和计划器\n",
    "    torch.save(optimizer.state_dict(), os.path.join(last_output_dir, \"optimizer.pt\"))\n",
    "    torch.save(scheduler.state_dict(), os.path.join(last_output_dir, \"scheduler.pt\"))\n",
    "    print(\"Saving optimizer and scheduler states to %s\", last_output_dir)\n",
    "#     if _==1:\n",
    "#         break\n",
    "    if (results['f1'] > best_f1):\n",
    "        best_f1 = results['f1']\n",
    "        #./models/checkpoint-best 检查目录是否存在 否则创建\n",
    "        output_dir = os.path.join(args.output_dir, 'checkpoint-best')\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        #保存model\n",
    "#         model_to_save = model.module if hasattr(model,'module') else model  # Take care of distributed/parallel training\n",
    "#         model_to_save.save_pretrained(output_dir)\n",
    "        torch.save(model, '%s/cls_model_%d.pth' % (output_dir, epoch))\n",
    "#         torch.save(args, os.path.join(output_dir, 'training_{}.bin'.format(idx)))\n",
    "        print(\"Saving model checkpoint to %s\", output_dir)\n",
    "        #保存优化器的计划器\n",
    "        torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "        torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "        print(\"Saving optimizer and scheduler states to %s\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([64, 100, 40, 100]) torch.Size([64, 208, 100])\n",
    "code第一次拼接的shape torch.Size([6400, 300, 1, 1])\n",
    "code第一次卷积 torch.Size([192, 1, 100, 100])\n",
    "torch.Size([192, 300, 1, 1])\n",
    "code size report size :  torch.Size([192, 300]) torch.Size([64, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GHM_Loss(nn.Module):\n",
    "    def __init__(self, bins, alpha):\n",
    "        super(GHM_Loss, self).__init__()\n",
    "        self._bins = bins\n",
    "        self._alpha = alpha\n",
    "        self._last_bin_count = None\n",
    "\n",
    "    def _g2bin(self, g):\n",
    "        return torch.floor(g * (self._bins - 0.0001)).long()\n",
    "\n",
    "    def _custom_loss(self, x, target, weight):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _custom_loss_grad(self, x, target):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        g = torch.abs(self._custom_loss_grad(x, target)).detach()\n",
    "\n",
    "        bin_idx = self._g2bin(g)\n",
    "\n",
    "        bin_count = torch.zeros((self._bins))\n",
    "        for i in range(self._bins):\n",
    "            bin_count[i] = (bin_idx == i).sum().item()\n",
    "\n",
    "        N = (x.size(0) * x.size(1))\n",
    "\n",
    "        if self._last_bin_count is None:\n",
    "            self._last_bin_count = bin_count\n",
    "        else:\n",
    "            bin_count = self._alpha * self._last_bin_count + (1 - self._alpha) * bin_count\n",
    "            self._last_bin_count = bin_count\n",
    "\n",
    "        nonempty_bins = (bin_count > 0).sum().item()\n",
    "\n",
    "        gd = bin_count * nonempty_bins\n",
    "        gd = torch.clamp(gd, min=0.0001)\n",
    "        beta = N / gd\n",
    "\n",
    "        return self._custom_loss(x, target, beta[bin_idx])\n",
    "\n",
    "class GHMC_Loss(GHM_Loss):\n",
    "    def __init__(self, bins, alpha):\n",
    "        super(GHMC_Loss, self).__init__(bins, alpha)\n",
    "\n",
    "    def _custom_loss(self, x, target, weight):\n",
    "        return F.binary_cross_entropy_with_logits(x, target, weight=weight)\n",
    "\n",
    "    def _custom_loss_grad(self, x, target):\n",
    "        return torch.sigmoid(x).detach() - target\n",
    "ghm=GHMC_Loss(bins=30,alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal_loss alpha = [0.25, 0.75], 将对每一类权重进行精细化赋值\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, alpha=[0.25,0.75], gamma=2, num_classes = 2, size_average=False):\n",
    "        \"\"\"\n",
    "        focal_loss损失函数, -α(1-yi)**γ *ce_loss(xi,yi)\n",
    "        步骤详细的实现了 focal_loss损失函数.\n",
    "        :param alpha: 阿尔法α,类别权重.      \n",
    "                    当α是列表时,为各类别权重；\n",
    "                    当α为常数时,类别权重为[α, 1-α, 1-α, ....],\n",
    "                    常用于目标检测算法中抑制背景类, \n",
    "                    retainnet中设置为0.25\n",
    "        :param gamma: 伽马γ,难易样本调节参数. retainnet中设置为2\n",
    "        :param num_classes: 类别数量\n",
    "        :param size_average: 损失计算方式,默认取均值\n",
    "        \"\"\"\n",
    "        super(focal_loss,self).__init__()\n",
    "        self.size_average = size_average\n",
    "        if isinstance(alpha,list):\n",
    "            assert len(alpha)==num_classes   \n",
    "            # α可以以list方式输入,\n",
    "            # size:[num_classes] 用于对不同类别精细地赋予权重\n",
    "            print(\"Focal_loss alpha = {}, 将对每一类权重进行精细化赋值\".format(alpha))\n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        else:\n",
    "            assert alpha<1  #如果α为一个常数,则降低第一类的影响,在目标检测中为第一类\n",
    "            print(\"Focal_loss alpha = {} ,将对背景类进行衰减,请在目标检测任务中使用.\".format(alpha))\n",
    "            self.alpha = torch.zeros(num_classes)\n",
    "            self.alpha[0] += alpha\n",
    "            self.alpha[1:] += (1-alpha) # α 最终为 [ α, 1-α, 1-α, 1-α, 1-α, ...] size:[num_classes]\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        \"\"\"\n",
    "        focal_loss损失计算\n",
    "        :param preds: 预测类别. size:[B,N,C] or [B,C]    分\n",
    "                别对应与检测与分类任务, B 批次, N检测框数, C类别数\n",
    "        :param labels:  实际类别. size:[B,N] or [B]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # assert preds.dim()==2 and labels.dim()==1\n",
    "        preds = preds.view(-1,preds.size(-1))\n",
    "#         print('preds :',preds)\n",
    "        self.alpha = self.alpha.to(preds.device)\n",
    "        # 这里并没有直接使用log_softmax, 因为后面会用到softmax的结果(当然也可以使用log_softmax,然后进行exp操作)\n",
    "        preds_softmax = F.softmax(preds, dim=1) \n",
    "#         print('preds_softmax :',preds_softmax)\n",
    "        preds_logsoft = torch.log(preds_softmax)\n",
    "#         print('preds_logsoft :',preds_logsoft)        \n",
    "        # 这部分实现nll_loss ( crossempty = log_softmax + nll )\n",
    "        preds_softmax = preds_softmax.gather(1,labels.view(-1,1))   \n",
    "#         print('preds_softmax :',preds_softmax) \n",
    "        preds_logsoft = preds_logsoft.gather(1,labels.view(-1,1))\n",
    "#         print('preds_logsoft :',preds_logsoft) \n",
    "        self.alpha = self.alpha.gather(0,labels.view(-1))\n",
    "        loss = -torch.mul(torch.pow((1-preds_softmax), self.gamma), preds_logsoft)  \n",
    "        # torch.pow((1-preds_softmax), self.gamma) 为focal loss中 (1-pt)**γ\n",
    "\n",
    "        loss = torch.mul(self.alpha, loss.t())\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "floss=focal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=[0.25,0.75], gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = torch.Tensor([gamma])\n",
    "        self.size_average = size_average\n",
    "        if isinstance(alpha, (float, int)):\n",
    "            if self.alpha > 1:\n",
    "                raise ValueError('Not supported value, alpha should be small than 1.0')\n",
    "            else:\n",
    "                self.alpha = torch.Tensor([alpha, 1.0 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.alpha /= torch.sum(self.alpha)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # [N,C,H,W]->[N,C,H*W] ([N,C,D,H,W]->[N,C,D*H*W])\n",
    "        # target\n",
    "        # [N,1,D,H,W] ->[N*D*H*W,1]\n",
    "        if self.alpha.device != input.device:\n",
    "            self.alpha = torch.tensor(self.alpha, device=input.device)\n",
    "        target = target.view(-1, 1)\n",
    "        logpt = torch.log(input + 1e-10)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1, 1)\n",
    "        pt = torch.exp(logpt)\n",
    "        alpha = self.alpha.gather(0, target.view(-1))\n",
    "\n",
    "        gamma = self.gamma\n",
    "\n",
    "        if not self.gamma.device == input.device:\n",
    "            gamma = torch.tensor(self.gamma, device=input.device)\n",
    "\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "floss=FocalLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和验证并保存最好模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #下面是在训练过程中进行验证 每一轮都会验证一次，保存模型最好的 和最近一次的模型\n",
    "# results = evaluate(args, model,val_loader,None ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='dev')\n",
    "# print('验证结果 ：',results)\n",
    "# #torch.save(model, '%s/cls_model_%d.pth' % ('models', epoch))\n",
    "# #./models/java/checkpoint-last\n",
    "# last_output_dir = os.path.join(args.output_dir, 'checkpoint-last')\n",
    "# if not os.path.exists(last_output_dir):\n",
    "#     os.makedirs(last_output_dir)\n",
    "# #     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "# #     model_to_save.save_pretrained(last_output_dir)\n",
    "# torch.save(model, '%s/cls_model_%d.pth' % (last_output_dir, epoch))\n",
    "# print(\"Saving model checkpoint to %s\", last_output_dir)\n",
    "# #保存idx_file 文件 第几轮训练的记录\n",
    "# idx_file = os.path.join(last_output_dir, 'idx_file.txt')\n",
    "# with open(idx_file, 'w', encoding='utf-8') as idxf:\n",
    "#     idxf.write(str(args.start_epoch + idx) + '\\n')\n",
    "# #保存idx_file完成\n",
    "# #保存优化器和计划器\n",
    "# torch.save(optimizer.state_dict(), os.path.join(last_output_dir, \"optimizer.pt\"))\n",
    "# torch.save(scheduler.state_dict(), os.path.join(last_output_dir, \"scheduler.pt\"))\n",
    "# print(\"Saving optimizer and scheduler states to %s\", last_output_dir)\n",
    "\n",
    "# if (results['f1'] > best_f1):\n",
    "#     best_f1 = results['f1']\n",
    "#     #./models/checkpoint-best 检查目录是否存在 否则创建\n",
    "#     output_dir = os.path.join(args.output_dir, 'checkpoint-best')\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "#     #保存model\n",
    "# #         model_to_save = model.module if hasattr(model,'module') else model  # Take care of distributed/parallel training\n",
    "# #         model_to_save.save_pretrained(output_dir)\n",
    "#         torch.save(model, '%s/cls_model_%d.pth' % (output_dir, epoch))\n",
    "# #         torch.save(args, os.path.join(output_dir, 'training_{}.bin'.format(idx)))\n",
    "#     print(\"Saving model checkpoint to %s\", output_dir)\n",
    "#     #保存优化器的计划器\n",
    "#     torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "#     torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "#     print(\"Saving optimizer and scheduler states to %s\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型进行test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "google_v=False #当为true时，使用RobertClassification模型\n",
    "num_labels=2\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接加载cache文件\n",
      "cached_features_file : /data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_test_test_2hard_2_source_nomethod_less_codebert-base_512_codesearch\n",
      "[Errno 2] No such file or directory: '/data/hdj/tracking_buggy_files/joblib_memmap_eclipse/one_vs_two/cached_test_test_2hard_2_source_nomethod_less_codebert-base_512_codesearch'\n",
      "生成cache文件\n",
      "Writing example 0 of 30000\n",
      "Writing example 10000 of 30000\n",
      "Writing example 20000 of 30000\n"
     ]
    }
   ],
   "source": [
    "# results = evaluate(args, model,val_loader,None ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='dev')\n",
    "#下面开启test模型性能\n",
    "#加载模型进行测试\n",
    "# del model\n",
    "import gc\n",
    "gc.collect()\n",
    "# file_prefix=''\n",
    "# train_file=''\n",
    "# dev_file=''\n",
    "# task_name='codesearch'\n",
    "# max_seq_length=256\n",
    "test_dir=\"/data/hdj/tracking_buggy_files/joblib_memmap_\"+project+\"/one_vs_two/\" #注意目前测试集的目录是单独的，更换测试数据需要更改\n",
    "# test_dir='/data/hdj/data/CodeBERT/data/codesearch/test/zxing_test/zxing/'\n",
    "# test_file = \"test_all.txt\"#目前只使用一个例子来进行测试，后期增加数据量\n",
    "# test_dir=\"/data/hdj/data/CodeBERT/data/codesearch/test/swt_test/swt/\" \n",
    "test_file = \"test_2hard_2_source_nomethod_less.txt\"#\n",
    "# train_file = \"aspectj_train_small.txt\"\n",
    "# dev_file = \"aspectj_val_small.txt\"\n",
    "eval_batch_size=64\n",
    "test_set, instances=load_and_cache_examples_hdj(file_prefix,test_dir,train_file,dev_file,test_file,task_name,tokenizer,max_seq_length,'test')\n",
    "testing_loader = DataLoader(dataset=test_set, batch_size=32, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集比例 tensor(815) 30000 tensor(0.0272)\n"
     ]
    }
   ],
   "source": [
    "# testing_loader.dataset.tensors[0].shape\n",
    "print('测试集比例',sum(list(testing_loader.dataset.tensors[3])),len(testing_loader.dataset.tensors[3]),sum(list(testing_loader.dataset.tensors[3]))/len(testing_loader.dataset.tensors[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始验证。。。\n",
      "0 / 938 tensor(0.7061, device='cuda:0')\n",
      "100 / 938 tensor(1.0171, device='cuda:0')\n",
      "200 / 938 tensor(0.9639, device='cuda:0')\n",
      "300 / 938 tensor(1.0116, device='cuda:0')\n",
      "400 / 938 tensor(0.8404, device='cuda:0')\n",
      "500 / 938 tensor(0.9830, device='cuda:0')\n",
      "600 / 938 tensor(1.0427, device='cuda:0')\n",
      "700 / 938 tensor(0.8450, device='cuda:0')\n",
      "800 / 938 tensor(0.5988, device='cuda:0')\n",
      "900 / 938 tensor(0.7327, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:108: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\r",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证结束，开始计算指标 823.756529957056\n",
      "***** Output test results *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 30000it [00:00, 109200.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.5598333333333333\n",
      "acc_and_f1 = 0.30454046967624254\n",
      "f1 = 0.04924760601915184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#先不删除模型直接进行预测 之后再删除模型 加载保存下来的模型进行预测\n",
    "test_results = evaluate(args, model,testing_loader,instances ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始验证。。。\n",
      "0 / 156 tensor(0.0597, device='cuda:0')\n",
      "100 / 156 tensor(0.6250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/hdj/anaconda3/envs/waf/lib/python3.7/site-packages/ipykernel_launcher.py:108: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\r",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证结束，开始计算指标 256.23298240453005\n",
      "***** Output test results *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 79415it [00:00, 85967.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.67504879430838\n",
      "acc_and_f1 = 0.39524702689299857\n",
      "f1 = 0.11544525947761707\n"
     ]
    }
   ],
   "source": [
    "#加载模型 进行验证 保存结果 22;43\n",
    "del model\n",
    "import gc\n",
    "gc.collect()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "need_feature=False\n",
    "epoch=1\n",
    "idx=1\n",
    "eval_step=0\n",
    "google_v=False #当为true时，使用RobertClassification模型\n",
    "num_labels=2\n",
    "batch_size=512\n",
    "output_dir = os.path.join(args.output_dir, 'checkpoint-best')\n",
    "# output_dir = os.path.join(args.output_dir, 'checkpoint-last')\n",
    "model=torch.load('%s/cls_model_%d.pth' % (output_dir, epoch))\n",
    "test_results = evaluate(args, model,testing_loader,instances ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #使用codeBert的模型不微调 测试效果如何\n",
    "# idx=0\n",
    "# test_results = evaluate(args, model,testing_loader,instances ,tokenizer, checkpoint=str(args.start_epoch + idx),mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算最终指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的文件长度 : 17400\n",
      "start processing\n",
      "top10rank, MRRrank, MAPrank 0 0.004184173669467787 0.006267507002801121\n",
      "top10rank, MRRrank, MAPrank 0 0.005557720717974844 0.01454896650276409\n",
      "top10rank, MRRrank, MAPrank 0 0.006756756756756757 0.006756756756756757\n",
      "top10rank, MRRrank, MAPrank 0 0.004200427935038059 0.00613841243116209\n",
      "top10rank, MRRrank, MAPrank 0 0.005180272566285254 0.011882916053344916\n",
      "top10rank, MRRrank, MAPrank 0 0.005190282381195985 0.011230199928064873\n",
      "top10rank, MRRrank, MAPrank 0 0.003663003663003663 0.003663003663003663\n",
      "top10rank, MRRrank, MAPrank 0 0.005494505494505495 0.005494505494505495\n",
      "top10rank, MRRrank, MAPrank 0 0.023278029160382102 0.03863750628456511\n",
      "top10rank, MRRrank, MAPrank 0 0.003745318352059925 0.003745318352059925\n",
      "top10rank, MRRrank, MAPrank 0 0.005045895939366729 0.009100515114260818\n",
      "top10rank, MRRrank, MAPrank 0 0.013069818133109272 0.02017523030181258\n",
      "top10rank, MRRrank, MAPrank 0 0.009566885964912281 0.011321271929824562\n",
      "top10rank, MRRrank, MAPrank 0 0.005754229839595694 0.007443419028784883\n",
      "top10rank, MRRrank, MAPrank 0 0.017844261450399558 0.02426857030437593\n",
      "top10rank, MRRrank, MAPrank 0 0.004471295682499106 0.008607744782687126\n",
      "top10rank, MRRrank, MAPrank 0 0.003937312416844581 0.005817011664964881\n",
      "top10rank, MRRrank, MAPrank 0 0.004243095087497364 0.006035209782837866\n",
      "top10rank, MRRrank, MAPrank 0 0.003787878787878788 0.003787878787878788\n",
      "top10rank, MRRrank, MAPrank 0 0.008695652173913044 0.008695652173913044\n",
      "top10rank, MRRrank, MAPrank 0 0.005950836351143546 0.014003749473707274\n",
      "top10rank, MRRrank, MAPrank 1 0.06571264108869304 0.07177760298138164\n",
      "top10rank, MRRrank, MAPrank 0 0.005917159763313609 0.005917159763313609\n",
      "top10rank, MRRrank, MAPrank 0 0.00451837140019861 0.006405163853028799\n",
      "top10rank, MRRrank, MAPrank 0 0.005739271747161973 0.014960276746978191\n",
      "top10rank, MRRrank, MAPrank 0 0.007139026158760426 0.017126984201116528\n",
      "top10rank, MRRrank, MAPrank 0 0.005494505494505494 0.007417582417582417\n",
      "top10rank, MRRrank, MAPrank 0 0.00533235629838654 0.03241116663057465\n",
      "top10rank, MRRrank, MAPrank 0 0.01051624893989426 0.015379202078709466\n",
      "top10rank, MRRrank, MAPrank 0 0.006516928273198542 0.010891204835151757\n",
      "top10rank, MRRrank, MAPrank 0 0.007086161302189687 0.01249500162613763\n",
      "top10rank, MRRrank, MAPrank 0 0.00967193799716683 0.017308216192655553\n",
      "top10rank, MRRrank, MAPrank 0 0.0037478944413250983 0.005572711959573273\n",
      "top10rank, MRRrank, MAPrank 1 0.0298623070509239 0.05468383527102922\n",
      "top10rank, MRRrank, MAPrank 0 0.003787878787878788 0.003787878787878788\n",
      "top10rank, MRRrank, MAPrank 0 0.02920993486193049 0.04265183058239373\n",
      "top10rank, MRRrank, MAPrank 0 0.004189597697556375 0.01191769862035488\n",
      "top10rank, MRRrank, MAPrank 0 0.006168910888223704 0.01873244329352512\n",
      "top10rank, MRRrank, MAPrank 0 0.0049500326888951155 0.0068880171850191465\n",
      "top10rank, MRRrank, MAPrank 0 0.007037723523865607 0.011341030566898678\n",
      "top10rank, MRRrank, MAPrank 0 0.012299795599613443 0.026926155173172494\n",
      "top10rank, MRRrank, MAPrank 0 0.013030479763349673 0.020073769328982832\n",
      "top10rank, MRRrank, MAPrank 0 0.0231055900621118 0.026211180124223604\n",
      "top10rank, MRRrank, MAPrank 0 0.00546571039512435 0.01185771757967756\n",
      "top10rank, MRRrank, MAPrank 0 0.018534206135284302 0.027091088007530056\n",
      "top10rank, MRRrank, MAPrank 0 0.012387533910342963 0.03752249141796465\n",
      "top10rank, MRRrank, MAPrank 0 0.006385556365671696 0.011074287650147662\n",
      "top10rank, MRRrank, MAPrank 0 0.006829558758470043 0.01259330968243431\n",
      "top10rank, MRRrank, MAPrank 1 0.031262568024060675 0.04826767541738136\n",
      "top10rank, MRRrank, MAPrank 1 0.024512834346185484 0.04489827306572957\n",
      "top10rank, MRRrank, MAPrank 0 0.003960055096418733 0.005853994490358127\n",
      "top10rank, MRRrank, MAPrank 0 0.005912078475410377 0.008174521914324405\n",
      "top10rank, MRRrank, MAPrank 0 0.0063551902287864595 0.011970661952106382\n",
      "top10rank, MRRrank, MAPrank 0 0.011235955056179775 0.011235955056179775\n",
      "top10rank, MRRrank, MAPrank 0 0.009306779254487448 0.020481281128737514\n",
      "top10rank, MRRrank, MAPrank 0 0.007787698412698413 0.010019841269841269\n",
      "top10rank, MRRrank, MAPrank 0 0.005847953216374269 0.005847953216374269\n",
      "top10rank, MRRrank, MAPrank 0 0.006457053146381793 0.01564224297757975\n",
      "最后平均得分 top10rank, MRRrank, MAPrank : 0.06896551724137931 0.010049881675428442 0.016397047463105597\n"
     ]
    }
   ],
   "source": [
    "#开始计算TOP MRR MAP指标\n",
    "#有个问题 如果预测a=[0.2,0.5] b=[0.8,0.7] 这样的话，是将a排在b前 还是相反 ；暂时还是按照分数的绝对大小来判断吧\n",
    "#每1000验证一次三个指标\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/aspectj_withou_code_clasMeth_summDesc_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/aspectj_clasMeth_summDesc_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/aspectj_oversam_60_clasMeth_summDesc_result_all.txt'\n",
    "\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/swt_clasMeth_summDesc_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/swt_overoversam_60_clasMeth_summDesc_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/swt_withou_code_clasMeth_summDesc_result_all.txt'\n",
    "\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/512_0202_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/result_all.txt'\n",
    "path='/data/hdj/data/CodeBERT/codesearch/results/java/test_v1_0414.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/0415_aspectj_withou_code_clasMeth_summDesc_result_all.txt'\n",
    "# path='/data/hdj/data/CodeBERT/codesearch/results/java/0415_swt_withou_code_clasMeth_summDesc_result_all.txt'\n",
    "with open(path,'r',encoding='utf-8') as f_in:\n",
    "    data = f_in.readlines()\n",
    "    print('读取的文件长度 :',len(data))\n",
    "    #注意swt是479 aspectj是1000 zxing是390\n",
    "#     batched_data = chunked(data, 479)\n",
    "#     batched_data = chunked(data, 390)\n",
    "    batched_data = chunked(data, 300)\n",
    "    print(\"start processing\")\n",
    "    top10ranks=[]\n",
    "    MRRranks=[]\n",
    "    MAPranks=[]\n",
    "    for batch_idx, batch_data in enumerate(batched_data):\n",
    "        preds=[]\n",
    "        out_label_ids=[]\n",
    "        report_ids=[]\n",
    "        paths=[]\n",
    "        for d_idx, d in enumerate(batch_data):\n",
    "            line=d.split('<CODESPLIT>')\n",
    "            out_label_ids.append(int(line[0]))\n",
    "            preds.append(float(line[-1]))\n",
    "            report_ids.append(line[1])\n",
    "            paths.append(line[2])\n",
    "        # print(len(preds),len(out_label_ids))\n",
    "        top10rank, MRRrank, MAPrank = eval_mrr(preds, out_label_ids)\n",
    "        print('top10rank, MRRrank, MAPrank',top10rank, MRRrank, MAPrank)\n",
    "        top10ranks.append(top10rank)\n",
    "        MRRranks.append(MRRrank)\n",
    "        MAPranks.append(MAPrank)\n",
    "        # with open('/data/hdj/data/CodeBERT/data/codesearch/test/aspectj_result_check/aspectj_'+str(batch_idx)+'.txt','w',encoding='utf-8') as f_out:\n",
    "        #     # f_out.writelines('\\n'.join(out_label_ids))\n",
    "        #      for label,pred,id,path in zip(out_label_ids,preds,report_ids,paths):\n",
    "        #          f_out.write(str(label)+\" \"+str(pred)+' '+id+' '+path+'\\n')\n",
    "\n",
    "    print('最后平均得分 top10rank, MRRrank, MAPrank :', sum(top10ranks)/len(top10ranks), sum(MRRranks)/len(MRRranks),sum(MAPranks)/len(MAPranks) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37362/479"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面试测试功能的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.8\n"
     ]
    }
   ],
   "source": [
    "#测试compute_metrics函数作用的代码\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "#从这来看，必须保证正例样本要有，不然f1值都为0 尽量使数据不要那么失衡\n",
    "logit_last=np.array([[4,5],[4,5],[3,2]])\n",
    "label_ids=np.array([1,1,1])\n",
    "preds_label_last = np.argmax(logit_last, axis=1)\n",
    "result_last = compute_metrics(preds_label_last, label_ids)\n",
    "print(result_last['acc'],result_last['f1'])\n",
    "#测试结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.5, 'f1': 0.6}\n",
      "{'acc': 0.6, 'f1': 0.7}\n"
     ]
    }
   ],
   "source": [
    "#测试字典更新函数的代码\n",
    "results={}\n",
    "res1={'acc':0.5,'f1':0.6}\n",
    "res2={'acc':0.6,'f1':0.7}\n",
    "results.update(res1)\n",
    "print(results)\n",
    "results.update(res2)\n",
    "print(results)\n",
    "#测试结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inputs [tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])]\n",
      "1 inputs [tensor([[5, 5, 5],\n",
      "        [6, 6, 6]])]\n"
     ]
    }
   ],
   "source": [
    "#测试shuffle作用的代码\n",
    "all_input_ids=torch.tensor([[1,1,1],[2,2,2],[3,3,3],[4,4,4],[5,5,5],[6,6,6]])\n",
    "dataset = TensorDataset(all_input_ids)\n",
    "testing_loader = DataLoader(dataset=dataset, batch_size=4, shuffle=False, num_workers=2, drop_last=False)\n",
    "testing_loader.dataset.tensors\n",
    "for i, data in enumerate(testing_loader, 0):\n",
    "    print(i, \"inputs\", data)\n",
    "#测试结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试eq函数的代码 eq只能是tensor变量才能使用\n",
    "preds=torch.tensor(np.array([[2.02,2.00],[1.26,1],[-2.3,1.2]]))\n",
    "print(type(preds),preds)\n",
    "targets=torch.tensor([0,1,1])\n",
    "pred_choice = preds.max(1)[1]#[batch_size,2]\n",
    "print(type(pred_choice),pred_choice)\n",
    "correct = pred_choice.eq(targets).cpu().sum()\n",
    "correct\n",
    "#测试结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试trange如何使用\n",
    "from tqdm import tqdm, trange\n",
    "# #这里就是在指定 一共训练多少Epoch\n",
    "# train_iterator = trange(args.start_epoch, int(args.num_train_epochs), desc=\"Epoch\")\n",
    "# for idx, _ in enumerate(train_iterator):\n",
    "#     print(\"a\",idx,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试weight参数如何设置\n",
    "#输入target 一维类别LongTensor input二维 增加weight来控制0类别的比例\n",
    "weights=torch.tensor([0.2,0.7]).cuda()\n",
    "loss_fun=CrossEntropyLoss(weight=weights)\n",
    "# pred = torch.FloatTensor([[0.5, 0.8], [-0.1, 0.7]]).cuda()\n",
    "# target = torch.LongTensor([1, 0]).cuda()\n",
    "# print(pred)\n",
    "# loss=loss_fun(pred,target)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看测试文件的顺序是否一致 必须一致下面计算TOP MRR MAP的结果才能正确\n",
    "# with open('/data/hdj/data/CodeBERT/codesearch/results/java/swt_clasMeth_summDesc_result_all.txt','r',encoding='utf-8') as f_in:\n",
    "#     for i,line  in enumerate(f_in):\n",
    "#         strings=line.split('<CODESPLIT>')\n",
    "#         print(strings[0],strings[1],strings[-2],strings[-1])\n",
    "#         if(i==2000):\n",
    "#             break\n",
    "# # 查看test集的数据是否正常\n",
    "# for i,ins in  enumerate(instances):\n",
    "#     print(i,ins[0],ins[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载打印模型的相关信息\n",
    "# from transformers import AutoModel\n",
    "# tokenizer=RobertaTokenizer.from_pretrained('microsoft/codebert-base')\n",
    "# tokenizer.cls_token,tokenizer.cls_token_id,tokenizer.sep_token,tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_type = 'roberta'\n",
    "        self.output_dir='/data/hdj/data/CodeBERT/codesearch/models/java'\n",
    "        self.test_result_dir='/data/hdj/data/CodeBERT/codesearch/results/java/test_v1_0414.txt'\n",
    "        self.start_epoch=0\n",
    "        self.num_train_epochs=1\n",
    "        self.model_type='roberta'\n",
    "        self.config_name=''\n",
    "        self.model_name_or_path=None\n",
    "        self.task_name='codesearch'\n",
    "        self.tokenizer_name=''\n",
    "        self.model_name_or_path='microsoft/codebert-base'\n",
    "        self.do_lower_case=True\n",
    "args=args()\n",
    "# weights=torch.tensor([0.1,0.9]).cuda()\n",
    "# loss_fun=CrossEntropyLoss(weight=weights)\n",
    "# loss_fun=CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#210415 问题1 RobertClassification模型具体结构和参数使用\n",
    "num_labels=2\n",
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)}\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path,\n",
    "                                      num_labels=num_labels, finetuning_task=args.task_name)\n",
    "if args.tokenizer_name:\n",
    "    tokenizer_name = args.tokenizer_name\n",
    "elif args.model_name_or_path:\n",
    "    tokenizer_name = 'roberta-base'\n",
    "tokenizer = tokenizer_class.from_pretrained(tokenizer_name, do_lower_case=args.do_lower_case)\n",
    "model = model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path),\n",
    "                                    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "input_ids=torch.tensor([[1,1,1],[2,2,2],[3,3,3]])\n",
    "attention_mask=torch.tensor([[1,1,1],[1,1,1],[1,1,1]])\n",
    "label=torch.tensor([0,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=None, labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7257, grad_fn=<NllLossBackward>),\n",
       " tensor([[-0.0580,  0.1690],\n",
       "         [ 0.0895,  0.0964],\n",
       "         [ 0.0569,  0.1093]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = output[1]\n",
    "y_pred_label = y_pred_prob.argmax(dim=1)\n",
    "# 计算loss\n",
    "# 这个 loss 和 output[0] 是一样的\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y_pred_prob.view(-1, 2), label.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7257, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(model)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以覆盖最后一层的值\n",
    "# model.classifier.out_proj=nn.Linear(768, 9)\n",
    "model.base_model.add_module=nn.Linear(768,768)\n",
    "model.base_model.add_module=nn.Linear(768,768)\n",
    "model.base_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "robertaModel=RobertaModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(robertaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/aspectj-attic/ajdoc-src/or...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/docs/sandbox/ubc-design-pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/bugs150/pr115252/Exa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/bcel-builder/src/org/aspec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/ajde/examples/spacew...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/pureJava/BoundaryNum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/docs/sandbox/ubc-design-pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/new/StaticIntroduced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/bugs/IntertypeDiffer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/bugs153/pr153490/Foo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/org.aspectj.ajdt.core/src/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/weaver/src/org/aspectj/wea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/org.aspectj.ajdt.core/test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/ltw/callMunging/case...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/pureJava/test126/Dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/new/NoCalledMethodNa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/bugs/AroundAdviceJPs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/multiIncremental/PR1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/tests/multiIncremental/Mul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>146546</td>\n",
       "      <td>org.aspectj/modules/ajdoc/testdata/coverage/fl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               path  label\n",
       "0   146546  org.aspectj/modules/aspectj-attic/ajdoc-src/or...      0\n",
       "1   146546  org.aspectj/modules/docs/sandbox/ubc-design-pa...      0\n",
       "2   146546  org.aspectj/modules/tests/bugs150/pr115252/Exa...      0\n",
       "3   146546  org.aspectj/modules/bcel-builder/src/org/aspec...      0\n",
       "4   146546  org.aspectj/modules/tests/ajde/examples/spacew...      0\n",
       "5   146546  org.aspectj/modules/tests/pureJava/BoundaryNum...      0\n",
       "6   146546  org.aspectj/modules/docs/sandbox/ubc-design-pa...      0\n",
       "7   146546  org.aspectj/modules/tests/new/StaticIntroduced...      0\n",
       "8   146546  org.aspectj/modules/tests/bugs/IntertypeDiffer...      0\n",
       "9   146546  org.aspectj/modules/tests/bugs153/pr153490/Foo...      0\n",
       "10  146546  org.aspectj/modules/org.aspectj.ajdt.core/src/...      0\n",
       "11  146546  org.aspectj/modules/weaver/src/org/aspectj/wea...      0\n",
       "12  146546  org.aspectj/modules/org.aspectj.ajdt.core/test...      0\n",
       "13  146546  org.aspectj/modules/tests/ltw/callMunging/case...      0\n",
       "14  146546  org.aspectj/modules/tests/pureJava/test126/Dri...      0\n",
       "15  146546  org.aspectj/modules/tests/new/NoCalledMethodNa...      0\n",
       "16  146546  org.aspectj/modules/tests/bugs/AroundAdviceJPs...      0\n",
       "17  146546  org.aspectj/modules/tests/multiIncremental/PR1...      0\n",
       "18  146546  org.aspectj/modules/tests/multiIncremental/Mul...      0\n",
       "19  146546  org.aspectj/modules/ajdoc/testdata/coverage/fl...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "aspectj_20_training_neg=pd.read_csv('/data/hdj/cross_project_trans/report/aspectj_20_training_neg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(aspectj_20_training_neg['id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
